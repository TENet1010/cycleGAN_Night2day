{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuGAiqDDsPoN",
        "outputId": "52fca9a4-7f72-4a81-b9b6-f6bae3e20933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.12.0+cu113)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 676 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.8 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181 kB 71.2 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 145 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Building wheels for collected packages: visdom, pathtools, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=ae7efd9ed47f6b2afd2ca50fd3f6fcd77620e08309e4c7057034b27632e03488\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=cfa65cf51fa26b3a0deda9891071f5b697f4225a0ca82a690565dd801193dff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=65d87b4cb8bd595ae0b2a2848b14ae6f1feb09dc567d4e42129f41908f8668cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom pathtools torchfile\n",
            "Installing collected packages: smmap, jsonpointer, gitdb, websocket-client, torchfile, shortuuid, setproctitle, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, wandb, visdom, dominate\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 dominate-2.6.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.12.18 websocket-client-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VIGyIus8Vr7"
      },
      "source": [
        "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images.\n",
        "\n",
        "- ‡∏°‡∏µ dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô /dataset/data_sample ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏≠‡∏≤ dataset ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö **trainA trainB testA testB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrdOettJxaCc",
        "outputId": "ffa83aba-4ee4-4512-ba48-611faa38a8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./datasets/data_v2: ./datasets/data_v2: Is a directory\n"
          ]
        }
      ],
      "source": [
        "!bash ./datasets/data_sample nightdayimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô pretrained model ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B75UqtKhxznS"
      },
      "outputs": [],
      "source": [
        "!bash /content/drive/MyDrive/cycleGAN/pytorch-CycleGAN-and-pix2pix-master/checkpoints/night2day_pretrained/latest_net_G.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/data_sample --name horse2zebra --model cycle_gan`\n",
        "\n",
        "‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name\n",
        "\n",
        "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
        " # all option for training\n",
        "        parser.add_argument('--display_freq', type=int, default=400, help='frequency of showing training results on screen')\n",
        "        parser.add_argument('--display_ncols', type=int, default=4, help='if positive, display all images in a single visdom web panel with certain number of images per row.')\n",
        "        parser.add_argument('--display_id', type=int, default=1, help='window id of the web display')\n",
        "        parser.add_argument('--display_server', type=str, default=\"http://localhost\", help='visdom server of the web display')\n",
        "        parser.add_argument('--display_env', type=str, default='main', help='visdom display environment name (default is \"main\")')\n",
        "        parser.add_argument('--display_port', type=int, default=8097, help='visdom port of the web display')\n",
        "        parser.add_argument('--update_html_freq', type=int, default=1000, help='frequency of saving training results to html')\n",
        "        parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
        "        parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n",
        "        # network saving and loading parameters\n",
        "        parser.add_argument('--save_latest_freq', type=int, default=5000, help='frequency of saving the latest results')\n",
        "        parser.add_argument('--save_epoch_freq', type=int, default=5, help='frequency of saving checkpoints at the end of epochs')\n",
        "        parser.add_argument('--save_by_iter', action='store_true', help='whether saves model by iteration')\n",
        "        parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
        "        parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n",
        "        parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
        "        # training parameters\n",
        "        parser.add_argument('--n_epochs', type=int, default=100, help='number of epochs with the initial learning rate')\n",
        "        parser.add_argument('--n_epochs_decay', type=int, default=100, help='number of epochs to linearly decay learning rate to zero')\n",
        "        parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
        "        parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
        "        parser.add_argument('--gan_mode', type=str, default='lsgan', help='the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.')\n",
        "        parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')\n",
        "        parser.add_argument('--lr_policy', type=str, default='linear', help='learning rate policy. [linear | step | plateau | cosine]')\n",
        "        parser.add_argument('--lr_decay_iters', type=int, default=50, help='multiply by a gamma every lr_decay_iters iterations')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sp7TCT2x9dB",
        "outputId": "b3d9996d-eecf-42f1-eb79-abb4716b558b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/data_v2            \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 20                            \t[default: 1]\n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 20                            \t[default: 100]\n",
            "           n_epochs_decay: 40                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "                     name: night2dayV2                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: True                          \t[default: False]\n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The number of training images = 2500\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "loading the model from ./checkpoints/night2dayV2/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/night2dayV2/latest_net_G_B.pth\n",
            "loading the model from ./checkpoints/night2dayV2/latest_net_D_A.pth\n",
            "loading the model from ./checkpoints/night2dayV2/latest_net_D_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnattakorn\u001b[0m (\u001b[33mstrong-ranccoons\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/cycleGAN/pytorch-CycleGAN-and-pix2pix-master/wandb/run-20220527_095109-10c9q4yx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnight2dayV2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/strong-ranccoons/CycleGAN-and-pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/strong-ranccoons/CycleGAN-and-pix2pix/runs/10c9q4yx\u001b[0m\n",
            "create web directory ./checkpoints/night2dayV2/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0001951\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "(epoch: 20, iters: 100, time: 0.379, data: 1.412) D_A: 0.224 G_A: 0.689 cycle_A: 1.004 idt_A: 0.225 D_B: 0.189 G_B: 0.550 cycle_B: 0.640 idt_B: 0.408 \n",
            "(epoch: 20, iters: 200, time: 0.317, data: 0.007) D_A: 0.109 G_A: 0.670 cycle_A: 1.092 idt_A: 0.314 D_B: 0.083 G_B: 0.294 cycle_B: 0.720 idt_B: 0.354 \n",
            "(epoch: 20, iters: 300, time: 0.309, data: 0.003) D_A: 0.242 G_A: 0.388 cycle_A: 1.332 idt_A: 0.237 D_B: 0.175 G_B: 0.517 cycle_B: 0.800 idt_B: 0.455 \n",
            "(epoch: 20, iters: 400, time: 5.495, data: 0.004) D_A: 0.344 G_A: 0.445 cycle_A: 1.129 idt_A: 0.306 D_B: 0.282 G_B: 0.783 cycle_B: 0.608 idt_B: 0.528 \n",
            "(epoch: 20, iters: 500, time: 0.310, data: 0.009) D_A: 0.071 G_A: 0.494 cycle_A: 1.180 idt_A: 0.250 D_B: 0.094 G_B: 0.289 cycle_B: 0.799 idt_B: 0.471 \n",
            "(epoch: 20, iters: 600, time: 0.337, data: 0.001) D_A: 0.142 G_A: 0.303 cycle_A: 0.945 idt_A: 0.253 D_B: 0.187 G_B: 0.458 cycle_B: 0.866 idt_B: 0.429 \n",
            "(epoch: 20, iters: 700, time: 0.304, data: 0.007) D_A: 0.589 G_A: 0.152 cycle_A: 0.698 idt_A: 0.372 D_B: 0.161 G_B: 0.288 cycle_B: 0.894 idt_B: 0.184 \n",
            "(epoch: 20, iters: 800, time: 1.160, data: 0.009) D_A: 0.091 G_A: 0.615 cycle_A: 1.386 idt_A: 0.426 D_B: 0.105 G_B: 0.220 cycle_B: 0.667 idt_B: 0.474 \n",
            "(epoch: 20, iters: 900, time: 0.303, data: 0.005) D_A: 0.244 G_A: 0.126 cycle_A: 1.339 idt_A: 0.165 D_B: 0.258 G_B: 0.152 cycle_B: 0.796 idt_B: 0.481 \n",
            "(epoch: 20, iters: 1000, time: 0.314, data: 0.002) D_A: 0.143 G_A: 0.376 cycle_A: 0.910 idt_A: 0.228 D_B: 0.214 G_B: 0.572 cycle_B: 0.620 idt_B: 0.334 \n",
            "(epoch: 20, iters: 1100, time: 0.315, data: 0.011) D_A: 0.225 G_A: 0.299 cycle_A: 1.062 idt_A: 0.346 D_B: 0.233 G_B: 0.750 cycle_B: 0.886 idt_B: 0.344 \n",
            "(epoch: 20, iters: 1200, time: 1.310, data: 0.000) D_A: 0.250 G_A: 0.167 cycle_A: 1.151 idt_A: 0.303 D_B: 0.289 G_B: 0.476 cycle_B: 0.731 idt_B: 0.415 \n",
            "(epoch: 20, iters: 1300, time: 0.309, data: 0.013) D_A: 0.078 G_A: 0.435 cycle_A: 0.728 idt_A: 0.232 D_B: 0.200 G_B: 0.293 cycle_B: 0.829 idt_B: 0.289 \n",
            "(epoch: 20, iters: 1400, time: 0.304, data: 0.013) D_A: 0.183 G_A: 0.099 cycle_A: 1.174 idt_A: 0.185 D_B: 0.300 G_B: 0.715 cycle_B: 0.528 idt_B: 0.485 \n",
            "(epoch: 20, iters: 1500, time: 0.327, data: 0.003) D_A: 0.079 G_A: 0.453 cycle_A: 0.912 idt_A: 0.216 D_B: 0.267 G_B: 0.333 cycle_B: 0.607 idt_B: 0.305 \n",
            "(epoch: 20, iters: 1600, time: 1.188, data: 0.006) D_A: 0.128 G_A: 0.403 cycle_A: 0.893 idt_A: 0.207 D_B: 0.298 G_B: 0.840 cycle_B: 0.689 idt_B: 0.350 \n",
            "(epoch: 20, iters: 1700, time: 0.431, data: 0.006) D_A: 0.096 G_A: 0.331 cycle_A: 0.979 idt_A: 0.178 D_B: 0.055 G_B: 0.285 cycle_B: 0.567 idt_B: 0.425 \n",
            "(epoch: 20, iters: 1800, time: 0.306, data: 0.015) D_A: 0.047 G_A: 0.779 cycle_A: 0.642 idt_A: 0.345 D_B: 0.150 G_B: 0.601 cycle_B: 0.900 idt_B: 0.278 \n",
            "(epoch: 20, iters: 1900, time: 0.314, data: 0.003) D_A: 0.025 G_A: 0.933 cycle_A: 1.244 idt_A: 0.216 D_B: 0.225 G_B: 0.515 cycle_B: 0.887 idt_B: 0.567 \n",
            "(epoch: 20, iters: 2000, time: 1.829, data: 0.005) D_A: 0.229 G_A: 0.359 cycle_A: 0.948 idt_A: 0.405 D_B: 0.196 G_B: 0.404 cycle_B: 0.966 idt_B: 0.392 \n",
            "(epoch: 20, iters: 2100, time: 0.311, data: 0.006) D_A: 0.075 G_A: 0.929 cycle_A: 1.435 idt_A: 0.281 D_B: 0.194 G_B: 0.344 cycle_B: 0.739 idt_B: 0.381 \n",
            "(epoch: 20, iters: 2200, time: 0.314, data: 0.003) D_A: 0.088 G_A: 0.416 cycle_A: 2.145 idt_A: 0.227 D_B: 0.128 G_B: 0.314 cycle_B: 0.838 idt_B: 0.501 \n",
            "(epoch: 20, iters: 2300, time: 0.306, data: 0.005) D_A: 0.074 G_A: 0.369 cycle_A: 1.695 idt_A: 0.298 D_B: 0.078 G_B: 0.549 cycle_B: 0.758 idt_B: 0.503 \n",
            "(epoch: 20, iters: 2400, time: 1.168, data: 0.013) D_A: 0.153 G_A: 0.638 cycle_A: 1.270 idt_A: 0.254 D_B: 0.084 G_B: 0.249 cycle_B: 0.772 idt_B: 0.459 \n",
            "(epoch: 20, iters: 2500, time: 0.309, data: 0.015) D_A: 0.364 G_A: 0.054 cycle_A: 1.003 idt_A: 0.232 D_B: 0.271 G_B: 0.121 cycle_B: 0.590 idt_B: 0.410 \n",
            "saving the model at the end of epoch 20, iters 2500\n",
            "End of epoch 20 / 60 \t Time Taken: 843 sec\n",
            "learning rate 0.0001951 -> 0.0001902\n",
            "(epoch: 21, iters: 100, time: 0.340, data: 1.164) D_A: 0.038 G_A: 0.688 cycle_A: 0.951 idt_A: 0.161 D_B: 0.157 G_B: 0.226 cycle_B: 0.554 idt_B: 0.382 \n",
            "(epoch: 21, iters: 200, time: 0.301, data: 0.006) D_A: 0.144 G_A: 0.284 cycle_A: 0.812 idt_A: 0.161 D_B: 0.191 G_B: 0.607 cycle_B: 0.522 idt_B: 0.239 \n",
            "(epoch: 21, iters: 300, time: 2.080, data: 0.004) D_A: 0.065 G_A: 0.569 cycle_A: 0.754 idt_A: 0.292 D_B: 0.083 G_B: 0.137 cycle_B: 0.855 idt_B: 0.313 \n",
            "(epoch: 21, iters: 400, time: 0.394, data: 0.006) D_A: 0.174 G_A: 0.266 cycle_A: 0.876 idt_A: 0.432 D_B: 0.203 G_B: 0.279 cycle_B: 0.778 idt_B: 0.296 \n",
            "(epoch: 21, iters: 500, time: 0.324, data: 0.024) D_A: 0.159 G_A: 0.456 cycle_A: 0.935 idt_A: 0.169 D_B: 0.220 G_B: 0.142 cycle_B: 0.488 idt_B: 0.408 \n",
            "(epoch: 21, iters: 600, time: 0.308, data: 0.006) D_A: 0.103 G_A: 0.505 cycle_A: 0.776 idt_A: 0.343 D_B: 0.086 G_B: 0.309 cycle_B: 0.695 idt_B: 0.344 \n",
            "(epoch: 21, iters: 700, time: 0.999, data: 0.012) D_A: 0.279 G_A: 0.104 cycle_A: 0.713 idt_A: 0.352 D_B: 0.291 G_B: 0.435 cycle_B: 0.534 idt_B: 0.271 \n",
            "(epoch: 21, iters: 800, time: 0.346, data: 0.005) D_A: 0.190 G_A: 0.382 cycle_A: 1.216 idt_A: 0.269 D_B: 0.142 G_B: 0.788 cycle_B: 0.777 idt_B: 0.461 \n",
            "(epoch: 21, iters: 900, time: 0.307, data: 0.010) D_A: 0.195 G_A: 0.329 cycle_A: 1.065 idt_A: 0.156 D_B: 0.156 G_B: 0.383 cycle_B: 0.518 idt_B: 0.399 \n",
            "(epoch: 21, iters: 1000, time: 0.352, data: 0.003) D_A: 0.269 G_A: 0.347 cycle_A: 3.870 idt_A: 0.215 D_B: 0.126 G_B: 0.391 cycle_B: 0.591 idt_B: 1.632 \n",
            "(epoch: 21, iters: 1100, time: 1.164, data: 0.004) D_A: 0.167 G_A: 0.311 cycle_A: 0.911 idt_A: 0.205 D_B: 0.125 G_B: 0.585 cycle_B: 0.547 idt_B: 0.291 \n",
            "(epoch: 21, iters: 1200, time: 0.346, data: 0.009) D_A: 0.125 G_A: 0.095 cycle_A: 1.069 idt_A: 0.304 D_B: 0.198 G_B: 0.695 cycle_B: 0.756 idt_B: 0.383 \n",
            "(epoch: 21, iters: 1300, time: 0.344, data: 0.010) D_A: 0.257 G_A: 0.112 cycle_A: 1.100 idt_A: 0.253 D_B: 0.145 G_B: 0.281 cycle_B: 0.707 idt_B: 0.365 \n",
            "(epoch: 21, iters: 1400, time: 0.308, data: 0.003) D_A: 0.128 G_A: 0.367 cycle_A: 1.400 idt_A: 0.174 D_B: 0.131 G_B: 0.296 cycle_B: 0.454 idt_B: 0.359 \n",
            "(epoch: 21, iters: 1500, time: 1.849, data: 0.007) D_A: 0.152 G_A: 0.222 cycle_A: 1.331 idt_A: 0.380 D_B: 0.285 G_B: 0.302 cycle_B: 0.871 idt_B: 0.461 \n",
            "(epoch: 21, iters: 1600, time: 0.300, data: 0.004) D_A: 0.187 G_A: 0.527 cycle_A: 1.371 idt_A: 0.168 D_B: 0.213 G_B: 0.250 cycle_B: 0.752 idt_B: 0.754 \n",
            "(epoch: 21, iters: 1700, time: 0.334, data: 0.013) D_A: 0.182 G_A: 0.231 cycle_A: 1.382 idt_A: 0.211 D_B: 0.418 G_B: 0.034 cycle_B: 0.620 idt_B: 0.649 \n",
            "(epoch: 21, iters: 1800, time: 0.324, data: 0.014) D_A: 0.178 G_A: 0.410 cycle_A: 1.322 idt_A: 0.252 D_B: 0.170 G_B: 0.207 cycle_B: 0.727 idt_B: 0.582 \n",
            "(epoch: 21, iters: 1900, time: 1.095, data: 0.001) D_A: 0.222 G_A: 0.172 cycle_A: 1.074 idt_A: 0.220 D_B: 0.166 G_B: 0.327 cycle_B: 0.597 idt_B: 0.382 \n",
            "(epoch: 21, iters: 2000, time: 0.303, data: 0.006) D_A: 0.209 G_A: 0.251 cycle_A: 0.956 idt_A: 0.198 D_B: 0.159 G_B: 0.764 cycle_B: 0.753 idt_B: 0.561 \n",
            "(epoch: 21, iters: 2100, time: 0.306, data: 0.005) D_A: 0.262 G_A: 0.160 cycle_A: 1.108 idt_A: 0.274 D_B: 0.138 G_B: 0.758 cycle_B: 0.882 idt_B: 0.282 \n",
            "(epoch: 21, iters: 2200, time: 0.408, data: 0.003) D_A: 0.125 G_A: 0.658 cycle_A: 1.716 idt_A: 0.184 D_B: 0.053 G_B: 0.277 cycle_B: 0.576 idt_B: 0.511 \n",
            "(epoch: 21, iters: 2300, time: 1.183, data: 0.020) D_A: 0.045 G_A: 0.444 cycle_A: 1.138 idt_A: 0.210 D_B: 0.168 G_B: 0.737 cycle_B: 0.483 idt_B: 0.400 \n",
            "(epoch: 21, iters: 2400, time: 0.311, data: 0.004) D_A: 0.078 G_A: 0.864 cycle_A: 1.149 idt_A: 0.255 D_B: 0.088 G_B: 0.447 cycle_B: 0.682 idt_B: 0.466 \n",
            "(epoch: 21, iters: 2500, time: 0.312, data: 0.003) D_A: 0.063 G_A: 0.615 cycle_A: 1.484 idt_A: 0.473 D_B: 0.065 G_B: 0.451 cycle_B: 0.942 idt_B: 0.629 \n",
            "saving the latest model (epoch 21, total_iters 5000)\n",
            "End of epoch 21 / 60 \t Time Taken: 819 sec\n",
            "learning rate 0.0001902 -> 0.0001854\n",
            "(epoch: 22, iters: 100, time: 0.373, data: 0.605) D_A: 0.174 G_A: 0.425 cycle_A: 1.455 idt_A: 0.747 D_B: 0.128 G_B: 0.410 cycle_B: 1.157 idt_B: 0.629 \n",
            "(epoch: 22, iters: 200, time: 2.145, data: 0.003) D_A: 0.124 G_A: 0.791 cycle_A: 1.293 idt_A: 0.393 D_B: 0.045 G_B: 0.633 cycle_B: 1.014 idt_B: 0.526 \n",
            "(epoch: 22, iters: 300, time: 0.364, data: 0.004) D_A: 0.028 G_A: 0.545 cycle_A: 1.881 idt_A: 0.357 D_B: 0.142 G_B: 0.832 cycle_B: 0.834 idt_B: 0.348 \n",
            "(epoch: 22, iters: 400, time: 0.394, data: 0.012) D_A: 0.050 G_A: 0.464 cycle_A: 0.938 idt_A: 0.246 D_B: 0.194 G_B: 0.765 cycle_B: 0.719 idt_B: 0.336 \n",
            "(epoch: 22, iters: 500, time: 0.336, data: 0.005) D_A: 0.067 G_A: 0.521 cycle_A: 1.208 idt_A: 0.259 D_B: 0.153 G_B: 0.682 cycle_B: 0.713 idt_B: 0.396 \n",
            "(epoch: 22, iters: 600, time: 1.071, data: 0.006) D_A: 0.120 G_A: 0.716 cycle_A: 0.749 idt_A: 0.355 D_B: 0.132 G_B: 0.353 cycle_B: 1.065 idt_B: 0.279 \n",
            "(epoch: 22, iters: 700, time: 0.306, data: 0.010) D_A: 0.079 G_A: 1.467 cycle_A: 2.109 idt_A: 0.298 D_B: 0.052 G_B: 0.538 cycle_B: 0.960 idt_B: 0.810 \n",
            "(epoch: 22, iters: 800, time: 0.296, data: 0.008) D_A: 0.109 G_A: 0.561 cycle_A: 1.132 idt_A: 0.377 D_B: 0.030 G_B: 0.235 cycle_B: 1.041 idt_B: 0.380 \n",
            "(epoch: 22, iters: 900, time: 0.345, data: 0.010) D_A: 0.055 G_A: 1.016 cycle_A: 2.270 idt_A: 0.545 D_B: 0.194 G_B: 0.813 cycle_B: 1.165 idt_B: 0.368 \n",
            "(epoch: 22, iters: 1000, time: 1.974, data: 0.003) D_A: 0.034 G_A: 0.520 cycle_A: 0.792 idt_A: 0.261 D_B: 0.136 G_B: 0.728 cycle_B: 0.763 idt_B: 0.316 \n",
            "(epoch: 22, iters: 1100, time: 0.318, data: 0.005) D_A: 0.050 G_A: 0.646 cycle_A: 0.892 idt_A: 0.249 D_B: 0.140 G_B: 0.199 cycle_B: 0.712 idt_B: 0.311 \n",
            "(epoch: 22, iters: 1200, time: 0.351, data: 0.015) D_A: 0.026 G_A: 0.982 cycle_A: 0.914 idt_A: 0.326 D_B: 0.175 G_B: 0.760 cycle_B: 0.947 idt_B: 0.286 \n",
            "(epoch: 22, iters: 1300, time: 0.349, data: 0.003) D_A: 0.067 G_A: 0.545 cycle_A: 1.548 idt_A: 0.394 D_B: 0.045 G_B: 0.977 cycle_B: 0.942 idt_B: 0.514 \n",
            "(epoch: 22, iters: 1400, time: 1.091, data: 0.012) D_A: 0.050 G_A: 0.555 cycle_A: 1.252 idt_A: 0.407 D_B: 0.275 G_B: 0.600 cycle_B: 1.306 idt_B: 0.511 \n",
            "(epoch: 22, iters: 1500, time: 0.332, data: 0.005) D_A: 0.069 G_A: 1.493 cycle_A: 1.072 idt_A: 0.181 D_B: 0.287 G_B: 0.846 cycle_B: 1.094 idt_B: 0.447 \n",
            "(epoch: 22, iters: 1600, time: 0.371, data: 0.012) D_A: 0.029 G_A: 0.870 cycle_A: 0.994 idt_A: 0.459 D_B: 0.111 G_B: 0.676 cycle_B: 0.961 idt_B: 0.456 \n",
            "(epoch: 22, iters: 1700, time: 0.324, data: 0.005) D_A: 0.339 G_A: 0.158 cycle_A: 2.895 idt_A: 0.734 D_B: 0.118 G_B: 0.357 cycle_B: 1.700 idt_B: 0.954 \n",
            "(epoch: 22, iters: 1800, time: 1.149, data: 0.006) D_A: 0.063 G_A: 0.693 cycle_A: 1.190 idt_A: 0.259 D_B: 0.122 G_B: 0.557 cycle_B: 0.742 idt_B: 0.528 \n",
            "(epoch: 22, iters: 1900, time: 0.328, data: 0.016) D_A: 0.142 G_A: 0.334 cycle_A: 1.207 idt_A: 0.345 D_B: 0.173 G_B: 0.595 cycle_B: 0.651 idt_B: 0.468 \n",
            "(epoch: 22, iters: 2000, time: 0.365, data: 0.016) D_A: 0.222 G_A: 0.581 cycle_A: 0.918 idt_A: 0.451 D_B: 0.093 G_B: 0.387 cycle_B: 0.508 idt_B: 0.323 \n",
            "(epoch: 22, iters: 2100, time: 0.335, data: 0.016) D_A: 0.060 G_A: 0.263 cycle_A: 1.659 idt_A: 0.261 D_B: 0.130 G_B: 0.315 cycle_B: 0.683 idt_B: 0.505 \n",
            "(epoch: 22, iters: 2200, time: 1.120, data: 0.005) D_A: 0.061 G_A: 0.646 cycle_A: 1.263 idt_A: 0.471 D_B: 0.151 G_B: 0.374 cycle_B: 1.168 idt_B: 0.628 \n",
            "(epoch: 22, iters: 2300, time: 0.325, data: 0.004) D_A: 0.057 G_A: 0.570 cycle_A: 1.073 idt_A: 0.519 D_B: 0.082 G_B: 0.560 cycle_B: 1.101 idt_B: 0.314 \n",
            "(epoch: 22, iters: 2400, time: 0.348, data: 0.003) D_A: 0.277 G_A: 0.624 cycle_A: 1.003 idt_A: 0.283 D_B: 0.093 G_B: 0.036 cycle_B: 0.553 idt_B: 0.365 \n",
            "(epoch: 22, iters: 2500, time: 0.308, data: 0.007) D_A: 0.150 G_A: 0.277 cycle_A: 1.007 idt_A: 0.273 D_B: 0.208 G_B: 0.394 cycle_B: 0.621 idt_B: 0.352 \n",
            "End of epoch 22 / 60 \t Time Taken: 814 sec\n",
            "learning rate 0.0001854 -> 0.0001805\n",
            "(epoch: 23, iters: 100, time: 2.149, data: 0.728) D_A: 0.179 G_A: 0.362 cycle_A: 0.969 idt_A: 0.193 D_B: 0.152 G_B: 0.378 cycle_B: 0.577 idt_B: 0.235 \n",
            "(epoch: 23, iters: 200, time: 0.295, data: 0.004) D_A: 0.112 G_A: 0.479 cycle_A: 0.782 idt_A: 0.260 D_B: 0.136 G_B: 0.391 cycle_B: 0.751 idt_B: 0.338 \n",
            "(epoch: 23, iters: 300, time: 0.332, data: 0.025) D_A: 0.158 G_A: 0.271 cycle_A: 1.444 idt_A: 0.312 D_B: 0.123 G_B: 0.495 cycle_B: 1.003 idt_B: 0.837 \n",
            "(epoch: 23, iters: 400, time: 0.363, data: 0.005) D_A: 0.115 G_A: 0.300 cycle_A: 0.898 idt_A: 0.206 D_B: 0.173 G_B: 0.269 cycle_B: 0.625 idt_B: 0.441 \n",
            "(epoch: 23, iters: 500, time: 1.981, data: 0.004) D_A: 0.072 G_A: 0.605 cycle_A: 1.048 idt_A: 0.228 D_B: 0.210 G_B: 0.600 cycle_B: 0.678 idt_B: 0.394 \n",
            "(epoch: 23, iters: 600, time: 0.371, data: 0.007) D_A: 0.093 G_A: 0.879 cycle_A: 0.892 idt_A: 0.313 D_B: 0.286 G_B: 0.463 cycle_B: 0.746 idt_B: 0.301 \n",
            "(epoch: 23, iters: 700, time: 0.322, data: 0.012) D_A: 0.101 G_A: 1.238 cycle_A: 1.543 idt_A: 0.231 D_B: 0.138 G_B: 0.292 cycle_B: 0.685 idt_B: 0.421 \n",
            "(epoch: 23, iters: 800, time: 0.359, data: 0.003) D_A: 0.130 G_A: 0.522 cycle_A: 0.900 idt_A: 0.287 D_B: 0.089 G_B: 0.721 cycle_B: 0.817 idt_B: 0.300 \n",
            "(epoch: 23, iters: 900, time: 1.116, data: 0.004) D_A: 0.137 G_A: 0.304 cycle_A: 0.738 idt_A: 0.249 D_B: 0.122 G_B: 0.375 cycle_B: 0.799 idt_B: 0.324 \n",
            "(epoch: 23, iters: 1000, time: 0.327, data: 0.004) D_A: 0.178 G_A: 0.544 cycle_A: 0.881 idt_A: 0.260 D_B: 0.085 G_B: 0.082 cycle_B: 0.805 idt_B: 0.604 \n",
            "(epoch: 23, iters: 1100, time: 0.358, data: 0.022) D_A: 0.148 G_A: 0.461 cycle_A: 1.120 idt_A: 0.235 D_B: 0.171 G_B: 0.367 cycle_B: 0.650 idt_B: 0.482 \n",
            "(epoch: 23, iters: 1200, time: 0.349, data: 0.005) D_A: 0.027 G_A: 0.465 cycle_A: 1.010 idt_A: 0.350 D_B: 0.112 G_B: 0.603 cycle_B: 0.916 idt_B: 0.323 \n",
            "(epoch: 23, iters: 1300, time: 1.088, data: 0.003) D_A: 0.213 G_A: 0.285 cycle_A: 1.542 idt_A: 0.307 D_B: 0.226 G_B: 0.465 cycle_B: 0.822 idt_B: 0.536 \n",
            "(epoch: 23, iters: 1400, time: 0.382, data: 0.006) D_A: 0.167 G_A: 0.256 cycle_A: 1.084 idt_A: 0.173 D_B: 0.096 G_B: 0.501 cycle_B: 0.603 idt_B: 0.417 \n",
            "(epoch: 23, iters: 1500, time: 0.291, data: 0.006) D_A: 0.079 G_A: 0.550 cycle_A: 1.707 idt_A: 0.206 D_B: 0.199 G_B: 0.406 cycle_B: 0.542 idt_B: 0.824 \n",
            "(epoch: 23, iters: 1600, time: 0.354, data: 0.003) D_A: 0.194 G_A: 0.341 cycle_A: 1.045 idt_A: 0.444 D_B: 0.282 G_B: 0.330 cycle_B: 1.027 idt_B: 0.405 \n",
            "(epoch: 23, iters: 1700, time: 1.095, data: 0.003) D_A: 0.046 G_A: 0.672 cycle_A: 0.794 idt_A: 0.441 D_B: 0.103 G_B: 0.309 cycle_B: 0.659 idt_B: 0.285 \n",
            "(epoch: 23, iters: 1800, time: 0.294, data: 0.005) D_A: 0.162 G_A: 0.344 cycle_A: 0.855 idt_A: 0.167 D_B: 0.104 G_B: 0.524 cycle_B: 0.747 idt_B: 0.327 \n",
            "(epoch: 23, iters: 1900, time: 0.349, data: 0.009) D_A: 0.150 G_A: 0.450 cycle_A: 0.614 idt_A: 0.201 D_B: 0.146 G_B: 0.325 cycle_B: 0.580 idt_B: 0.339 \n",
            "(epoch: 23, iters: 2000, time: 0.344, data: 0.011) D_A: 0.229 G_A: 0.700 cycle_A: 0.784 idt_A: 0.262 D_B: 0.173 G_B: 0.720 cycle_B: 0.666 idt_B: 0.278 \n",
            "(epoch: 23, iters: 2100, time: 1.193, data: 0.018) D_A: 0.111 G_A: 0.552 cycle_A: 0.875 idt_A: 0.126 D_B: 0.080 G_B: 0.218 cycle_B: 0.510 idt_B: 0.421 \n",
            "(epoch: 23, iters: 2200, time: 0.333, data: 0.003) D_A: 0.054 G_A: 0.390 cycle_A: 0.898 idt_A: 0.229 D_B: 0.077 G_B: 0.471 cycle_B: 0.630 idt_B: 0.390 \n",
            "(epoch: 23, iters: 2300, time: 0.359, data: 0.015) D_A: 0.118 G_A: 0.521 cycle_A: 0.769 idt_A: 0.148 D_B: 0.258 G_B: 0.173 cycle_B: 0.480 idt_B: 0.201 \n",
            "(epoch: 23, iters: 2400, time: 0.326, data: 0.006) D_A: 0.156 G_A: 0.354 cycle_A: 1.200 idt_A: 0.243 D_B: 0.112 G_B: 0.385 cycle_B: 0.695 idt_B: 0.431 \n",
            "(epoch: 23, iters: 2500, time: 2.217, data: 0.007) D_A: 0.399 G_A: 0.382 cycle_A: 0.989 idt_A: 0.172 D_B: 0.144 G_B: 0.344 cycle_B: 0.909 idt_B: 0.413 \n",
            "saving the latest model (epoch 23, total_iters 10000)\n",
            "End of epoch 23 / 60 \t Time Taken: 815 sec\n",
            "learning rate 0.0001805 -> 0.0001756\n",
            "(epoch: 24, iters: 100, time: 0.369, data: 1.336) D_A: 0.189 G_A: 0.364 cycle_A: 1.738 idt_A: 0.273 D_B: 0.147 G_B: 0.304 cycle_B: 0.776 idt_B: 0.765 \n",
            "(epoch: 24, iters: 200, time: 0.319, data: 0.016) D_A: 0.043 G_A: 0.395 cycle_A: 0.796 idt_A: 0.291 D_B: 0.164 G_B: 0.456 cycle_B: 0.753 idt_B: 0.303 \n",
            "(epoch: 24, iters: 300, time: 0.360, data: 0.003) D_A: 0.168 G_A: 0.490 cycle_A: 0.925 idt_A: 0.135 D_B: 0.276 G_B: 0.448 cycle_B: 0.473 idt_B: 0.356 \n",
            "(epoch: 24, iters: 400, time: 2.199, data: 0.006) D_A: 0.125 G_A: 0.334 cycle_A: 0.852 idt_A: 0.233 D_B: 0.045 G_B: 0.223 cycle_B: 0.618 idt_B: 0.341 \n",
            "(epoch: 24, iters: 500, time: 0.323, data: 0.003) D_A: 0.040 G_A: 0.889 cycle_A: 1.034 idt_A: 0.275 D_B: 0.192 G_B: 0.276 cycle_B: 0.684 idt_B: 0.508 \n",
            "(epoch: 24, iters: 600, time: 0.298, data: 0.003) D_A: 0.201 G_A: 0.237 cycle_A: 0.925 idt_A: 0.183 D_B: 0.160 G_B: 0.391 cycle_B: 0.506 idt_B: 0.311 \n",
            "(epoch: 24, iters: 700, time: 0.375, data: 0.005) D_A: 0.053 G_A: 0.482 cycle_A: 1.077 idt_A: 0.475 D_B: 0.054 G_B: 0.587 cycle_B: 1.057 idt_B: 0.356 \n",
            "(epoch: 24, iters: 800, time: 1.026, data: 0.004) D_A: 0.135 G_A: 0.753 cycle_A: 1.423 idt_A: 0.268 D_B: 0.140 G_B: 0.595 cycle_B: 0.805 idt_B: 0.346 \n",
            "(epoch: 24, iters: 900, time: 0.310, data: 0.012) D_A: 0.078 G_A: 0.848 cycle_A: 0.821 idt_A: 0.286 D_B: 0.032 G_B: 0.555 cycle_B: 0.632 idt_B: 0.376 \n",
            "(epoch: 24, iters: 1000, time: 0.310, data: 0.017) D_A: 0.108 G_A: 0.491 cycle_A: 0.968 idt_A: 0.368 D_B: 0.086 G_B: 0.377 cycle_B: 0.944 idt_B: 0.293 \n",
            "(epoch: 24, iters: 1100, time: 0.304, data: 0.003) D_A: 0.218 G_A: 0.181 cycle_A: 1.487 idt_A: 0.303 D_B: 0.247 G_B: 0.670 cycle_B: 0.883 idt_B: 0.402 \n",
            "(epoch: 24, iters: 1200, time: 1.062, data: 0.018) D_A: 0.141 G_A: 0.684 cycle_A: 0.899 idt_A: 0.623 D_B: 0.159 G_B: 0.200 cycle_B: 1.338 idt_B: 0.323 \n",
            "(epoch: 24, iters: 1300, time: 0.309, data: 0.020) D_A: 0.120 G_A: 0.780 cycle_A: 1.159 idt_A: 0.286 D_B: 0.078 G_B: 0.286 cycle_B: 0.805 idt_B: 0.430 \n",
            "(epoch: 24, iters: 1400, time: 0.326, data: 0.005) D_A: 0.351 G_A: 0.454 cycle_A: 1.000 idt_A: 0.344 D_B: 0.220 G_B: 0.383 cycle_B: 0.940 idt_B: 0.340 \n",
            "(epoch: 24, iters: 1500, time: 0.305, data: 0.006) D_A: 0.270 G_A: 0.791 cycle_A: 0.829 idt_A: 0.236 D_B: 0.146 G_B: 0.330 cycle_B: 0.671 idt_B: 0.222 \n",
            "(epoch: 24, iters: 1600, time: 1.085, data: 0.003) D_A: 0.060 G_A: 0.391 cycle_A: 1.259 idt_A: 0.267 D_B: 0.212 G_B: 0.500 cycle_B: 0.753 idt_B: 0.300 \n",
            "(epoch: 24, iters: 1700, time: 0.301, data: 0.005) D_A: 0.151 G_A: 0.656 cycle_A: 1.303 idt_A: 0.201 D_B: 0.114 G_B: 0.345 cycle_B: 0.757 idt_B: 0.410 \n",
            "(epoch: 24, iters: 1800, time: 0.306, data: 0.011) D_A: 0.147 G_A: 0.194 cycle_A: 0.899 idt_A: 0.218 D_B: 0.113 G_B: 0.741 cycle_B: 0.621 idt_B: 0.274 \n",
            "(epoch: 24, iters: 1900, time: 0.323, data: 0.003) D_A: 0.092 G_A: 0.561 cycle_A: 0.962 idt_A: 0.230 D_B: 0.078 G_B: 0.372 cycle_B: 0.900 idt_B: 0.377 \n",
            "(epoch: 24, iters: 2000, time: 1.926, data: 0.003) D_A: 0.076 G_A: 0.486 cycle_A: 1.197 idt_A: 0.268 D_B: 0.084 G_B: 0.386 cycle_B: 0.766 idt_B: 0.642 \n",
            "(epoch: 24, iters: 2100, time: 0.329, data: 0.007) D_A: 0.169 G_A: 0.342 cycle_A: 1.194 idt_A: 0.182 D_B: 0.247 G_B: 0.330 cycle_B: 0.525 idt_B: 0.432 \n",
            "(epoch: 24, iters: 2200, time: 0.328, data: 0.005) D_A: 0.099 G_A: 0.425 cycle_A: 1.218 idt_A: 0.258 D_B: 0.116 G_B: 1.008 cycle_B: 0.827 idt_B: 0.430 \n",
            "(epoch: 24, iters: 2300, time: 0.340, data: 0.003) D_A: 0.056 G_A: 0.786 cycle_A: 0.974 idt_A: 0.276 D_B: 0.164 G_B: 0.882 cycle_B: 0.566 idt_B: 0.388 \n",
            "(epoch: 24, iters: 2400, time: 1.037, data: 0.008) D_A: 0.237 G_A: 0.383 cycle_A: 1.339 idt_A: 0.284 D_B: 0.135 G_B: 0.330 cycle_B: 0.746 idt_B: 0.457 \n",
            "(epoch: 24, iters: 2500, time: 0.309, data: 0.004) D_A: 0.113 G_A: 0.320 cycle_A: 1.065 idt_A: 0.249 D_B: 0.066 G_B: 0.736 cycle_B: 0.746 idt_B: 0.420 \n",
            "End of epoch 24 / 60 \t Time Taken: 811 sec\n",
            "learning rate 0.0001756 -> 0.0001707\n",
            "(epoch: 25, iters: 100, time: 0.298, data: 0.962) D_A: 0.139 G_A: 0.345 cycle_A: 0.829 idt_A: 0.374 D_B: 0.219 G_B: 0.290 cycle_B: 0.987 idt_B: 0.278 \n",
            "(epoch: 25, iters: 200, time: 0.308, data: 0.012) D_A: 0.299 G_A: 0.379 cycle_A: 0.641 idt_A: 0.408 D_B: 0.192 G_B: 0.362 cycle_B: 1.098 idt_B: 0.245 \n",
            "(epoch: 25, iters: 300, time: 2.280, data: 0.005) D_A: 0.178 G_A: 0.458 cycle_A: 1.082 idt_A: 0.271 D_B: 0.076 G_B: 0.145 cycle_B: 0.552 idt_B: 0.391 \n",
            "(epoch: 25, iters: 400, time: 0.353, data: 0.003) D_A: 0.123 G_A: 0.501 cycle_A: 1.204 idt_A: 0.159 D_B: 0.121 G_B: 0.130 cycle_B: 0.442 idt_B: 0.326 \n",
            "(epoch: 25, iters: 500, time: 0.305, data: 0.003) D_A: 0.152 G_A: 0.370 cycle_A: 1.095 idt_A: 0.272 D_B: 0.281 G_B: 0.857 cycle_B: 0.709 idt_B: 0.315 \n",
            "(epoch: 25, iters: 600, time: 0.342, data: 0.019) D_A: 0.211 G_A: 0.183 cycle_A: 0.780 idt_A: 0.156 D_B: 0.116 G_B: 0.367 cycle_B: 0.529 idt_B: 0.196 \n",
            "(epoch: 25, iters: 700, time: 1.323, data: 0.009) D_A: 0.089 G_A: 0.308 cycle_A: 0.887 idt_A: 0.149 D_B: 0.209 G_B: 0.670 cycle_B: 0.546 idt_B: 0.284 \n",
            "(epoch: 25, iters: 800, time: 0.308, data: 0.004) D_A: 0.065 G_A: 0.432 cycle_A: 1.184 idt_A: 0.163 D_B: 0.150 G_B: 0.344 cycle_B: 0.445 idt_B: 0.368 \n",
            "(epoch: 25, iters: 900, time: 0.359, data: 0.019) D_A: 0.039 G_A: 0.747 cycle_A: 0.545 idt_A: 0.367 D_B: 0.131 G_B: 0.604 cycle_B: 1.059 idt_B: 0.178 \n",
            "(epoch: 25, iters: 1000, time: 0.314, data: 0.003) D_A: 0.076 G_A: 0.367 cycle_A: 1.264 idt_A: 0.278 D_B: 0.253 G_B: 0.744 cycle_B: 0.626 idt_B: 0.457 \n",
            "(epoch: 25, iters: 1100, time: 1.122, data: 0.004) D_A: 0.156 G_A: 0.337 cycle_A: 0.645 idt_A: 0.308 D_B: 0.151 G_B: 0.751 cycle_B: 0.856 idt_B: 0.203 \n",
            "(epoch: 25, iters: 1200, time: 0.385, data: 0.002) D_A: 0.185 G_A: 0.419 cycle_A: 1.087 idt_A: 0.141 D_B: 0.134 G_B: 0.516 cycle_B: 0.696 idt_B: 0.449 \n",
            "(epoch: 25, iters: 1300, time: 0.321, data: 0.022) D_A: 0.172 G_A: 0.722 cycle_A: 2.091 idt_A: 0.142 D_B: 0.201 G_B: 0.420 cycle_B: 0.611 idt_B: 0.881 \n",
            "(epoch: 25, iters: 1400, time: 0.340, data: 0.023) D_A: 0.123 G_A: 0.444 cycle_A: 1.023 idt_A: 0.205 D_B: 0.123 G_B: 0.321 cycle_B: 0.475 idt_B: 0.423 \n",
            "(epoch: 25, iters: 1500, time: 1.889, data: 0.005) D_A: 0.107 G_A: 0.669 cycle_A: 1.190 idt_A: 0.361 D_B: 0.236 G_B: 0.163 cycle_B: 1.097 idt_B: 0.375 \n",
            "(epoch: 25, iters: 1600, time: 0.327, data: 0.006) D_A: 0.115 G_A: 0.323 cycle_A: 0.841 idt_A: 0.343 D_B: 0.049 G_B: 0.473 cycle_B: 0.753 idt_B: 0.361 \n",
            "(epoch: 25, iters: 1700, time: 0.298, data: 0.004) D_A: 0.167 G_A: 0.408 cycle_A: 0.747 idt_A: 0.128 D_B: 0.252 G_B: 0.435 cycle_B: 0.443 idt_B: 0.220 \n",
            "(epoch: 25, iters: 1800, time: 0.310, data: 0.001) D_A: 0.077 G_A: 0.798 cycle_A: 0.743 idt_A: 0.239 D_B: 0.314 G_B: 0.607 cycle_B: 0.456 idt_B: 0.244 \n",
            "(epoch: 25, iters: 1900, time: 1.134, data: 0.004) D_A: 0.135 G_A: 0.748 cycle_A: 0.894 idt_A: 0.190 D_B: 0.178 G_B: 0.267 cycle_B: 0.651 idt_B: 0.260 \n",
            "(epoch: 25, iters: 2000, time: 0.311, data: 0.004) D_A: 0.083 G_A: 0.845 cycle_A: 0.892 idt_A: 0.190 D_B: 0.151 G_B: 0.475 cycle_B: 0.649 idt_B: 0.406 \n",
            "(epoch: 25, iters: 2100, time: 0.316, data: 0.012) D_A: 0.117 G_A: 1.423 cycle_A: 1.176 idt_A: 0.283 D_B: 0.303 G_B: 0.134 cycle_B: 0.837 idt_B: 0.388 \n",
            "(epoch: 25, iters: 2200, time: 0.368, data: 0.009) D_A: 0.175 G_A: 0.474 cycle_A: 1.410 idt_A: 0.387 D_B: 0.074 G_B: 0.671 cycle_B: 0.914 idt_B: 0.375 \n",
            "(epoch: 25, iters: 2300, time: 1.188, data: 0.019) D_A: 0.070 G_A: 0.985 cycle_A: 1.631 idt_A: 0.379 D_B: 0.104 G_B: 0.595 cycle_B: 1.147 idt_B: 0.571 \n",
            "(epoch: 25, iters: 2400, time: 0.337, data: 0.003) D_A: 0.069 G_A: 0.480 cycle_A: 0.957 idt_A: 0.489 D_B: 0.084 G_B: 0.648 cycle_B: 0.925 idt_B: 0.222 \n",
            "(epoch: 25, iters: 2500, time: 0.310, data: 0.006) D_A: 0.055 G_A: 0.523 cycle_A: 0.904 idt_A: 0.295 D_B: 0.124 G_B: 0.381 cycle_B: 0.786 idt_B: 0.320 \n",
            "saving the latest model (epoch 25, total_iters 15000)\n",
            "saving the model at the end of epoch 25, iters 15000\n",
            "End of epoch 25 / 60 \t Time Taken: 815 sec\n",
            "learning rate 0.0001707 -> 0.0001659\n",
            "(epoch: 26, iters: 100, time: 0.335, data: 1.052) D_A: 0.032 G_A: 0.899 cycle_A: 1.032 idt_A: 0.236 D_B: 0.212 G_B: 0.463 cycle_B: 0.547 idt_B: 0.328 \n",
            "(epoch: 26, iters: 200, time: 2.181, data: 0.006) D_A: 0.147 G_A: 0.597 cycle_A: 0.884 idt_A: 0.235 D_B: 0.160 G_B: 0.375 cycle_B: 0.628 idt_B: 0.288 \n",
            "(epoch: 26, iters: 300, time: 0.304, data: 0.006) D_A: 0.069 G_A: 0.537 cycle_A: 1.028 idt_A: 0.184 D_B: 0.246 G_B: 0.450 cycle_B: 0.497 idt_B: 0.221 \n",
            "(epoch: 26, iters: 400, time: 0.308, data: 0.012) D_A: 0.058 G_A: 0.579 cycle_A: 1.079 idt_A: 0.263 D_B: 0.355 G_B: 0.525 cycle_B: 0.737 idt_B: 0.367 \n",
            "(epoch: 26, iters: 500, time: 0.311, data: 0.003) D_A: 0.054 G_A: 0.209 cycle_A: 1.083 idt_A: 0.263 D_B: 0.131 G_B: 0.555 cycle_B: 0.953 idt_B: 0.393 \n",
            "(epoch: 26, iters: 600, time: 1.170, data: 0.020) D_A: 0.054 G_A: 0.319 cycle_A: 0.829 idt_A: 0.162 D_B: 0.302 G_B: 0.437 cycle_B: 0.579 idt_B: 0.286 \n",
            "(epoch: 26, iters: 700, time: 0.329, data: 0.004) D_A: 0.085 G_A: 0.434 cycle_A: 0.846 idt_A: 0.174 D_B: 0.159 G_B: 1.010 cycle_B: 0.523 idt_B: 0.332 \n",
            "(epoch: 26, iters: 800, time: 0.359, data: 0.020) D_A: 0.248 G_A: 0.505 cycle_A: 1.200 idt_A: 0.475 D_B: 0.118 G_B: 0.470 cycle_B: 1.129 idt_B: 0.615 \n",
            "(epoch: 26, iters: 900, time: 0.307, data: 0.006) D_A: 0.201 G_A: 0.221 cycle_A: 1.573 idt_A: 0.241 D_B: 0.256 G_B: 0.753 cycle_B: 0.616 idt_B: 1.334 \n",
            "(epoch: 26, iters: 1000, time: 1.942, data: 0.023) D_A: 0.206 G_A: 0.124 cycle_A: 0.937 idt_A: 0.298 D_B: 0.258 G_B: 0.378 cycle_B: 0.671 idt_B: 0.327 \n",
            "(epoch: 26, iters: 1100, time: 0.307, data: 0.005) D_A: 0.241 G_A: 0.973 cycle_A: 1.267 idt_A: 0.179 D_B: 0.239 G_B: 0.587 cycle_B: 0.577 idt_B: 0.515 \n",
            "(epoch: 26, iters: 1200, time: 0.326, data: 0.011) D_A: 0.077 G_A: 0.532 cycle_A: 1.902 idt_A: 0.252 D_B: 0.211 G_B: 0.582 cycle_B: 0.766 idt_B: 0.701 \n",
            "(epoch: 26, iters: 1300, time: 0.308, data: 0.003) D_A: 0.099 G_A: 0.440 cycle_A: 0.963 idt_A: 0.321 D_B: 0.181 G_B: 0.762 cycle_B: 0.830 idt_B: 0.300 \n",
            "(epoch: 26, iters: 1400, time: 1.135, data: 0.017) D_A: 0.051 G_A: 0.648 cycle_A: 1.341 idt_A: 0.292 D_B: 0.248 G_B: 0.385 cycle_B: 0.781 idt_B: 0.501 \n",
            "(epoch: 26, iters: 1500, time: 0.312, data: 0.003) D_A: 0.084 G_A: 0.492 cycle_A: 1.330 idt_A: 0.297 D_B: 0.147 G_B: 0.354 cycle_B: 0.756 idt_B: 0.333 \n",
            "(epoch: 26, iters: 1600, time: 0.314, data: 0.003) D_A: 0.066 G_A: 1.399 cycle_A: 1.749 idt_A: 0.352 D_B: 0.198 G_B: 0.238 cycle_B: 0.952 idt_B: 0.735 \n",
            "(epoch: 26, iters: 1700, time: 0.306, data: 0.007) D_A: 0.188 G_A: 0.247 cycle_A: 0.895 idt_A: 0.245 D_B: 0.099 G_B: 0.797 cycle_B: 0.637 idt_B: 0.324 \n",
            "(epoch: 26, iters: 1800, time: 1.086, data: 0.003) D_A: 0.348 G_A: 0.714 cycle_A: 0.914 idt_A: 0.289 D_B: 0.189 G_B: 0.512 cycle_B: 0.729 idt_B: 0.299 \n",
            "(epoch: 26, iters: 1900, time: 0.312, data: 0.004) D_A: 0.128 G_A: 0.304 cycle_A: 1.943 idt_A: 0.305 D_B: 0.109 G_B: 0.517 cycle_B: 1.133 idt_B: 0.799 \n",
            "(epoch: 26, iters: 2000, time: 0.327, data: 0.011) D_A: 0.077 G_A: 0.807 cycle_A: 1.501 idt_A: 0.251 D_B: 0.149 G_B: 0.511 cycle_B: 0.735 idt_B: 0.559 \n",
            "(epoch: 26, iters: 2100, time: 0.310, data: 0.006) D_A: 0.027 G_A: 0.818 cycle_A: 1.357 idt_A: 0.234 D_B: 0.047 G_B: 0.522 cycle_B: 0.763 idt_B: 0.673 \n",
            "(epoch: 26, iters: 2200, time: 1.161, data: 0.015) D_A: 0.057 G_A: 0.770 cycle_A: 1.155 idt_A: 0.196 D_B: 0.116 G_B: 0.623 cycle_B: 0.534 idt_B: 0.481 \n",
            "(epoch: 26, iters: 2300, time: 0.466, data: 0.007) D_A: 0.069 G_A: 0.161 cycle_A: 1.045 idt_A: 0.217 D_B: 0.029 G_B: 0.334 cycle_B: 0.711 idt_B: 0.403 \n",
            "(epoch: 26, iters: 2400, time: 0.334, data: 0.019) D_A: 0.269 G_A: 0.660 cycle_A: 0.933 idt_A: 0.294 D_B: 0.093 G_B: 0.314 cycle_B: 0.726 idt_B: 0.254 \n",
            "(epoch: 26, iters: 2500, time: 0.310, data: 0.013) D_A: 0.105 G_A: 0.694 cycle_A: 0.878 idt_A: 0.164 D_B: 0.242 G_B: 0.309 cycle_B: 0.477 idt_B: 0.381 \n",
            "End of epoch 26 / 60 \t Time Taken: 814 sec\n",
            "learning rate 0.0001659 -> 0.0001610\n",
            "(epoch: 27, iters: 100, time: 2.211, data: 0.990) D_A: 0.188 G_A: 0.472 cycle_A: 1.519 idt_A: 0.268 D_B: 0.092 G_B: 0.206 cycle_B: 0.689 idt_B: 0.656 \n",
            "(epoch: 27, iters: 200, time: 0.292, data: 0.006) D_A: 0.131 G_A: 0.413 cycle_A: 0.953 idt_A: 0.270 D_B: 0.120 G_B: 0.343 cycle_B: 0.551 idt_B: 0.242 \n",
            "(epoch: 27, iters: 300, time: 0.362, data: 0.016) D_A: 0.124 G_A: 0.354 cycle_A: 0.854 idt_A: 0.149 D_B: 0.148 G_B: 0.446 cycle_B: 0.514 idt_B: 0.281 \n",
            "(epoch: 27, iters: 400, time: 0.297, data: 0.013) D_A: 0.120 G_A: 0.557 cycle_A: 0.880 idt_A: 0.255 D_B: 0.156 G_B: 0.480 cycle_B: 0.870 idt_B: 0.379 \n",
            "(epoch: 27, iters: 500, time: 2.074, data: 0.005) D_A: 0.136 G_A: 0.132 cycle_A: 0.948 idt_A: 0.226 D_B: 0.320 G_B: 0.529 cycle_B: 0.685 idt_B: 0.323 \n",
            "(epoch: 27, iters: 600, time: 0.341, data: 0.008) D_A: 0.093 G_A: 0.803 cycle_A: 1.056 idt_A: 0.203 D_B: 0.184 G_B: 0.237 cycle_B: 0.761 idt_B: 0.351 \n",
            "(epoch: 27, iters: 700, time: 0.356, data: 0.015) D_A: 0.110 G_A: 0.317 cycle_A: 1.286 idt_A: 0.324 D_B: 0.193 G_B: 0.624 cycle_B: 0.923 idt_B: 0.377 \n",
            "(epoch: 27, iters: 800, time: 0.292, data: 0.023) D_A: 0.201 G_A: 0.128 cycle_A: 0.863 idt_A: 0.207 D_B: 0.247 G_B: 0.195 cycle_B: 0.458 idt_B: 0.230 \n",
            "(epoch: 27, iters: 900, time: 1.011, data: 0.013) D_A: 0.102 G_A: 1.149 cycle_A: 0.712 idt_A: 0.161 D_B: 0.098 G_B: 0.453 cycle_B: 0.757 idt_B: 0.215 \n",
            "(epoch: 27, iters: 1000, time: 0.307, data: 0.004) D_A: 0.083 G_A: 0.482 cycle_A: 1.110 idt_A: 0.212 D_B: 0.279 G_B: 0.117 cycle_B: 0.560 idt_B: 0.430 \n",
            "(epoch: 27, iters: 1100, time: 0.320, data: 0.003) D_A: 0.132 G_A: 0.386 cycle_A: 1.349 idt_A: 0.344 D_B: 0.134 G_B: 0.363 cycle_B: 0.833 idt_B: 0.616 \n",
            "(epoch: 27, iters: 1200, time: 0.321, data: 0.007) D_A: 0.097 G_A: 0.660 cycle_A: 0.999 idt_A: 0.159 D_B: 0.110 G_B: 0.253 cycle_B: 0.457 idt_B: 0.351 \n",
            "(epoch: 27, iters: 1300, time: 1.010, data: 0.011) D_A: 0.130 G_A: 0.406 cycle_A: 0.974 idt_A: 0.450 D_B: 0.162 G_B: 0.443 cycle_B: 1.114 idt_B: 0.232 \n",
            "(epoch: 27, iters: 1400, time: 0.307, data: 0.004) D_A: 0.225 G_A: 0.341 cycle_A: 1.155 idt_A: 0.423 D_B: 0.182 G_B: 0.434 cycle_B: 1.104 idt_B: 0.481 \n",
            "(epoch: 27, iters: 1500, time: 0.403, data: 0.001) D_A: 0.063 G_A: 0.577 cycle_A: 0.747 idt_A: 0.409 D_B: 0.189 G_B: 0.331 cycle_B: 0.884 idt_B: 0.174 \n",
            "(epoch: 27, iters: 1600, time: 0.308, data: 0.022) D_A: 0.123 G_A: 0.552 cycle_A: 0.927 idt_A: 0.489 D_B: 0.112 G_B: 0.572 cycle_B: 1.159 idt_B: 0.278 \n",
            "(epoch: 27, iters: 1700, time: 1.178, data: 0.006) D_A: 0.122 G_A: 0.489 cycle_A: 1.318 idt_A: 0.166 D_B: 0.248 G_B: 0.208 cycle_B: 0.422 idt_B: 0.552 \n",
            "(epoch: 27, iters: 1800, time: 0.350, data: 0.005) D_A: 0.108 G_A: 0.370 cycle_A: 0.847 idt_A: 0.178 D_B: 0.172 G_B: 0.241 cycle_B: 0.769 idt_B: 0.279 \n",
            "(epoch: 27, iters: 1900, time: 0.307, data: 0.004) D_A: 0.190 G_A: 0.214 cycle_A: 1.055 idt_A: 0.227 D_B: 0.062 G_B: 0.754 cycle_B: 0.716 idt_B: 0.336 \n",
            "(epoch: 27, iters: 2000, time: 0.381, data: 0.003) D_A: 0.166 G_A: 1.123 cycle_A: 0.899 idt_A: 0.185 D_B: 0.087 G_B: 0.151 cycle_B: 0.554 idt_B: 0.309 \n",
            "(epoch: 27, iters: 2100, time: 1.140, data: 0.003) D_A: 0.142 G_A: 0.337 cycle_A: 0.748 idt_A: 0.325 D_B: 0.170 G_B: 0.904 cycle_B: 0.661 idt_B: 0.264 \n",
            "(epoch: 27, iters: 2200, time: 0.325, data: 0.005) D_A: 0.037 G_A: 0.494 cycle_A: 0.796 idt_A: 0.336 D_B: 0.177 G_B: 0.318 cycle_B: 0.650 idt_B: 0.391 \n",
            "(epoch: 27, iters: 2300, time: 0.306, data: 0.001) D_A: 0.050 G_A: 0.740 cycle_A: 1.278 idt_A: 0.346 D_B: 0.076 G_B: 0.502 cycle_B: 0.809 idt_B: 0.525 \n",
            "(epoch: 27, iters: 2400, time: 0.353, data: 0.004) D_A: 0.061 G_A: 0.694 cycle_A: 1.269 idt_A: 0.390 D_B: 0.177 G_B: 0.237 cycle_B: 0.701 idt_B: 0.502 \n",
            "(epoch: 27, iters: 2500, time: 1.790, data: 0.005) D_A: 0.187 G_A: 0.362 cycle_A: 0.812 idt_A: 0.185 D_B: 0.277 G_B: 0.231 cycle_B: 0.515 idt_B: 0.245 \n",
            "saving the latest model (epoch 27, total_iters 20000)\n",
            "End of epoch 27 / 60 \t Time Taken: 820 sec\n",
            "learning rate 0.0001610 -> 0.0001561\n",
            "(epoch: 28, iters: 100, time: 0.346, data: 1.469) D_A: 0.129 G_A: 0.533 cycle_A: 1.116 idt_A: 0.146 D_B: 0.192 G_B: 0.461 cycle_B: 0.312 idt_B: 0.403 \n",
            "(epoch: 28, iters: 200, time: 0.343, data: 0.003) D_A: 0.104 G_A: 0.433 cycle_A: 1.027 idt_A: 0.187 D_B: 0.135 G_B: 0.122 cycle_B: 0.632 idt_B: 0.391 \n",
            "(epoch: 28, iters: 300, time: 0.306, data: 0.018) D_A: 0.048 G_A: 0.339 cycle_A: 1.177 idt_A: 0.329 D_B: 0.212 G_B: 0.544 cycle_B: 0.613 idt_B: 0.453 \n",
            "(epoch: 28, iters: 400, time: 2.479, data: 0.012) D_A: 0.157 G_A: 0.380 cycle_A: 0.824 idt_A: 0.334 D_B: 0.235 G_B: 0.577 cycle_B: 0.839 idt_B: 0.269 \n",
            "(epoch: 28, iters: 500, time: 0.305, data: 0.012) D_A: 0.073 G_A: 1.002 cycle_A: 1.083 idt_A: 0.233 D_B: 0.142 G_B: 0.258 cycle_B: 0.656 idt_B: 0.405 \n",
            "(epoch: 28, iters: 600, time: 0.369, data: 0.021) D_A: 0.250 G_A: 0.148 cycle_A: 1.333 idt_A: 0.353 D_B: 0.225 G_B: 0.458 cycle_B: 0.813 idt_B: 0.377 \n",
            "(epoch: 28, iters: 700, time: 0.325, data: 0.024) D_A: 0.096 G_A: 0.375 cycle_A: 1.202 idt_A: 0.116 D_B: 0.425 G_B: 0.824 cycle_B: 0.418 idt_B: 0.443 \n",
            "(epoch: 28, iters: 800, time: 1.163, data: 0.022) D_A: 0.167 G_A: 0.277 cycle_A: 0.934 idt_A: 0.205 D_B: 0.292 G_B: 0.156 cycle_B: 0.693 idt_B: 0.339 \n",
            "(epoch: 28, iters: 900, time: 0.322, data: 0.005) D_A: 0.115 G_A: 0.655 cycle_A: 0.969 idt_A: 0.144 D_B: 0.250 G_B: 0.783 cycle_B: 0.490 idt_B: 0.444 \n",
            "(epoch: 28, iters: 1000, time: 0.376, data: 0.007) D_A: 0.143 G_A: 0.532 cycle_A: 2.391 idt_A: 0.379 D_B: 0.081 G_B: 0.613 cycle_B: 0.938 idt_B: 0.794 \n",
            "(epoch: 28, iters: 1100, time: 0.370, data: 0.007) D_A: 0.221 G_A: 0.319 cycle_A: 0.771 idt_A: 0.521 D_B: 0.069 G_B: 0.813 cycle_B: 0.818 idt_B: 0.317 \n",
            "(epoch: 28, iters: 1200, time: 1.102, data: 0.011) D_A: 0.142 G_A: 0.114 cycle_A: 0.946 idt_A: 0.310 D_B: 0.158 G_B: 0.214 cycle_B: 0.951 idt_B: 0.316 \n",
            "(epoch: 28, iters: 1300, time: 0.306, data: 0.004) D_A: 0.148 G_A: 0.469 cycle_A: 2.059 idt_A: 0.223 D_B: 0.237 G_B: 0.216 cycle_B: 0.611 idt_B: 0.973 \n",
            "(epoch: 28, iters: 1400, time: 0.304, data: 0.006) D_A: 0.055 G_A: 0.554 cycle_A: 1.138 idt_A: 0.145 D_B: 0.285 G_B: 0.297 cycle_B: 0.538 idt_B: 0.402 \n",
            "(epoch: 28, iters: 1500, time: 0.455, data: 0.004) D_A: 0.243 G_A: 0.282 cycle_A: 0.641 idt_A: 0.354 D_B: 0.090 G_B: 0.417 cycle_B: 0.500 idt_B: 0.204 \n",
            "(epoch: 28, iters: 1600, time: 1.287, data: 0.007) D_A: 0.111 G_A: 0.490 cycle_A: 0.812 idt_A: 0.177 D_B: 0.221 G_B: 0.303 cycle_B: 0.560 idt_B: 0.180 \n",
            "(epoch: 28, iters: 1700, time: 0.302, data: 0.002) D_A: 0.179 G_A: 1.159 cycle_A: 0.762 idt_A: 0.175 D_B: 0.283 G_B: 0.100 cycle_B: 0.711 idt_B: 0.274 \n",
            "(epoch: 28, iters: 1800, time: 0.292, data: 0.002) D_A: 0.308 G_A: 0.329 cycle_A: 0.766 idt_A: 0.266 D_B: 0.186 G_B: 0.321 cycle_B: 0.860 idt_B: 0.254 \n",
            "(epoch: 28, iters: 1900, time: 0.335, data: 0.003) D_A: 0.098 G_A: 0.756 cycle_A: 1.275 idt_A: 0.290 D_B: 0.028 G_B: 0.630 cycle_B: 0.859 idt_B: 0.847 \n",
            "(epoch: 28, iters: 2000, time: 1.981, data: 0.021) D_A: 0.095 G_A: 0.226 cycle_A: 0.931 idt_A: 0.174 D_B: 0.133 G_B: 0.387 cycle_B: 0.563 idt_B: 0.269 \n",
            "(epoch: 28, iters: 2100, time: 0.314, data: 0.005) D_A: 0.136 G_A: 0.463 cycle_A: 0.755 idt_A: 0.220 D_B: 0.162 G_B: 0.250 cycle_B: 0.609 idt_B: 0.285 \n",
            "(epoch: 28, iters: 2200, time: 0.307, data: 0.007) D_A: 0.296 G_A: 0.366 cycle_A: 1.207 idt_A: 0.308 D_B: 0.262 G_B: 0.480 cycle_B: 0.596 idt_B: 0.360 \n",
            "(epoch: 28, iters: 2300, time: 0.326, data: 0.008) D_A: 0.076 G_A: 0.713 cycle_A: 0.964 idt_A: 0.217 D_B: 0.115 G_B: 0.520 cycle_B: 0.648 idt_B: 0.369 \n",
            "(epoch: 28, iters: 2400, time: 1.140, data: 0.004) D_A: 0.313 G_A: 0.288 cycle_A: 0.878 idt_A: 0.244 D_B: 0.148 G_B: 0.618 cycle_B: 0.701 idt_B: 0.284 \n",
            "(epoch: 28, iters: 2500, time: 0.311, data: 0.001) D_A: 0.208 G_A: 0.852 cycle_A: 0.916 idt_A: 0.147 D_B: 0.132 G_B: 0.163 cycle_B: 0.460 idt_B: 0.296 \n",
            "End of epoch 28 / 60 \t Time Taken: 817 sec\n",
            "learning rate 0.0001561 -> 0.0001512\n",
            "(epoch: 29, iters: 100, time: 0.325, data: 1.003) D_A: 0.122 G_A: 0.380 cycle_A: 0.751 idt_A: 0.253 D_B: 0.188 G_B: 0.352 cycle_B: 0.692 idt_B: 0.282 \n",
            "(epoch: 29, iters: 200, time: 0.338, data: 0.019) D_A: 0.159 G_A: 0.516 cycle_A: 1.865 idt_A: 0.314 D_B: 0.037 G_B: 0.936 cycle_B: 0.950 idt_B: 0.479 \n",
            "(epoch: 29, iters: 300, time: 2.359, data: 0.008) D_A: 0.100 G_A: 0.562 cycle_A: 1.502 idt_A: 0.240 D_B: 0.234 G_B: 0.809 cycle_B: 0.675 idt_B: 0.358 \n",
            "(epoch: 29, iters: 400, time: 0.306, data: 0.007) D_A: 0.027 G_A: 0.476 cycle_A: 1.151 idt_A: 0.128 D_B: 0.140 G_B: 0.634 cycle_B: 0.504 idt_B: 0.328 \n",
            "(epoch: 29, iters: 500, time: 0.298, data: 0.006) D_A: 0.203 G_A: 0.488 cycle_A: 0.909 idt_A: 0.220 D_B: 0.162 G_B: 0.225 cycle_B: 0.581 idt_B: 0.261 \n",
            "(epoch: 29, iters: 600, time: 0.321, data: 0.003) D_A: 0.302 G_A: 0.354 cycle_A: 1.072 idt_A: 0.263 D_B: 0.083 G_B: 0.423 cycle_B: 0.748 idt_B: 0.555 \n",
            "(epoch: 29, iters: 700, time: 1.032, data: 0.007) D_A: 0.185 G_A: 0.213 cycle_A: 0.963 idt_A: 0.136 D_B: 0.055 G_B: 0.364 cycle_B: 0.466 idt_B: 0.353 \n",
            "(epoch: 29, iters: 800, time: 0.316, data: 0.004) D_A: 0.128 G_A: 0.417 cycle_A: 0.887 idt_A: 0.150 D_B: 0.038 G_B: 0.284 cycle_B: 0.389 idt_B: 0.294 \n",
            "(epoch: 29, iters: 900, time: 0.342, data: 0.011) D_A: 0.183 G_A: 0.309 cycle_A: 0.993 idt_A: 0.228 D_B: 0.132 G_B: 0.354 cycle_B: 0.667 idt_B: 0.612 \n",
            "(epoch: 29, iters: 1000, time: 0.308, data: 0.004) D_A: 0.296 G_A: 0.168 cycle_A: 1.602 idt_A: 0.369 D_B: 0.293 G_B: 0.117 cycle_B: 0.867 idt_B: 0.676 \n",
            "(epoch: 29, iters: 1100, time: 1.058, data: 0.011) D_A: 0.237 G_A: 0.305 cycle_A: 1.065 idt_A: 0.275 D_B: 0.129 G_B: 0.380 cycle_B: 0.794 idt_B: 0.321 \n",
            "(epoch: 29, iters: 1200, time: 0.321, data: 0.004) D_A: 0.149 G_A: 0.290 cycle_A: 1.233 idt_A: 0.359 D_B: 0.101 G_B: 0.388 cycle_B: 0.688 idt_B: 0.587 \n",
            "(epoch: 29, iters: 1300, time: 0.360, data: 0.001) D_A: 0.117 G_A: 0.504 cycle_A: 0.968 idt_A: 0.201 D_B: 0.320 G_B: 0.105 cycle_B: 0.630 idt_B: 0.627 \n",
            "(epoch: 29, iters: 1400, time: 0.310, data: 0.016) D_A: 0.140 G_A: 0.155 cycle_A: 0.773 idt_A: 0.361 D_B: 0.084 G_B: 0.220 cycle_B: 0.991 idt_B: 0.215 \n",
            "(epoch: 29, iters: 1500, time: 1.958, data: 0.024) D_A: 0.151 G_A: 0.278 cycle_A: 0.771 idt_A: 0.226 D_B: 0.186 G_B: 0.209 cycle_B: 0.647 idt_B: 0.239 \n",
            "(epoch: 29, iters: 1600, time: 0.333, data: 0.005) D_A: 0.052 G_A: 0.618 cycle_A: 0.859 idt_A: 0.187 D_B: 0.111 G_B: 0.474 cycle_B: 0.677 idt_B: 0.301 \n",
            "(epoch: 29, iters: 1700, time: 0.307, data: 0.003) D_A: 0.212 G_A: 0.207 cycle_A: 1.314 idt_A: 0.185 D_B: 0.270 G_B: 0.123 cycle_B: 0.675 idt_B: 0.617 \n",
            "(epoch: 29, iters: 1800, time: 0.324, data: 0.019) D_A: 0.177 G_A: 0.299 cycle_A: 1.016 idt_A: 0.295 D_B: 0.344 G_B: 0.540 cycle_B: 0.851 idt_B: 0.374 \n",
            "(epoch: 29, iters: 1900, time: 1.015, data: 0.006) D_A: 0.252 G_A: 0.362 cycle_A: 1.182 idt_A: 0.210 D_B: 0.179 G_B: 0.437 cycle_B: 0.620 idt_B: 0.222 \n",
            "(epoch: 29, iters: 2000, time: 0.305, data: 0.004) D_A: 0.119 G_A: 0.391 cycle_A: 1.031 idt_A: 0.140 D_B: 0.095 G_B: 0.535 cycle_B: 0.452 idt_B: 0.369 \n",
            "(epoch: 29, iters: 2100, time: 0.312, data: 0.023) D_A: 0.073 G_A: 0.860 cycle_A: 1.241 idt_A: 0.193 D_B: 0.124 G_B: 0.576 cycle_B: 0.604 idt_B: 0.348 \n",
            "(epoch: 29, iters: 2200, time: 0.315, data: 0.006) D_A: 0.230 G_A: 0.481 cycle_A: 0.837 idt_A: 0.240 D_B: 0.108 G_B: 0.284 cycle_B: 0.745 idt_B: 0.316 \n",
            "(epoch: 29, iters: 2300, time: 0.989, data: 0.018) D_A: 0.101 G_A: 0.652 cycle_A: 1.198 idt_A: 0.187 D_B: 0.200 G_B: 0.095 cycle_B: 0.630 idt_B: 0.460 \n",
            "(epoch: 29, iters: 2400, time: 0.307, data: 0.003) D_A: 0.052 G_A: 0.852 cycle_A: 0.841 idt_A: 0.348 D_B: 0.315 G_B: 0.419 cycle_B: 0.977 idt_B: 0.349 \n",
            "(epoch: 29, iters: 2500, time: 0.310, data: 0.012) D_A: 0.045 G_A: 0.814 cycle_A: 1.261 idt_A: 0.165 D_B: 0.149 G_B: 0.590 cycle_B: 0.567 idt_B: 0.506 \n",
            "saving the latest model (epoch 29, total_iters 25000)\n",
            "End of epoch 29 / 60 \t Time Taken: 816 sec\n",
            "learning rate 0.0001512 -> 0.0001463\n",
            "(epoch: 30, iters: 100, time: 0.345, data: 0.856) D_A: 0.080 G_A: 0.911 cycle_A: 1.386 idt_A: 0.353 D_B: 0.162 G_B: 0.317 cycle_B: 0.847 idt_B: 0.427 \n",
            "(epoch: 30, iters: 200, time: 2.221, data: 0.007) D_A: 0.089 G_A: 1.163 cycle_A: 1.038 idt_A: 0.366 D_B: 0.207 G_B: 0.626 cycle_B: 1.364 idt_B: 0.289 \n",
            "(epoch: 30, iters: 300, time: 0.314, data: 0.005) D_A: 0.151 G_A: 0.241 cycle_A: 1.294 idt_A: 0.340 D_B: 0.190 G_B: 0.341 cycle_B: 0.966 idt_B: 0.571 \n",
            "(epoch: 30, iters: 400, time: 0.316, data: 0.012) D_A: 0.111 G_A: 0.462 cycle_A: 0.908 idt_A: 0.380 D_B: 0.216 G_B: 0.444 cycle_B: 0.793 idt_B: 0.305 \n",
            "(epoch: 30, iters: 500, time: 0.297, data: 0.004) D_A: 0.084 G_A: 0.424 cycle_A: 0.780 idt_A: 0.314 D_B: 0.085 G_B: 0.382 cycle_B: 0.824 idt_B: 0.302 \n",
            "(epoch: 30, iters: 600, time: 1.102, data: 0.003) D_A: 0.176 G_A: 0.310 cycle_A: 0.616 idt_A: 0.256 D_B: 0.223 G_B: 0.165 cycle_B: 0.643 idt_B: 0.207 \n",
            "(epoch: 30, iters: 700, time: 0.325, data: 0.004) D_A: 0.110 G_A: 0.453 cycle_A: 0.947 idt_A: 0.444 D_B: 0.171 G_B: 0.265 cycle_B: 1.087 idt_B: 0.293 \n",
            "(epoch: 30, iters: 800, time: 0.317, data: 0.019) D_A: 0.168 G_A: 0.294 cycle_A: 0.904 idt_A: 0.231 D_B: 0.248 G_B: 0.219 cycle_B: 0.613 idt_B: 0.355 \n",
            "(epoch: 30, iters: 900, time: 0.324, data: 0.008) D_A: 0.038 G_A: 0.388 cycle_A: 1.029 idt_A: 0.374 D_B: 0.109 G_B: 1.417 cycle_B: 1.423 idt_B: 0.402 \n",
            "(epoch: 30, iters: 1000, time: 1.821, data: 0.012) D_A: 0.092 G_A: 0.794 cycle_A: 0.831 idt_A: 0.211 D_B: 0.100 G_B: 0.644 cycle_B: 0.547 idt_B: 0.326 \n",
            "(epoch: 30, iters: 1100, time: 0.305, data: 0.005) D_A: 0.080 G_A: 0.624 cycle_A: 1.363 idt_A: 0.291 D_B: 0.138 G_B: 0.643 cycle_B: 0.707 idt_B: 0.452 \n",
            "(epoch: 30, iters: 1200, time: 0.312, data: 0.024) D_A: 0.023 G_A: 0.648 cycle_A: 1.041 idt_A: 0.328 D_B: 0.245 G_B: 0.960 cycle_B: 0.931 idt_B: 0.222 \n",
            "(epoch: 30, iters: 1300, time: 0.344, data: 0.011) D_A: 0.021 G_A: 0.666 cycle_A: 0.934 idt_A: 0.233 D_B: 0.266 G_B: 0.203 cycle_B: 0.677 idt_B: 0.364 \n",
            "(epoch: 30, iters: 1400, time: 1.066, data: 0.006) D_A: 0.030 G_A: 0.449 cycle_A: 0.885 idt_A: 0.250 D_B: 0.163 G_B: 0.348 cycle_B: 0.963 idt_B: 0.280 \n",
            "(epoch: 30, iters: 1500, time: 0.308, data: 0.004) D_A: 0.041 G_A: 0.808 cycle_A: 1.411 idt_A: 0.476 D_B: 0.128 G_B: 0.386 cycle_B: 0.813 idt_B: 0.544 \n",
            "(epoch: 30, iters: 1600, time: 0.324, data: 0.003) D_A: 0.022 G_A: 0.369 cycle_A: 1.121 idt_A: 0.224 D_B: 0.113 G_B: 0.513 cycle_B: 0.756 idt_B: 0.329 \n",
            "(epoch: 30, iters: 1700, time: 0.304, data: 0.004) D_A: 0.084 G_A: 0.179 cycle_A: 0.950 idt_A: 0.424 D_B: 0.089 G_B: 0.545 cycle_B: 0.887 idt_B: 0.452 \n",
            "(epoch: 30, iters: 1800, time: 1.109, data: 0.012) D_A: 0.133 G_A: 0.485 cycle_A: 1.341 idt_A: 0.253 D_B: 0.101 G_B: 0.435 cycle_B: 0.648 idt_B: 0.622 \n",
            "(epoch: 30, iters: 1900, time: 0.322, data: 0.005) D_A: 0.123 G_A: 0.353 cycle_A: 0.933 idt_A: 0.346 D_B: 0.055 G_B: 0.533 cycle_B: 0.955 idt_B: 0.332 \n",
            "(epoch: 30, iters: 2000, time: 0.331, data: 0.011) D_A: 0.029 G_A: 0.162 cycle_A: 0.971 idt_A: 0.255 D_B: 0.070 G_B: 0.689 cycle_B: 0.814 idt_B: 0.365 \n",
            "(epoch: 30, iters: 2100, time: 0.324, data: 0.008) D_A: 0.144 G_A: 0.314 cycle_A: 1.091 idt_A: 0.235 D_B: 0.049 G_B: 0.808 cycle_B: 0.795 idt_B: 0.448 \n",
            "(epoch: 30, iters: 2200, time: 1.087, data: 0.003) D_A: 0.025 G_A: 0.899 cycle_A: 1.137 idt_A: 0.174 D_B: 0.070 G_B: 1.010 cycle_B: 0.550 idt_B: 0.360 \n",
            "(epoch: 30, iters: 2300, time: 0.323, data: 0.004) D_A: 0.037 G_A: 0.696 cycle_A: 1.736 idt_A: 0.297 D_B: 0.107 G_B: 0.118 cycle_B: 0.562 idt_B: 0.526 \n",
            "(epoch: 30, iters: 2400, time: 0.340, data: 0.006) D_A: 0.184 G_A: 0.230 cycle_A: 0.849 idt_A: 0.194 D_B: 0.196 G_B: 0.263 cycle_B: 0.922 idt_B: 0.324 \n",
            "(epoch: 30, iters: 2500, time: 0.309, data: 0.022) D_A: 0.120 G_A: 1.234 cycle_A: 0.662 idt_A: 0.267 D_B: 0.143 G_B: 0.407 cycle_B: 0.872 idt_B: 0.233 \n",
            "saving the model at the end of epoch 30, iters 27500\n",
            "End of epoch 30 / 60 \t Time Taken: 816 sec\n",
            "learning rate 0.0001463 -> 0.0001415\n",
            "(epoch: 31, iters: 100, time: 2.656, data: 1.058) D_A: 0.127 G_A: 0.535 cycle_A: 1.196 idt_A: 0.272 D_B: 0.102 G_B: 0.595 cycle_B: 0.896 idt_B: 0.509 \n",
            "(epoch: 31, iters: 200, time: 0.310, data: 0.006) D_A: 0.031 G_A: 0.861 cycle_A: 0.810 idt_A: 0.346 D_B: 0.283 G_B: 0.370 cycle_B: 0.912 idt_B: 0.222 \n",
            "(epoch: 31, iters: 300, time: 0.309, data: 0.014) D_A: 0.043 G_A: 1.105 cycle_A: 1.107 idt_A: 0.602 D_B: 0.158 G_B: 0.285 cycle_B: 1.151 idt_B: 0.301 \n",
            "(epoch: 31, iters: 400, time: 0.380, data: 0.006) D_A: 0.177 G_A: 0.711 cycle_A: 0.853 idt_A: 0.292 D_B: 0.170 G_B: 0.291 cycle_B: 0.642 idt_B: 0.275 \n",
            "(epoch: 31, iters: 500, time: 2.229, data: 0.022) D_A: 0.060 G_A: 0.612 cycle_A: 0.845 idt_A: 0.239 D_B: 0.117 G_B: 0.601 cycle_B: 0.665 idt_B: 0.330 \n",
            "(epoch: 31, iters: 600, time: 0.308, data: 0.004) D_A: 0.141 G_A: 0.686 cycle_A: 1.532 idt_A: 0.454 D_B: 0.125 G_B: 0.646 cycle_B: 1.253 idt_B: 0.481 \n",
            "(epoch: 31, iters: 700, time: 0.306, data: 0.024) D_A: 0.039 G_A: 0.521 cycle_A: 1.249 idt_A: 0.304 D_B: 0.320 G_B: 0.440 cycle_B: 0.865 idt_B: 0.624 \n",
            "(epoch: 31, iters: 800, time: 0.320, data: 0.025) D_A: 0.258 G_A: 0.372 cycle_A: 0.726 idt_A: 0.320 D_B: 0.093 G_B: 0.520 cycle_B: 0.946 idt_B: 0.669 \n",
            "(epoch: 31, iters: 900, time: 1.021, data: 0.009) D_A: 0.246 G_A: 0.485 cycle_A: 0.749 idt_A: 0.359 D_B: 0.062 G_B: 0.425 cycle_B: 0.834 idt_B: 0.881 \n",
            "(epoch: 31, iters: 1000, time: 0.380, data: 0.003) D_A: 0.094 G_A: 0.372 cycle_A: 1.268 idt_A: 0.312 D_B: 0.118 G_B: 0.422 cycle_B: 1.254 idt_B: 0.576 \n",
            "(epoch: 31, iters: 1100, time: 0.318, data: 0.009) D_A: 0.063 G_A: 0.550 cycle_A: 0.667 idt_A: 0.276 D_B: 0.060 G_B: 0.296 cycle_B: 0.620 idt_B: 0.226 \n",
            "(epoch: 31, iters: 1200, time: 0.311, data: 0.003) D_A: 0.048 G_A: 0.888 cycle_A: 1.876 idt_A: 0.237 D_B: 0.051 G_B: 0.377 cycle_B: 0.813 idt_B: 0.588 \n",
            "(epoch: 31, iters: 1300, time: 1.099, data: 0.003) D_A: 0.067 G_A: 1.419 cycle_A: 0.967 idt_A: 0.236 D_B: 0.149 G_B: 0.233 cycle_B: 0.738 idt_B: 0.319 \n",
            "(epoch: 31, iters: 1400, time: 0.391, data: 0.004) D_A: 0.033 G_A: 0.600 cycle_A: 0.739 idt_A: 0.249 D_B: 0.303 G_B: 0.548 cycle_B: 0.731 idt_B: 0.230 \n",
            "(epoch: 31, iters: 1500, time: 0.350, data: 0.006) D_A: 0.144 G_A: 0.807 cycle_A: 0.779 idt_A: 0.313 D_B: 0.261 G_B: 0.297 cycle_B: 1.012 idt_B: 0.374 \n",
            "(epoch: 31, iters: 1600, time: 0.309, data: 0.006) D_A: 0.036 G_A: 0.254 cycle_A: 1.555 idt_A: 0.253 D_B: 0.067 G_B: 0.665 cycle_B: 0.656 idt_B: 0.432 \n",
            "(epoch: 31, iters: 1700, time: 1.115, data: 0.005) D_A: 0.066 G_A: 0.235 cycle_A: 1.265 idt_A: 0.343 D_B: 0.172 G_B: 0.260 cycle_B: 0.707 idt_B: 0.556 \n",
            "(epoch: 31, iters: 1800, time: 0.298, data: 0.004) D_A: 0.076 G_A: 0.576 cycle_A: 0.846 idt_A: 0.323 D_B: 0.060 G_B: 0.336 cycle_B: 0.853 idt_B: 0.284 \n",
            "(epoch: 31, iters: 1900, time: 0.400, data: 0.013) D_A: 0.262 G_A: 0.218 cycle_A: 0.877 idt_A: 0.199 D_B: 0.170 G_B: 0.288 cycle_B: 0.567 idt_B: 0.303 \n",
            "(epoch: 31, iters: 2000, time: 0.322, data: 0.013) D_A: 0.120 G_A: 0.467 cycle_A: 1.745 idt_A: 0.289 D_B: 0.216 G_B: 0.365 cycle_B: 0.896 idt_B: 0.790 \n",
            "(epoch: 31, iters: 2100, time: 1.051, data: 0.024) D_A: 0.072 G_A: 0.832 cycle_A: 0.788 idt_A: 0.142 D_B: 0.191 G_B: 0.350 cycle_B: 0.528 idt_B: 0.260 \n",
            "(epoch: 31, iters: 2200, time: 0.393, data: 0.004) D_A: 0.102 G_A: 0.394 cycle_A: 0.848 idt_A: 0.251 D_B: 0.056 G_B: 0.141 cycle_B: 0.668 idt_B: 0.394 \n",
            "(epoch: 31, iters: 2300, time: 0.321, data: 0.013) D_A: 0.056 G_A: 0.563 cycle_A: 0.749 idt_A: 0.191 D_B: 0.135 G_B: 0.453 cycle_B: 0.504 idt_B: 0.244 \n",
            "(epoch: 31, iters: 2400, time: 0.305, data: 0.010) D_A: 0.217 G_A: 0.471 cycle_A: 1.203 idt_A: 0.242 D_B: 0.082 G_B: 0.805 cycle_B: 0.613 idt_B: 0.403 \n",
            "(epoch: 31, iters: 2500, time: 2.009, data: 0.006) D_A: 0.146 G_A: 0.594 cycle_A: 0.979 idt_A: 0.205 D_B: 0.258 G_B: 0.451 cycle_B: 0.591 idt_B: 0.434 \n",
            "saving the latest model (epoch 31, total_iters 30000)\n",
            "End of epoch 31 / 60 \t Time Taken: 821 sec\n",
            "learning rate 0.0001415 -> 0.0001366\n",
            "(epoch: 32, iters: 100, time: 0.455, data: 1.851) D_A: 0.047 G_A: 0.223 cycle_A: 0.616 idt_A: 0.219 D_B: 0.129 G_B: 0.533 cycle_B: 0.806 idt_B: 0.175 \n",
            "(epoch: 32, iters: 200, time: 0.323, data: 0.006) D_A: 0.073 G_A: 0.974 cycle_A: 1.630 idt_A: 0.170 D_B: 0.086 G_B: 0.425 cycle_B: 0.517 idt_B: 0.702 \n",
            "(epoch: 32, iters: 300, time: 0.318, data: 0.010) D_A: 0.138 G_A: 0.314 cycle_A: 0.915 idt_A: 0.316 D_B: 0.166 G_B: 0.371 cycle_B: 0.695 idt_B: 0.363 \n",
            "(epoch: 32, iters: 400, time: 2.485, data: 0.003) D_A: 0.051 G_A: 0.273 cycle_A: 1.075 idt_A: 0.201 D_B: 0.351 G_B: 0.285 cycle_B: 0.702 idt_B: 0.397 \n",
            "(epoch: 32, iters: 500, time: 0.323, data: 0.004) D_A: 0.024 G_A: 0.496 cycle_A: 1.372 idt_A: 0.159 D_B: 0.198 G_B: 0.511 cycle_B: 0.463 idt_B: 0.589 \n",
            "(epoch: 32, iters: 600, time: 0.435, data: 0.015) D_A: 0.071 G_A: 0.561 cycle_A: 1.285 idt_A: 0.194 D_B: 0.238 G_B: 0.229 cycle_B: 0.601 idt_B: 0.410 \n",
            "(epoch: 32, iters: 700, time: 0.290, data: 0.020) D_A: 0.154 G_A: 0.448 cycle_A: 0.729 idt_A: 0.246 D_B: 0.056 G_B: 0.561 cycle_B: 0.589 idt_B: 0.466 \n",
            "(epoch: 32, iters: 800, time: 1.302, data: 0.008) D_A: 0.140 G_A: 0.625 cycle_A: 0.807 idt_A: 0.258 D_B: 0.226 G_B: 0.433 cycle_B: 0.736 idt_B: 0.296 \n",
            "(epoch: 32, iters: 900, time: 0.338, data: 0.006) D_A: 0.247 G_A: 0.312 cycle_A: 1.536 idt_A: 0.253 D_B: 0.160 G_B: 0.292 cycle_B: 0.770 idt_B: 0.901 \n",
            "(epoch: 32, iters: 1000, time: 0.327, data: 0.008) D_A: 0.200 G_A: 0.564 cycle_A: 1.181 idt_A: 0.211 D_B: 0.522 G_B: 0.022 cycle_B: 0.672 idt_B: 0.470 \n",
            "(epoch: 32, iters: 1100, time: 0.309, data: 0.006) D_A: 0.154 G_A: 0.728 cycle_A: 0.808 idt_A: 0.259 D_B: 0.202 G_B: 0.242 cycle_B: 0.795 idt_B: 0.288 \n",
            "(epoch: 32, iters: 1200, time: 0.989, data: 0.010) D_A: 0.090 G_A: 0.421 cycle_A: 0.908 idt_A: 0.106 D_B: 0.243 G_B: 0.243 cycle_B: 0.371 idt_B: 0.304 \n",
            "(epoch: 32, iters: 1300, time: 0.296, data: 0.004) D_A: 0.136 G_A: 0.217 cycle_A: 0.764 idt_A: 0.288 D_B: 0.123 G_B: 0.449 cycle_B: 0.810 idt_B: 0.253 \n",
            "(epoch: 32, iters: 1400, time: 0.324, data: 0.005) D_A: 0.155 G_A: 0.558 cycle_A: 1.453 idt_A: 0.233 D_B: 0.391 G_B: 0.645 cycle_B: 0.727 idt_B: 0.429 \n",
            "(epoch: 32, iters: 1500, time: 0.383, data: 0.007) D_A: 0.149 G_A: 0.416 cycle_A: 0.923 idt_A: 0.248 D_B: 0.101 G_B: 0.547 cycle_B: 0.608 idt_B: 0.422 \n",
            "(epoch: 32, iters: 1600, time: 1.082, data: 0.005) D_A: 0.116 G_A: 0.581 cycle_A: 0.603 idt_A: 0.363 D_B: 0.309 G_B: 0.187 cycle_B: 0.851 idt_B: 0.227 \n",
            "(epoch: 32, iters: 1700, time: 0.308, data: 0.004) D_A: 0.096 G_A: 0.906 cycle_A: 0.860 idt_A: 0.178 D_B: 0.252 G_B: 0.612 cycle_B: 0.672 idt_B: 0.260 \n",
            "(epoch: 32, iters: 1800, time: 0.309, data: 0.005) D_A: 0.108 G_A: 0.964 cycle_A: 0.933 idt_A: 0.284 D_B: 0.266 G_B: 0.200 cycle_B: 1.006 idt_B: 0.297 \n",
            "(epoch: 32, iters: 1900, time: 0.335, data: 0.005) D_A: 0.089 G_A: 0.513 cycle_A: 1.054 idt_A: 0.156 D_B: 0.272 G_B: 0.241 cycle_B: 0.566 idt_B: 0.312 \n",
            "(epoch: 32, iters: 2000, time: 1.925, data: 0.003) D_A: 0.108 G_A: 0.677 cycle_A: 0.844 idt_A: 0.425 D_B: 0.081 G_B: 0.528 cycle_B: 0.834 idt_B: 0.298 \n",
            "(epoch: 32, iters: 2100, time: 0.374, data: 0.011) D_A: 0.140 G_A: 0.521 cycle_A: 1.450 idt_A: 0.123 D_B: 0.416 G_B: 0.125 cycle_B: 0.520 idt_B: 0.721 \n",
            "(epoch: 32, iters: 2200, time: 0.380, data: 0.015) D_A: 0.093 G_A: 1.135 cycle_A: 1.879 idt_A: 0.148 D_B: 0.149 G_B: 0.338 cycle_B: 0.448 idt_B: 0.959 \n",
            "(epoch: 32, iters: 2300, time: 0.308, data: 0.004) D_A: 0.036 G_A: 0.802 cycle_A: 1.282 idt_A: 0.252 D_B: 0.137 G_B: 0.919 cycle_B: 0.523 idt_B: 0.462 \n",
            "(epoch: 32, iters: 2400, time: 1.083, data: 0.004) D_A: 0.126 G_A: 0.419 cycle_A: 0.835 idt_A: 0.317 D_B: 0.096 G_B: 0.565 cycle_B: 0.919 idt_B: 0.324 \n",
            "(epoch: 32, iters: 2500, time: 0.316, data: 0.005) D_A: 0.144 G_A: 0.269 cycle_A: 1.146 idt_A: 0.279 D_B: 0.260 G_B: 0.303 cycle_B: 0.725 idt_B: 0.428 \n",
            "End of epoch 32 / 60 \t Time Taken: 816 sec\n",
            "learning rate 0.0001366 -> 0.0001317\n",
            "(epoch: 33, iters: 100, time: 0.320, data: 0.991) D_A: 0.371 G_A: 0.098 cycle_A: 2.625 idt_A: 0.209 D_B: 0.417 G_B: 0.393 cycle_B: 0.546 idt_B: 2.805 \n",
            "(epoch: 33, iters: 200, time: 0.334, data: 0.005) D_A: 0.109 G_A: 0.514 cycle_A: 0.926 idt_A: 0.230 D_B: 0.330 G_B: 0.214 cycle_B: 0.790 idt_B: 0.240 \n",
            "(epoch: 33, iters: 300, time: 3.201, data: 0.006) D_A: 0.079 G_A: 0.624 cycle_A: 0.808 idt_A: 0.136 D_B: 0.080 G_B: 0.343 cycle_B: 0.581 idt_B: 0.374 \n",
            "(epoch: 33, iters: 400, time: 0.327, data: 0.004) D_A: 0.319 G_A: 1.055 cycle_A: 0.685 idt_A: 0.201 D_B: 0.109 G_B: 0.067 cycle_B: 0.623 idt_B: 0.195 \n",
            "(epoch: 33, iters: 500, time: 0.309, data: 0.008) D_A: 0.160 G_A: 0.349 cycle_A: 0.817 idt_A: 0.330 D_B: 0.083 G_B: 0.588 cycle_B: 0.860 idt_B: 0.424 \n",
            "(epoch: 33, iters: 600, time: 0.305, data: 0.004) D_A: 0.196 G_A: 0.579 cycle_A: 1.096 idt_A: 0.319 D_B: 0.188 G_B: 0.246 cycle_B: 0.778 idt_B: 0.517 \n",
            "(epoch: 33, iters: 700, time: 1.114, data: 0.011) D_A: 0.240 G_A: 0.486 cycle_A: 1.123 idt_A: 0.234 D_B: 0.087 G_B: 0.626 cycle_B: 0.572 idt_B: 0.314 \n",
            "(epoch: 33, iters: 800, time: 0.380, data: 0.004) D_A: 0.054 G_A: 0.619 cycle_A: 0.755 idt_A: 0.193 D_B: 0.114 G_B: 0.360 cycle_B: 0.572 idt_B: 0.211 \n",
            "(epoch: 33, iters: 900, time: 0.331, data: 0.006) D_A: 0.053 G_A: 0.504 cycle_A: 1.620 idt_A: 0.290 D_B: 0.098 G_B: 0.520 cycle_B: 0.478 idt_B: 0.701 \n",
            "(epoch: 33, iters: 1000, time: 0.379, data: 0.020) D_A: 0.033 G_A: 0.493 cycle_A: 1.412 idt_A: 0.223 D_B: 0.261 G_B: 0.318 cycle_B: 0.481 idt_B: 0.485 \n",
            "(epoch: 33, iters: 1100, time: 1.053, data: 0.007) D_A: 0.071 G_A: 0.455 cycle_A: 0.863 idt_A: 0.220 D_B: 0.329 G_B: 0.885 cycle_B: 0.666 idt_B: 0.298 \n",
            "(epoch: 33, iters: 1200, time: 0.333, data: 0.007) D_A: 0.169 G_A: 0.539 cycle_A: 0.883 idt_A: 0.188 D_B: 0.214 G_B: 0.502 cycle_B: 0.616 idt_B: 0.375 \n",
            "(epoch: 33, iters: 1300, time: 0.333, data: 0.011) D_A: 0.084 G_A: 0.608 cycle_A: 1.215 idt_A: 0.244 D_B: 0.053 G_B: 0.435 cycle_B: 0.709 idt_B: 0.474 \n",
            "(epoch: 33, iters: 1400, time: 0.396, data: 0.010) D_A: 0.081 G_A: 0.553 cycle_A: 1.143 idt_A: 0.130 D_B: 0.176 G_B: 0.544 cycle_B: 0.441 idt_B: 0.400 \n",
            "(epoch: 33, iters: 1500, time: 2.329, data: 0.003) D_A: 0.161 G_A: 0.357 cycle_A: 0.810 idt_A: 0.165 D_B: 0.359 G_B: 0.294 cycle_B: 0.547 idt_B: 0.278 \n",
            "(epoch: 33, iters: 1600, time: 0.376, data: 0.005) D_A: 0.164 G_A: 0.250 cycle_A: 0.775 idt_A: 0.345 D_B: 0.164 G_B: 0.404 cycle_B: 0.991 idt_B: 0.363 \n",
            "(epoch: 33, iters: 1700, time: 0.337, data: 0.011) D_A: 0.111 G_A: 0.919 cycle_A: 1.025 idt_A: 0.289 D_B: 0.149 G_B: 0.366 cycle_B: 0.832 idt_B: 0.524 \n",
            "(epoch: 33, iters: 1800, time: 0.354, data: 0.015) D_A: 0.153 G_A: 0.649 cycle_A: 0.917 idt_A: 0.256 D_B: 0.206 G_B: 0.219 cycle_B: 0.727 idt_B: 0.348 \n",
            "(epoch: 33, iters: 1900, time: 1.048, data: 0.003) D_A: 0.077 G_A: 0.363 cycle_A: 0.967 idt_A: 0.291 D_B: 0.156 G_B: 0.770 cycle_B: 0.689 idt_B: 0.325 \n",
            "(epoch: 33, iters: 2000, time: 0.339, data: 0.004) D_A: 0.045 G_A: 0.245 cycle_A: 1.069 idt_A: 0.169 D_B: 0.222 G_B: 0.435 cycle_B: 0.552 idt_B: 0.319 \n",
            "(epoch: 33, iters: 2100, time: 0.410, data: 0.016) D_A: 0.296 G_A: 0.133 cycle_A: 0.689 idt_A: 0.217 D_B: 0.147 G_B: 0.472 cycle_B: 0.608 idt_B: 0.205 \n",
            "(epoch: 33, iters: 2200, time: 0.305, data: 0.007) D_A: 0.129 G_A: 0.410 cycle_A: 0.627 idt_A: 0.183 D_B: 0.112 G_B: 0.347 cycle_B: 0.587 idt_B: 0.175 \n",
            "(epoch: 33, iters: 2300, time: 1.212, data: 0.005) D_A: 0.138 G_A: 0.310 cycle_A: 0.799 idt_A: 0.297 D_B: 0.080 G_B: 0.444 cycle_B: 0.805 idt_B: 0.272 \n",
            "(epoch: 33, iters: 2400, time: 0.298, data: 0.001) D_A: 0.208 G_A: 0.751 cycle_A: 1.432 idt_A: 0.211 D_B: 0.297 G_B: 0.431 cycle_B: 0.796 idt_B: 0.603 \n",
            "(epoch: 33, iters: 2500, time: 0.309, data: 0.003) D_A: 0.065 G_A: 0.546 cycle_A: 1.081 idt_A: 0.198 D_B: 0.094 G_B: 0.342 cycle_B: 0.673 idt_B: 0.380 \n",
            "saving the latest model (epoch 33, total_iters 35000)\n",
            "End of epoch 33 / 60 \t Time Taken: 812 sec\n",
            "learning rate 0.0001317 -> 0.0001268\n",
            "(epoch: 34, iters: 100, time: 0.432, data: 2.019) D_A: 0.209 G_A: 0.711 cycle_A: 1.086 idt_A: 0.342 D_B: 0.154 G_B: 0.592 cycle_B: 0.633 idt_B: 0.389 \n",
            "(epoch: 34, iters: 200, time: 2.500, data: 0.020) D_A: 0.066 G_A: 0.521 cycle_A: 1.260 idt_A: 1.119 D_B: 0.054 G_B: 0.487 cycle_B: 1.821 idt_B: 0.434 \n",
            "(epoch: 34, iters: 300, time: 0.389, data: 0.005) D_A: 0.167 G_A: 0.532 cycle_A: 0.595 idt_A: 0.260 D_B: 0.209 G_B: 0.350 cycle_B: 0.674 idt_B: 0.189 \n",
            "(epoch: 34, iters: 400, time: 0.323, data: 0.004) D_A: 0.087 G_A: 0.694 cycle_A: 0.946 idt_A: 0.297 D_B: 0.154 G_B: 0.165 cycle_B: 0.695 idt_B: 0.404 \n",
            "(epoch: 34, iters: 500, time: 0.293, data: 0.013) D_A: 0.119 G_A: 0.350 cycle_A: 1.207 idt_A: 0.144 D_B: 0.189 G_B: 0.189 cycle_B: 0.531 idt_B: 0.377 \n",
            "(epoch: 34, iters: 600, time: 1.133, data: 0.004) D_A: 0.126 G_A: 0.475 cycle_A: 0.956 idt_A: 0.197 D_B: 0.110 G_B: 0.369 cycle_B: 0.675 idt_B: 0.315 \n",
            "(epoch: 34, iters: 700, time: 0.322, data: 0.004) D_A: 0.147 G_A: 1.499 cycle_A: 0.712 idt_A: 0.262 D_B: 0.314 G_B: 0.356 cycle_B: 0.721 idt_B: 0.297 \n",
            "(epoch: 34, iters: 800, time: 0.348, data: 0.004) D_A: 0.055 G_A: 0.664 cycle_A: 1.379 idt_A: 0.131 D_B: 0.127 G_B: 0.215 cycle_B: 0.413 idt_B: 0.382 \n",
            "(epoch: 34, iters: 900, time: 0.333, data: 0.003) D_A: 0.139 G_A: 0.286 cycle_A: 0.817 idt_A: 0.176 D_B: 0.279 G_B: 0.140 cycle_B: 0.510 idt_B: 0.480 \n",
            "(epoch: 34, iters: 1000, time: 2.142, data: 0.013) D_A: 0.134 G_A: 0.653 cycle_A: 0.815 idt_A: 0.203 D_B: 0.316 G_B: 0.234 cycle_B: 0.695 idt_B: 0.293 \n",
            "(epoch: 34, iters: 1100, time: 0.314, data: 0.004) D_A: 0.054 G_A: 0.428 cycle_A: 1.116 idt_A: 0.162 D_B: 0.243 G_B: 0.385 cycle_B: 0.445 idt_B: 0.546 \n",
            "(epoch: 34, iters: 1200, time: 0.308, data: 0.012) D_A: 0.046 G_A: 0.367 cycle_A: 1.002 idt_A: 0.176 D_B: 0.157 G_B: 0.241 cycle_B: 0.594 idt_B: 0.394 \n",
            "(epoch: 34, iters: 1300, time: 0.325, data: 0.014) D_A: 0.100 G_A: 0.471 cycle_A: 0.866 idt_A: 0.136 D_B: 0.051 G_B: 0.525 cycle_B: 0.508 idt_B: 0.250 \n",
            "(epoch: 34, iters: 1400, time: 1.205, data: 0.011) D_A: 0.326 G_A: 0.682 cycle_A: 1.011 idt_A: 0.133 D_B: 0.274 G_B: 0.207 cycle_B: 0.409 idt_B: 0.360 \n",
            "(epoch: 34, iters: 1500, time: 0.306, data: 0.005) D_A: 0.202 G_A: 0.208 cycle_A: 0.737 idt_A: 0.209 D_B: 0.275 G_B: 0.586 cycle_B: 0.572 idt_B: 0.454 \n",
            "(epoch: 34, iters: 1600, time: 0.311, data: 0.003) D_A: 0.037 G_A: 0.761 cycle_A: 1.349 idt_A: 0.279 D_B: 0.149 G_B: 0.390 cycle_B: 0.887 idt_B: 0.475 \n",
            "(epoch: 34, iters: 1700, time: 0.311, data: 0.007) D_A: 0.170 G_A: 0.526 cycle_A: 0.674 idt_A: 0.315 D_B: 0.041 G_B: 0.340 cycle_B: 0.870 idt_B: 0.248 \n",
            "(epoch: 34, iters: 1800, time: 1.272, data: 0.006) D_A: 0.103 G_A: 0.686 cycle_A: 0.757 idt_A: 0.136 D_B: 0.139 G_B: 0.114 cycle_B: 0.500 idt_B: 0.236 \n",
            "(epoch: 34, iters: 1900, time: 0.306, data: 0.004) D_A: 0.178 G_A: 0.740 cycle_A: 0.857 idt_A: 0.280 D_B: 0.214 G_B: 0.164 cycle_B: 0.770 idt_B: 0.235 \n",
            "(epoch: 34, iters: 2000, time: 0.305, data: 0.010) D_A: 0.284 G_A: 0.232 cycle_A: 1.231 idt_A: 0.122 D_B: 0.139 G_B: 0.395 cycle_B: 0.569 idt_B: 0.301 \n",
            "(epoch: 34, iters: 2100, time: 0.304, data: 0.003) D_A: 0.128 G_A: 0.314 cycle_A: 0.914 idt_A: 0.301 D_B: 0.204 G_B: 0.112 cycle_B: 0.718 idt_B: 0.413 \n",
            "(epoch: 34, iters: 2200, time: 1.156, data: 0.007) D_A: 0.241 G_A: 0.896 cycle_A: 0.658 idt_A: 0.307 D_B: 0.175 G_B: 0.567 cycle_B: 0.909 idt_B: 0.238 \n",
            "(epoch: 34, iters: 2300, time: 0.319, data: 0.004) D_A: 0.238 G_A: 0.269 cycle_A: 0.834 idt_A: 0.362 D_B: 0.266 G_B: 0.537 cycle_B: 0.978 idt_B: 0.248 \n",
            "(epoch: 34, iters: 2400, time: 0.340, data: 0.014) D_A: 0.099 G_A: 0.866 cycle_A: 1.228 idt_A: 0.271 D_B: 0.077 G_B: 0.203 cycle_B: 0.775 idt_B: 0.451 \n",
            "(epoch: 34, iters: 2500, time: 0.309, data: 0.014) D_A: 0.082 G_A: 0.453 cycle_A: 1.209 idt_A: 0.231 D_B: 0.062 G_B: 0.276 cycle_B: 0.926 idt_B: 0.508 \n",
            "End of epoch 34 / 60 \t Time Taken: 814 sec\n",
            "learning rate 0.0001268 -> 0.0001220\n",
            "(epoch: 35, iters: 100, time: 2.200, data: 1.390) D_A: 0.119 G_A: 0.370 cycle_A: 1.328 idt_A: 0.276 D_B: 0.069 G_B: 0.525 cycle_B: 0.687 idt_B: 0.404 \n",
            "(epoch: 35, iters: 200, time: 0.310, data: 0.005) D_A: 0.155 G_A: 0.824 cycle_A: 1.402 idt_A: 0.344 D_B: 0.202 G_B: 0.556 cycle_B: 0.701 idt_B: 0.499 \n",
            "(epoch: 35, iters: 300, time: 0.316, data: 0.003) D_A: 0.142 G_A: 0.871 cycle_A: 0.825 idt_A: 0.596 D_B: 0.192 G_B: 0.204 cycle_B: 0.793 idt_B: 0.435 \n",
            "(epoch: 35, iters: 400, time: 0.375, data: 0.003) D_A: 0.082 G_A: 0.649 cycle_A: 1.212 idt_A: 0.238 D_B: 0.083 G_B: 0.200 cycle_B: 0.632 idt_B: 0.424 \n",
            "(epoch: 35, iters: 500, time: 2.129, data: 0.007) D_A: 0.061 G_A: 0.738 cycle_A: 1.085 idt_A: 0.270 D_B: 0.036 G_B: 1.076 cycle_B: 0.683 idt_B: 0.280 \n",
            "(epoch: 35, iters: 600, time: 0.389, data: 0.005) D_A: 0.090 G_A: 0.651 cycle_A: 0.961 idt_A: 0.343 D_B: 0.037 G_B: 0.277 cycle_B: 0.834 idt_B: 0.322 \n",
            "(epoch: 35, iters: 700, time: 0.343, data: 0.023) D_A: 0.102 G_A: 0.443 cycle_A: 0.874 idt_A: 0.480 D_B: 0.189 G_B: 0.322 cycle_B: 1.104 idt_B: 0.299 \n",
            "(epoch: 35, iters: 800, time: 0.309, data: 0.005) D_A: 0.054 G_A: 0.495 cycle_A: 1.485 idt_A: 0.169 D_B: 0.075 G_B: 0.342 cycle_B: 0.594 idt_B: 0.687 \n",
            "(epoch: 35, iters: 900, time: 1.138, data: 0.014) D_A: 0.068 G_A: 0.686 cycle_A: 1.044 idt_A: 0.153 D_B: 0.343 G_B: 0.086 cycle_B: 0.699 idt_B: 0.326 \n",
            "(epoch: 35, iters: 1000, time: 0.353, data: 0.004) D_A: 0.025 G_A: 0.486 cycle_A: 0.633 idt_A: 0.360 D_B: 0.060 G_B: 0.709 cycle_B: 0.825 idt_B: 0.184 \n",
            "(epoch: 35, iters: 1100, time: 0.314, data: 0.003) D_A: 0.253 G_A: 0.145 cycle_A: 0.710 idt_A: 0.152 D_B: 0.302 G_B: 0.313 cycle_B: 0.515 idt_B: 0.175 \n",
            "(epoch: 35, iters: 1200, time: 0.308, data: 0.003) D_A: 0.116 G_A: 0.450 cycle_A: 0.627 idt_A: 0.291 D_B: 0.130 G_B: 0.336 cycle_B: 0.774 idt_B: 0.177 \n",
            "(epoch: 35, iters: 1300, time: 1.080, data: 0.003) D_A: 0.076 G_A: 0.622 cycle_A: 0.870 idt_A: 0.228 D_B: 0.106 G_B: 0.298 cycle_B: 0.478 idt_B: 0.544 \n",
            "(epoch: 35, iters: 1400, time: 0.305, data: 0.004) D_A: 0.232 G_A: 0.777 cycle_A: 0.763 idt_A: 0.323 D_B: 0.160 G_B: 0.882 cycle_B: 0.811 idt_B: 0.354 \n",
            "(epoch: 35, iters: 1500, time: 0.309, data: 0.004) D_A: 0.124 G_A: 0.549 cycle_A: 0.768 idt_A: 0.283 D_B: 0.201 G_B: 0.348 cycle_B: 0.715 idt_B: 0.254 \n",
            "(epoch: 35, iters: 1600, time: 0.308, data: 0.016) D_A: 0.073 G_A: 0.659 cycle_A: 1.194 idt_A: 0.276 D_B: 0.197 G_B: 0.605 cycle_B: 0.616 idt_B: 0.488 \n",
            "(epoch: 35, iters: 1700, time: 1.018, data: 0.026) D_A: 0.090 G_A: 0.433 cycle_A: 1.006 idt_A: 0.134 D_B: 0.119 G_B: 0.270 cycle_B: 0.428 idt_B: 0.289 \n",
            "(epoch: 35, iters: 1800, time: 0.380, data: 0.004) D_A: 0.142 G_A: 0.325 cycle_A: 1.202 idt_A: 0.261 D_B: 0.155 G_B: 0.222 cycle_B: 0.512 idt_B: 0.446 \n",
            "(epoch: 35, iters: 1900, time: 0.305, data: 0.009) D_A: 0.146 G_A: 0.550 cycle_A: 0.818 idt_A: 0.258 D_B: 0.092 G_B: 0.420 cycle_B: 0.701 idt_B: 0.241 \n",
            "(epoch: 35, iters: 2000, time: 0.354, data: 0.019) D_A: 0.117 G_A: 0.392 cycle_A: 0.587 idt_A: 0.175 D_B: 0.159 G_B: 0.396 cycle_B: 0.491 idt_B: 0.185 \n",
            "(epoch: 35, iters: 2100, time: 1.392, data: 0.022) D_A: 0.174 G_A: 0.457 cycle_A: 0.778 idt_A: 0.187 D_B: 0.233 G_B: 0.353 cycle_B: 0.561 idt_B: 0.232 \n",
            "(epoch: 35, iters: 2200, time: 0.304, data: 0.004) D_A: 0.115 G_A: 0.682 cycle_A: 0.819 idt_A: 0.151 D_B: 0.087 G_B: 0.493 cycle_B: 0.370 idt_B: 0.263 \n",
            "(epoch: 35, iters: 2300, time: 0.454, data: 0.003) D_A: 0.031 G_A: 0.312 cycle_A: 0.729 idt_A: 0.392 D_B: 0.135 G_B: 0.854 cycle_B: 0.594 idt_B: 0.275 \n",
            "(epoch: 35, iters: 2400, time: 0.305, data: 0.003) D_A: 0.076 G_A: 0.858 cycle_A: 0.997 idt_A: 0.368 D_B: 0.143 G_B: 0.236 cycle_B: 1.127 idt_B: 0.592 \n",
            "(epoch: 35, iters: 2500, time: 1.954, data: 0.012) D_A: 0.235 G_A: 0.525 cycle_A: 0.985 idt_A: 0.195 D_B: 0.220 G_B: 0.262 cycle_B: 0.642 idt_B: 0.329 \n",
            "saving the latest model (epoch 35, total_iters 40000)\n",
            "saving the model at the end of epoch 35, iters 40000\n",
            "End of epoch 35 / 60 \t Time Taken: 813 sec\n",
            "learning rate 0.0001220 -> 0.0001171\n",
            "(epoch: 36, iters: 100, time: 0.308, data: 1.227) D_A: 0.039 G_A: 0.531 cycle_A: 0.891 idt_A: 0.347 D_B: 0.140 G_B: 0.657 cycle_B: 0.863 idt_B: 0.283 \n",
            "(epoch: 36, iters: 200, time: 0.302, data: 0.006) D_A: 0.068 G_A: 0.646 cycle_A: 0.851 idt_A: 0.201 D_B: 0.059 G_B: 0.728 cycle_B: 0.634 idt_B: 0.355 \n",
            "(epoch: 36, iters: 300, time: 0.305, data: 0.001) D_A: 0.040 G_A: 0.344 cycle_A: 0.483 idt_A: 0.269 D_B: 0.028 G_B: 0.891 cycle_B: 0.793 idt_B: 0.173 \n",
            "(epoch: 36, iters: 400, time: 2.312, data: 0.013) D_A: 0.204 G_A: 0.503 cycle_A: 0.977 idt_A: 0.314 D_B: 0.074 G_B: 0.806 cycle_B: 0.726 idt_B: 0.271 \n",
            "(epoch: 36, iters: 500, time: 0.319, data: 0.007) D_A: 0.031 G_A: 0.798 cycle_A: 1.072 idt_A: 0.220 D_B: 0.143 G_B: 0.346 cycle_B: 0.606 idt_B: 0.202 \n",
            "(epoch: 36, iters: 600, time: 0.311, data: 0.013) D_A: 0.188 G_A: 0.813 cycle_A: 1.163 idt_A: 0.223 D_B: 0.089 G_B: 0.290 cycle_B: 0.541 idt_B: 0.368 \n",
            "(epoch: 36, iters: 700, time: 0.315, data: 0.008) D_A: 0.079 G_A: 0.506 cycle_A: 1.886 idt_A: 0.179 D_B: 0.172 G_B: 0.242 cycle_B: 0.495 idt_B: 1.133 \n",
            "(epoch: 36, iters: 800, time: 1.238, data: 0.008) D_A: 0.176 G_A: 0.421 cycle_A: 0.766 idt_A: 0.226 D_B: 0.230 G_B: 0.447 cycle_B: 0.617 idt_B: 0.245 \n",
            "(epoch: 36, iters: 900, time: 0.299, data: 0.005) D_A: 0.206 G_A: 0.635 cycle_A: 1.641 idt_A: 0.196 D_B: 0.049 G_B: 0.558 cycle_B: 0.634 idt_B: 0.791 \n",
            "(epoch: 36, iters: 1000, time: 0.309, data: 0.012) D_A: 0.090 G_A: 0.248 cycle_A: 2.190 idt_A: 0.265 D_B: 0.131 G_B: 0.909 cycle_B: 0.714 idt_B: 0.907 \n",
            "(epoch: 36, iters: 1100, time: 0.305, data: 0.007) D_A: 0.164 G_A: 0.701 cycle_A: 0.827 idt_A: 0.255 D_B: 0.184 G_B: 0.436 cycle_B: 0.759 idt_B: 0.296 \n",
            "(epoch: 36, iters: 1200, time: 1.094, data: 0.003) D_A: 0.170 G_A: 0.158 cycle_A: 0.824 idt_A: 0.256 D_B: 0.072 G_B: 0.506 cycle_B: 0.635 idt_B: 0.148 \n",
            "(epoch: 36, iters: 1300, time: 0.316, data: 0.004) D_A: 0.230 G_A: 0.388 cycle_A: 1.130 idt_A: 0.270 D_B: 0.078 G_B: 0.029 cycle_B: 0.616 idt_B: 0.422 \n",
            "(epoch: 36, iters: 1400, time: 0.371, data: 0.007) D_A: 0.108 G_A: 0.802 cycle_A: 0.998 idt_A: 0.123 D_B: 0.043 G_B: 0.907 cycle_B: 0.463 idt_B: 0.344 \n",
            "(epoch: 36, iters: 1500, time: 0.307, data: 0.008) D_A: 0.141 G_A: 0.321 cycle_A: 1.272 idt_A: 0.330 D_B: 0.123 G_B: 0.127 cycle_B: 0.900 idt_B: 0.605 \n",
            "(epoch: 36, iters: 1600, time: 1.072, data: 0.007) D_A: 0.105 G_A: 0.273 cycle_A: 0.822 idt_A: 0.240 D_B: 0.179 G_B: 0.449 cycle_B: 0.770 idt_B: 0.370 \n",
            "(epoch: 36, iters: 1700, time: 0.300, data: 0.005) D_A: 0.104 G_A: 0.417 cycle_A: 0.853 idt_A: 0.159 D_B: 0.282 G_B: 0.135 cycle_B: 0.503 idt_B: 0.590 \n",
            "(epoch: 36, iters: 1800, time: 0.319, data: 0.005) D_A: 0.034 G_A: 0.371 cycle_A: 0.901 idt_A: 0.223 D_B: 0.065 G_B: 0.293 cycle_B: 0.505 idt_B: 0.223 \n",
            "(epoch: 36, iters: 1900, time: 0.330, data: 0.005) D_A: 0.037 G_A: 0.804 cycle_A: 1.192 idt_A: 0.233 D_B: 0.190 G_B: 0.525 cycle_B: 0.460 idt_B: 0.395 \n",
            "(epoch: 36, iters: 2000, time: 1.985, data: 0.003) D_A: 0.190 G_A: 0.290 cycle_A: 0.913 idt_A: 0.178 D_B: 0.228 G_B: 0.326 cycle_B: 0.470 idt_B: 0.281 \n",
            "(epoch: 36, iters: 2100, time: 0.363, data: 0.004) D_A: 0.109 G_A: 0.582 cycle_A: 0.659 idt_A: 0.320 D_B: 0.056 G_B: 0.467 cycle_B: 0.623 idt_B: 0.258 \n",
            "(epoch: 36, iters: 2200, time: 0.313, data: 0.004) D_A: 0.107 G_A: 0.384 cycle_A: 0.663 idt_A: 0.192 D_B: 0.263 G_B: 0.230 cycle_B: 0.543 idt_B: 0.206 \n",
            "(epoch: 36, iters: 2300, time: 0.288, data: 0.010) D_A: 0.130 G_A: 0.318 cycle_A: 1.108 idt_A: 0.207 D_B: 0.141 G_B: 0.633 cycle_B: 0.485 idt_B: 0.422 \n",
            "(epoch: 36, iters: 2400, time: 1.151, data: 0.003) D_A: 0.112 G_A: 0.153 cycle_A: 0.767 idt_A: 0.166 D_B: 0.216 G_B: 0.289 cycle_B: 0.441 idt_B: 0.268 \n",
            "(epoch: 36, iters: 2500, time: 0.307, data: 0.004) D_A: 0.078 G_A: 0.520 cycle_A: 0.972 idt_A: 0.212 D_B: 0.190 G_B: 0.426 cycle_B: 0.642 idt_B: 0.234 \n",
            "End of epoch 36 / 60 \t Time Taken: 809 sec\n",
            "learning rate 0.0001171 -> 0.0001122\n",
            "(epoch: 37, iters: 100, time: 0.313, data: 0.973) D_A: 0.130 G_A: 0.763 cycle_A: 1.138 idt_A: 0.320 D_B: 0.076 G_B: 0.732 cycle_B: 0.758 idt_B: 0.328 \n",
            "(epoch: 37, iters: 200, time: 0.314, data: 0.026) D_A: 0.098 G_A: 0.686 cycle_A: 1.219 idt_A: 0.301 D_B: 0.048 G_B: 0.884 cycle_B: 0.886 idt_B: 0.388 \n",
            "(epoch: 37, iters: 300, time: 2.271, data: 0.006) D_A: 0.086 G_A: 0.299 cycle_A: 1.454 idt_A: 0.191 D_B: 0.236 G_B: 0.649 cycle_B: 0.444 idt_B: 0.626 \n",
            "(epoch: 37, iters: 400, time: 0.314, data: 0.003) D_A: 0.040 G_A: 0.436 cycle_A: 1.064 idt_A: 0.224 D_B: 0.202 G_B: 0.290 cycle_B: 0.609 idt_B: 0.346 \n",
            "(epoch: 37, iters: 500, time: 0.314, data: 0.003) D_A: 0.162 G_A: 0.506 cycle_A: 0.943 idt_A: 0.188 D_B: 0.178 G_B: 0.501 cycle_B: 0.574 idt_B: 0.390 \n",
            "(epoch: 37, iters: 600, time: 0.306, data: 0.003) D_A: 0.143 G_A: 0.435 cycle_A: 2.070 idt_A: 0.213 D_B: 0.056 G_B: 0.264 cycle_B: 0.685 idt_B: 0.882 \n",
            "(epoch: 37, iters: 700, time: 1.142, data: 0.003) D_A: 0.192 G_A: 0.540 cycle_A: 0.930 idt_A: 0.123 D_B: 0.169 G_B: 0.329 cycle_B: 0.434 idt_B: 0.295 \n",
            "(epoch: 37, iters: 800, time: 0.290, data: 0.005) D_A: 0.048 G_A: 0.509 cycle_A: 1.099 idt_A: 0.254 D_B: 0.202 G_B: 0.119 cycle_B: 0.772 idt_B: 0.466 \n",
            "(epoch: 37, iters: 900, time: 0.301, data: 0.001) D_A: 0.119 G_A: 0.509 cycle_A: 0.628 idt_A: 0.257 D_B: 0.216 G_B: 0.398 cycle_B: 0.731 idt_B: 0.295 \n",
            "(epoch: 37, iters: 1000, time: 0.319, data: 0.003) D_A: 0.094 G_A: 0.426 cycle_A: 0.942 idt_A: 0.174 D_B: 0.054 G_B: 1.075 cycle_B: 0.576 idt_B: 0.345 \n",
            "(epoch: 37, iters: 1100, time: 1.159, data: 0.013) D_A: 0.172 G_A: 0.231 cycle_A: 0.800 idt_A: 0.137 D_B: 0.117 G_B: 0.532 cycle_B: 0.565 idt_B: 0.271 \n",
            "(epoch: 37, iters: 1200, time: 0.308, data: 0.004) D_A: 0.193 G_A: 0.317 cycle_A: 0.639 idt_A: 0.240 D_B: 0.069 G_B: 0.404 cycle_B: 0.767 idt_B: 0.308 \n",
            "(epoch: 37, iters: 1300, time: 0.334, data: 0.003) D_A: 0.099 G_A: 0.885 cycle_A: 0.785 idt_A: 0.222 D_B: 0.329 G_B: 0.190 cycle_B: 0.596 idt_B: 0.344 \n",
            "(epoch: 37, iters: 1400, time: 0.341, data: 0.021) D_A: 0.109 G_A: 0.605 cycle_A: 1.059 idt_A: 0.207 D_B: 0.174 G_B: 0.436 cycle_B: 0.608 idt_B: 0.318 \n",
            "(epoch: 37, iters: 1500, time: 2.359, data: 0.005) D_A: 0.123 G_A: 0.675 cycle_A: 0.571 idt_A: 0.187 D_B: 0.175 G_B: 0.469 cycle_B: 0.539 idt_B: 0.310 \n",
            "(epoch: 37, iters: 1600, time: 0.365, data: 0.004) D_A: 0.053 G_A: 0.391 cycle_A: 0.790 idt_A: 0.226 D_B: 0.092 G_B: 0.530 cycle_B: 0.415 idt_B: 0.271 \n",
            "(epoch: 37, iters: 1700, time: 0.349, data: 0.010) D_A: 0.098 G_A: 0.438 cycle_A: 0.971 idt_A: 0.230 D_B: 0.117 G_B: 0.390 cycle_B: 0.460 idt_B: 0.332 \n",
            "(epoch: 37, iters: 1800, time: 0.357, data: 0.011) D_A: 0.217 G_A: 0.173 cycle_A: 0.741 idt_A: 0.242 D_B: 0.208 G_B: 0.442 cycle_B: 0.739 idt_B: 0.273 \n",
            "(epoch: 37, iters: 1900, time: 1.034, data: 0.006) D_A: 0.042 G_A: 0.652 cycle_A: 1.062 idt_A: 0.169 D_B: 0.039 G_B: 0.838 cycle_B: 0.487 idt_B: 0.393 \n",
            "(epoch: 37, iters: 2000, time: 0.362, data: 0.008) D_A: 0.068 G_A: 0.234 cycle_A: 0.923 idt_A: 0.171 D_B: 0.122 G_B: 0.596 cycle_B: 0.577 idt_B: 0.353 \n",
            "(epoch: 37, iters: 2100, time: 0.325, data: 0.019) D_A: 0.204 G_A: 0.232 cycle_A: 0.858 idt_A: 0.149 D_B: 0.260 G_B: 0.325 cycle_B: 0.542 idt_B: 0.284 \n",
            "(epoch: 37, iters: 2200, time: 0.306, data: 0.003) D_A: 0.118 G_A: 0.486 cycle_A: 1.155 idt_A: 0.120 D_B: 0.142 G_B: 0.217 cycle_B: 0.409 idt_B: 0.387 \n",
            "(epoch: 37, iters: 2300, time: 1.158, data: 0.010) D_A: 0.087 G_A: 0.484 cycle_A: 0.626 idt_A: 0.251 D_B: 0.088 G_B: 1.012 cycle_B: 0.703 idt_B: 0.269 \n",
            "(epoch: 37, iters: 2400, time: 0.304, data: 0.004) D_A: 0.095 G_A: 0.551 cycle_A: 1.204 idt_A: 0.145 D_B: 0.073 G_B: 0.458 cycle_B: 0.743 idt_B: 0.386 \n",
            "(epoch: 37, iters: 2500, time: 0.309, data: 0.004) D_A: 0.128 G_A: 0.317 cycle_A: 0.686 idt_A: 0.192 D_B: 0.104 G_B: 0.385 cycle_B: 0.563 idt_B: 0.213 \n",
            "saving the latest model (epoch 37, total_iters 45000)\n",
            "End of epoch 37 / 60 \t Time Taken: 811 sec\n",
            "learning rate 0.0001122 -> 0.0001073\n",
            "(epoch: 38, iters: 100, time: 0.365, data: 0.935) D_A: 0.110 G_A: 0.449 cycle_A: 0.838 idt_A: 0.186 D_B: 0.064 G_B: 0.462 cycle_B: 0.546 idt_B: 0.320 \n",
            "(epoch: 38, iters: 200, time: 2.368, data: 0.003) D_A: 0.103 G_A: 0.453 cycle_A: 0.986 idt_A: 0.298 D_B: 0.210 G_B: 0.235 cycle_B: 0.604 idt_B: 0.323 \n",
            "(epoch: 38, iters: 300, time: 0.326, data: 0.004) D_A: 0.101 G_A: 0.397 cycle_A: 1.003 idt_A: 0.216 D_B: 0.332 G_B: 0.520 cycle_B: 0.581 idt_B: 0.336 \n",
            "(epoch: 38, iters: 400, time: 0.353, data: 0.003) D_A: 0.052 G_A: 0.635 cycle_A: 1.274 idt_A: 0.174 D_B: 0.107 G_B: 0.480 cycle_B: 0.504 idt_B: 0.454 \n",
            "(epoch: 38, iters: 500, time: 0.349, data: 0.003) D_A: 0.201 G_A: 0.547 cycle_A: 1.094 idt_A: 0.252 D_B: 0.146 G_B: 0.297 cycle_B: 0.686 idt_B: 0.345 \n",
            "(epoch: 38, iters: 600, time: 1.060, data: 0.003) D_A: 0.081 G_A: 0.992 cycle_A: 1.312 idt_A: 0.278 D_B: 0.157 G_B: 0.265 cycle_B: 0.642 idt_B: 0.542 \n",
            "(epoch: 38, iters: 700, time: 0.299, data: 0.005) D_A: 0.102 G_A: 0.795 cycle_A: 1.095 idt_A: 0.099 D_B: 0.278 G_B: 0.286 cycle_B: 0.282 idt_B: 0.481 \n",
            "(epoch: 38, iters: 800, time: 0.375, data: 0.003) D_A: 0.103 G_A: 0.389 cycle_A: 0.655 idt_A: 0.293 D_B: 0.088 G_B: 0.715 cycle_B: 0.749 idt_B: 0.242 \n",
            "(epoch: 38, iters: 900, time: 0.321, data: 0.005) D_A: 0.337 G_A: 0.566 cycle_A: 0.651 idt_A: 0.217 D_B: 0.063 G_B: 0.481 cycle_B: 0.726 idt_B: 0.198 \n",
            "(epoch: 38, iters: 1000, time: 1.681, data: 0.005) D_A: 0.226 G_A: 0.509 cycle_A: 0.868 idt_A: 0.178 D_B: 0.264 G_B: 0.417 cycle_B: 0.541 idt_B: 0.327 \n",
            "(epoch: 38, iters: 1100, time: 0.307, data: 0.004) D_A: 0.203 G_A: 0.289 cycle_A: 0.744 idt_A: 0.278 D_B: 0.247 G_B: 0.163 cycle_B: 0.636 idt_B: 0.233 \n",
            "(epoch: 38, iters: 1200, time: 0.322, data: 0.003) D_A: 0.141 G_A: 0.356 cycle_A: 0.679 idt_A: 0.399 D_B: 0.115 G_B: 0.444 cycle_B: 0.791 idt_B: 0.266 \n",
            "(epoch: 38, iters: 1300, time: 0.378, data: 0.004) D_A: 0.108 G_A: 0.314 cycle_A: 0.850 idt_A: 0.234 D_B: 0.088 G_B: 0.542 cycle_B: 0.519 idt_B: 0.260 \n",
            "(epoch: 38, iters: 1400, time: 1.162, data: 0.009) D_A: 0.358 G_A: 0.810 cycle_A: 0.749 idt_A: 0.305 D_B: 0.107 G_B: 0.452 cycle_B: 0.640 idt_B: 0.272 \n",
            "(epoch: 38, iters: 1500, time: 0.360, data: 0.004) D_A: 0.061 G_A: 0.433 cycle_A: 0.932 idt_A: 0.269 D_B: 0.178 G_B: 0.644 cycle_B: 0.747 idt_B: 0.299 \n",
            "(epoch: 38, iters: 1600, time: 0.309, data: 0.004) D_A: 0.173 G_A: 0.642 cycle_A: 0.904 idt_A: 0.224 D_B: 0.129 G_B: 0.510 cycle_B: 0.704 idt_B: 0.281 \n",
            "(epoch: 38, iters: 1700, time: 0.345, data: 0.019) D_A: 0.281 G_A: 0.117 cycle_A: 0.703 idt_A: 0.261 D_B: 0.182 G_B: 0.234 cycle_B: 0.443 idt_B: 0.197 \n",
            "(epoch: 38, iters: 1800, time: 0.995, data: 0.023) D_A: 0.103 G_A: 0.588 cycle_A: 0.942 idt_A: 0.113 D_B: 0.184 G_B: 0.420 cycle_B: 0.550 idt_B: 0.187 \n",
            "(epoch: 38, iters: 1900, time: 0.303, data: 0.004) D_A: 0.049 G_A: 0.835 cycle_A: 0.969 idt_A: 0.160 D_B: 0.101 G_B: 0.513 cycle_B: 0.615 idt_B: 0.387 \n",
            "(epoch: 38, iters: 2000, time: 0.318, data: 0.003) D_A: 0.075 G_A: 0.447 cycle_A: 0.945 idt_A: 0.123 D_B: 0.181 G_B: 0.332 cycle_B: 0.469 idt_B: 0.343 \n",
            "(epoch: 38, iters: 2100, time: 0.358, data: 0.007) D_A: 0.075 G_A: 0.590 cycle_A: 0.644 idt_A: 0.136 D_B: 0.252 G_B: 0.229 cycle_B: 0.543 idt_B: 0.237 \n",
            "(epoch: 38, iters: 2200, time: 1.311, data: 0.003) D_A: 0.251 G_A: 0.190 cycle_A: 0.793 idt_A: 0.197 D_B: 0.322 G_B: 0.206 cycle_B: 0.503 idt_B: 0.250 \n",
            "(epoch: 38, iters: 2300, time: 0.300, data: 0.004) D_A: 0.027 G_A: 0.843 cycle_A: 1.829 idt_A: 0.176 D_B: 0.052 G_B: 0.188 cycle_B: 0.555 idt_B: 0.398 \n",
            "(epoch: 38, iters: 2400, time: 0.332, data: 0.015) D_A: 0.199 G_A: 0.422 cycle_A: 1.170 idt_A: 0.221 D_B: 0.151 G_B: 0.280 cycle_B: 0.631 idt_B: 0.472 \n",
            "(epoch: 38, iters: 2500, time: 0.310, data: 0.003) D_A: 0.108 G_A: 0.376 cycle_A: 1.286 idt_A: 0.237 D_B: 0.024 G_B: 0.280 cycle_B: 0.634 idt_B: 0.441 \n",
            "End of epoch 38 / 60 \t Time Taken: 811 sec\n",
            "learning rate 0.0001073 -> 0.0001024\n",
            "(epoch: 39, iters: 100, time: 2.510, data: 0.957) D_A: 0.143 G_A: 0.476 cycle_A: 0.880 idt_A: 0.149 D_B: 0.156 G_B: 0.459 cycle_B: 0.454 idt_B: 0.344 \n",
            "(epoch: 39, iters: 200, time: 0.306, data: 0.004) D_A: 0.041 G_A: 0.654 cycle_A: 0.697 idt_A: 0.174 D_B: 0.081 G_B: 0.287 cycle_B: 0.584 idt_B: 0.152 \n",
            "(epoch: 39, iters: 300, time: 0.389, data: 0.006) D_A: 0.026 G_A: 1.019 cycle_A: 0.796 idt_A: 0.400 D_B: 0.122 G_B: 0.521 cycle_B: 0.935 idt_B: 0.359 \n",
            "(epoch: 39, iters: 400, time: 0.303, data: 0.004) D_A: 0.029 G_A: 0.559 cycle_A: 1.448 idt_A: 0.503 D_B: 0.218 G_B: 0.569 cycle_B: 0.820 idt_B: 0.486 \n",
            "(epoch: 39, iters: 500, time: 2.165, data: 0.005) D_A: 0.094 G_A: 0.518 cycle_A: 0.837 idt_A: 0.383 D_B: 0.185 G_B: 0.397 cycle_B: 0.842 idt_B: 0.305 \n",
            "(epoch: 39, iters: 600, time: 0.369, data: 0.005) D_A: 0.031 G_A: 0.786 cycle_A: 0.975 idt_A: 0.207 D_B: 0.174 G_B: 0.237 cycle_B: 0.817 idt_B: 0.318 \n",
            "(epoch: 39, iters: 700, time: 0.368, data: 0.003) D_A: 0.030 G_A: 0.497 cycle_A: 1.270 idt_A: 0.166 D_B: 0.159 G_B: 0.258 cycle_B: 0.615 idt_B: 0.575 \n",
            "(epoch: 39, iters: 800, time: 0.308, data: 0.003) D_A: 0.046 G_A: 0.847 cycle_A: 1.182 idt_A: 0.147 D_B: 0.111 G_B: 0.513 cycle_B: 0.477 idt_B: 0.608 \n",
            "(epoch: 39, iters: 900, time: 1.027, data: 0.010) D_A: 0.050 G_A: 0.705 cycle_A: 0.687 idt_A: 0.223 D_B: 0.138 G_B: 0.443 cycle_B: 0.560 idt_B: 0.197 \n",
            "(epoch: 39, iters: 1000, time: 0.337, data: 0.010) D_A: 0.117 G_A: 0.449 cycle_A: 0.862 idt_A: 0.141 D_B: 0.152 G_B: 0.074 cycle_B: 0.502 idt_B: 0.189 \n",
            "(epoch: 39, iters: 1100, time: 0.311, data: 0.005) D_A: 0.117 G_A: 0.487 cycle_A: 1.087 idt_A: 0.366 D_B: 0.112 G_B: 0.605 cycle_B: 0.913 idt_B: 0.403 \n",
            "(epoch: 39, iters: 1200, time: 0.302, data: 0.010) D_A: 0.187 G_A: 0.258 cycle_A: 0.850 idt_A: 0.536 D_B: 0.215 G_B: 0.714 cycle_B: 0.981 idt_B: 0.284 \n",
            "(epoch: 39, iters: 1300, time: 1.016, data: 0.003) D_A: 0.119 G_A: 0.501 cycle_A: 0.872 idt_A: 0.200 D_B: 0.256 G_B: 0.519 cycle_B: 0.567 idt_B: 0.307 \n",
            "(epoch: 39, iters: 1400, time: 0.304, data: 0.004) D_A: 0.278 G_A: 0.152 cycle_A: 0.881 idt_A: 0.222 D_B: 0.196 G_B: 0.832 cycle_B: 0.673 idt_B: 0.312 \n",
            "(epoch: 39, iters: 1500, time: 0.352, data: 0.004) D_A: 0.248 G_A: 1.156 cycle_A: 0.974 idt_A: 0.133 D_B: 0.057 G_B: 0.491 cycle_B: 0.625 idt_B: 0.277 \n",
            "(epoch: 39, iters: 1600, time: 0.308, data: 0.004) D_A: 0.067 G_A: 0.497 cycle_A: 0.951 idt_A: 0.196 D_B: 0.265 G_B: 0.490 cycle_B: 0.677 idt_B: 0.244 \n",
            "(epoch: 39, iters: 1700, time: 1.155, data: 0.005) D_A: 0.161 G_A: 0.440 cycle_A: 0.979 idt_A: 0.185 D_B: 0.114 G_B: 0.338 cycle_B: 0.596 idt_B: 0.435 \n",
            "(epoch: 39, iters: 1800, time: 0.338, data: 0.005) D_A: 0.086 G_A: 0.662 cycle_A: 1.242 idt_A: 0.205 D_B: 0.055 G_B: 0.586 cycle_B: 0.595 idt_B: 0.417 \n",
            "(epoch: 39, iters: 1900, time: 0.306, data: 0.022) D_A: 0.124 G_A: 0.609 cycle_A: 0.879 idt_A: 0.249 D_B: 0.198 G_B: 0.400 cycle_B: 0.618 idt_B: 0.318 \n",
            "(epoch: 39, iters: 2000, time: 0.298, data: 0.017) D_A: 0.188 G_A: 0.461 cycle_A: 0.644 idt_A: 0.322 D_B: 0.246 G_B: 0.345 cycle_B: 0.926 idt_B: 0.197 \n",
            "(epoch: 39, iters: 2100, time: 1.285, data: 0.004) D_A: 0.023 G_A: 1.015 cycle_A: 1.269 idt_A: 0.235 D_B: 0.157 G_B: 0.248 cycle_B: 0.707 idt_B: 0.368 \n",
            "(epoch: 39, iters: 2200, time: 0.306, data: 0.004) D_A: 0.036 G_A: 0.435 cycle_A: 0.918 idt_A: 0.163 D_B: 0.140 G_B: 0.288 cycle_B: 0.561 idt_B: 0.251 \n",
            "(epoch: 39, iters: 2300, time: 0.307, data: 0.015) D_A: 0.161 G_A: 0.825 cycle_A: 0.782 idt_A: 0.221 D_B: 0.162 G_B: 0.244 cycle_B: 0.601 idt_B: 0.223 \n",
            "(epoch: 39, iters: 2400, time: 0.365, data: 0.003) D_A: 0.048 G_A: 0.811 cycle_A: 1.021 idt_A: 0.218 D_B: 0.225 G_B: 0.439 cycle_B: 0.616 idt_B: 0.368 \n",
            "(epoch: 39, iters: 2500, time: 2.157, data: 0.003) D_A: 0.112 G_A: 0.359 cycle_A: 0.745 idt_A: 0.166 D_B: 0.154 G_B: 0.564 cycle_B: 0.554 idt_B: 0.284 \n",
            "saving the latest model (epoch 39, total_iters 50000)\n",
            "End of epoch 39 / 60 \t Time Taken: 813 sec\n",
            "learning rate 0.0001024 -> 0.0000976\n",
            "(epoch: 40, iters: 100, time: 0.304, data: 1.089) D_A: 0.177 G_A: 0.406 cycle_A: 0.784 idt_A: 0.299 D_B: 0.201 G_B: 0.442 cycle_B: 0.797 idt_B: 0.305 \n",
            "(epoch: 40, iters: 200, time: 0.331, data: 0.022) D_A: 0.071 G_A: 0.550 cycle_A: 0.691 idt_A: 0.103 D_B: 0.202 G_B: 0.443 cycle_B: 0.444 idt_B: 0.245 \n",
            "(epoch: 40, iters: 300, time: 0.378, data: 0.012) D_A: 0.092 G_A: 0.420 cycle_A: 0.811 idt_A: 0.162 D_B: 0.093 G_B: 0.453 cycle_B: 0.607 idt_B: 0.385 \n",
            "(epoch: 40, iters: 400, time: 2.679, data: 0.005) D_A: 0.217 G_A: 0.186 cycle_A: 0.862 idt_A: 0.181 D_B: 0.124 G_B: 0.579 cycle_B: 0.672 idt_B: 0.391 \n",
            "(epoch: 40, iters: 500, time: 0.310, data: 0.005) D_A: 0.093 G_A: 0.342 cycle_A: 1.072 idt_A: 0.156 D_B: 0.326 G_B: 0.381 cycle_B: 0.414 idt_B: 0.314 \n",
            "(epoch: 40, iters: 600, time: 0.301, data: 0.005) D_A: 0.109 G_A: 0.526 cycle_A: 0.750 idt_A: 0.183 D_B: 0.100 G_B: 0.180 cycle_B: 0.634 idt_B: 0.245 \n",
            "(epoch: 40, iters: 700, time: 0.315, data: 0.003) D_A: 0.122 G_A: 0.892 cycle_A: 0.869 idt_A: 0.141 D_B: 0.089 G_B: 0.468 cycle_B: 0.418 idt_B: 0.416 \n",
            "(epoch: 40, iters: 800, time: 1.154, data: 0.003) D_A: 0.114 G_A: 0.263 cycle_A: 0.727 idt_A: 0.250 D_B: 0.105 G_B: 0.388 cycle_B: 0.641 idt_B: 0.248 \n",
            "(epoch: 40, iters: 900, time: 0.329, data: 0.004) D_A: 0.139 G_A: 0.447 cycle_A: 1.769 idt_A: 0.315 D_B: 0.100 G_B: 0.498 cycle_B: 0.884 idt_B: 0.697 \n",
            "(epoch: 40, iters: 1000, time: 0.292, data: 0.004) D_A: 0.215 G_A: 0.315 cycle_A: 1.332 idt_A: 0.309 D_B: 0.074 G_B: 0.183 cycle_B: 0.716 idt_B: 0.355 \n",
            "(epoch: 40, iters: 1100, time: 0.305, data: 0.007) D_A: 0.256 G_A: 0.778 cycle_A: 0.709 idt_A: 0.207 D_B: 0.266 G_B: 0.413 cycle_B: 0.677 idt_B: 0.316 \n",
            "(epoch: 40, iters: 1200, time: 0.998, data: 0.004) D_A: 0.035 G_A: 0.748 cycle_A: 0.856 idt_A: 0.185 D_B: 0.169 G_B: 0.292 cycle_B: 0.635 idt_B: 0.334 \n",
            "(epoch: 40, iters: 1300, time: 0.301, data: 0.004) D_A: 0.196 G_A: 0.420 cycle_A: 0.755 idt_A: 0.410 D_B: 0.136 G_B: 0.416 cycle_B: 0.961 idt_B: 0.300 \n",
            "(epoch: 40, iters: 1400, time: 0.365, data: 0.005) D_A: 0.032 G_A: 0.698 cycle_A: 0.920 idt_A: 0.243 D_B: 0.132 G_B: 0.503 cycle_B: 0.837 idt_B: 0.355 \n",
            "(epoch: 40, iters: 1500, time: 0.363, data: 0.008) D_A: 0.043 G_A: 0.873 cycle_A: 1.399 idt_A: 0.206 D_B: 0.118 G_B: 0.501 cycle_B: 0.595 idt_B: 0.258 \n",
            "(epoch: 40, iters: 1600, time: 1.117, data: 0.014) D_A: 0.105 G_A: 0.353 cycle_A: 0.966 idt_A: 0.273 D_B: 0.195 G_B: 0.459 cycle_B: 0.677 idt_B: 0.312 \n",
            "(epoch: 40, iters: 1700, time: 0.300, data: 0.004) D_A: 0.043 G_A: 0.754 cycle_A: 0.823 idt_A: 0.261 D_B: 0.098 G_B: 0.559 cycle_B: 0.712 idt_B: 0.174 \n",
            "(epoch: 40, iters: 1800, time: 0.295, data: 0.010) D_A: 0.110 G_A: 0.529 cycle_A: 0.920 idt_A: 0.238 D_B: 0.225 G_B: 0.275 cycle_B: 0.732 idt_B: 0.281 \n",
            "(epoch: 40, iters: 1900, time: 0.342, data: 0.001) D_A: 0.024 G_A: 0.796 cycle_A: 1.044 idt_A: 0.163 D_B: 0.037 G_B: 0.693 cycle_B: 0.501 idt_B: 0.467 \n",
            "(epoch: 40, iters: 2000, time: 2.117, data: 0.013) D_A: 0.215 G_A: 0.779 cycle_A: 0.762 idt_A: 0.349 D_B: 0.108 G_B: 0.430 cycle_B: 0.896 idt_B: 0.212 \n",
            "(epoch: 40, iters: 2100, time: 0.343, data: 0.005) D_A: 0.041 G_A: 0.564 cycle_A: 0.772 idt_A: 0.202 D_B: 0.304 G_B: 0.545 cycle_B: 0.498 idt_B: 0.266 \n",
            "(epoch: 40, iters: 2200, time: 0.308, data: 0.013) D_A: 0.034 G_A: 0.920 cycle_A: 1.017 idt_A: 0.193 D_B: 0.086 G_B: 1.030 cycle_B: 0.569 idt_B: 0.326 \n",
            "(epoch: 40, iters: 2300, time: 0.351, data: 0.012) D_A: 0.069 G_A: 0.862 cycle_A: 1.458 idt_A: 0.196 D_B: 0.208 G_B: 0.202 cycle_B: 0.600 idt_B: 0.422 \n",
            "(epoch: 40, iters: 2400, time: 1.030, data: 0.015) D_A: 0.028 G_A: 0.984 cycle_A: 0.732 idt_A: 0.190 D_B: 0.041 G_B: 0.750 cycle_B: 0.528 idt_B: 0.357 \n",
            "(epoch: 40, iters: 2500, time: 0.308, data: 0.004) D_A: 0.018 G_A: 0.646 cycle_A: 1.017 idt_A: 0.178 D_B: 0.110 G_B: 0.653 cycle_B: 0.469 idt_B: 0.249 \n",
            "saving the model at the end of epoch 40, iters 52500\n",
            "End of epoch 40 / 60 \t Time Taken: 816 sec\n",
            "learning rate 0.0000976 -> 0.0000927\n",
            "(epoch: 41, iters: 100, time: 0.308, data: 0.987) D_A: 0.032 G_A: 0.937 cycle_A: 0.815 idt_A: 0.259 D_B: 0.149 G_B: 0.173 cycle_B: 0.694 idt_B: 0.191 \n",
            "(epoch: 41, iters: 200, time: 0.298, data: 0.003) D_A: 0.052 G_A: 0.689 cycle_A: 1.085 idt_A: 0.280 D_B: 0.042 G_B: 0.479 cycle_B: 0.746 idt_B: 0.370 \n",
            "(epoch: 41, iters: 300, time: 2.386, data: 0.003) D_A: 0.092 G_A: 1.221 cycle_A: 1.078 idt_A: 0.210 D_B: 0.209 G_B: 0.452 cycle_B: 0.660 idt_B: 0.378 \n",
            "(epoch: 41, iters: 400, time: 0.310, data: 0.003) D_A: 0.093 G_A: 1.036 cycle_A: 0.995 idt_A: 0.204 D_B: 0.080 G_B: 0.315 cycle_B: 0.394 idt_B: 0.297 \n",
            "(epoch: 41, iters: 500, time: 0.354, data: 0.014) D_A: 0.132 G_A: 0.553 cycle_A: 0.893 idt_A: 0.719 D_B: 0.273 G_B: 0.543 cycle_B: 1.389 idt_B: 0.287 \n",
            "(epoch: 41, iters: 600, time: 0.305, data: 0.017) D_A: 0.083 G_A: 0.848 cycle_A: 0.699 idt_A: 0.235 D_B: 0.137 G_B: 0.350 cycle_B: 0.737 idt_B: 0.178 \n",
            "(epoch: 41, iters: 700, time: 1.190, data: 0.003) D_A: 0.037 G_A: 0.514 cycle_A: 0.832 idt_A: 0.229 D_B: 0.113 G_B: 0.427 cycle_B: 0.528 idt_B: 0.253 \n",
            "(epoch: 41, iters: 800, time: 0.310, data: 0.001) D_A: 0.042 G_A: 0.413 cycle_A: 1.025 idt_A: 0.246 D_B: 0.225 G_B: 0.372 cycle_B: 0.771 idt_B: 0.332 \n",
            "(epoch: 41, iters: 900, time: 0.347, data: 0.003) D_A: 0.063 G_A: 0.909 cycle_A: 0.891 idt_A: 0.248 D_B: 0.154 G_B: 0.481 cycle_B: 0.823 idt_B: 0.366 \n",
            "(epoch: 41, iters: 1000, time: 0.299, data: 0.002) D_A: 0.134 G_A: 0.738 cycle_A: 0.797 idt_A: 0.207 D_B: 0.154 G_B: 0.285 cycle_B: 0.605 idt_B: 0.381 \n",
            "(epoch: 41, iters: 1100, time: 0.978, data: 0.005) D_A: 0.152 G_A: 1.109 cycle_A: 0.993 idt_A: 0.219 D_B: 0.084 G_B: 0.820 cycle_B: 0.817 idt_B: 0.441 \n",
            "(epoch: 41, iters: 1200, time: 0.362, data: 0.014) D_A: 0.081 G_A: 0.484 cycle_A: 1.113 idt_A: 0.188 D_B: 0.074 G_B: 0.415 cycle_B: 0.517 idt_B: 0.463 \n",
            "(epoch: 41, iters: 1300, time: 0.305, data: 0.007) D_A: 0.017 G_A: 0.996 cycle_A: 1.203 idt_A: 0.175 D_B: 0.071 G_B: 1.049 cycle_B: 0.598 idt_B: 0.340 \n",
            "(epoch: 41, iters: 1400, time: 0.300, data: 0.013) D_A: 0.041 G_A: 0.735 cycle_A: 0.876 idt_A: 0.126 D_B: 0.057 G_B: 0.960 cycle_B: 0.496 idt_B: 0.229 \n",
            "(epoch: 41, iters: 1500, time: 2.068, data: 0.001) D_A: 0.046 G_A: 0.859 cycle_A: 1.064 idt_A: 0.275 D_B: 0.214 G_B: 0.381 cycle_B: 0.717 idt_B: 0.337 \n",
            "(epoch: 41, iters: 1600, time: 0.352, data: 0.005) D_A: 0.040 G_A: 1.101 cycle_A: 0.676 idt_A: 0.186 D_B: 0.119 G_B: 0.377 cycle_B: 0.584 idt_B: 0.242 \n",
            "(epoch: 41, iters: 1700, time: 0.310, data: 0.003) D_A: 0.033 G_A: 0.566 cycle_A: 0.831 idt_A: 0.203 D_B: 0.179 G_B: 0.691 cycle_B: 0.680 idt_B: 0.251 \n",
            "(epoch: 41, iters: 1800, time: 0.306, data: 0.028) D_A: 0.122 G_A: 0.883 cycle_A: 0.556 idt_A: 0.211 D_B: 0.024 G_B: 0.892 cycle_B: 0.675 idt_B: 0.193 \n",
            "(epoch: 41, iters: 1900, time: 1.141, data: 0.001) D_A: 0.094 G_A: 0.348 cycle_A: 1.385 idt_A: 0.224 D_B: 0.121 G_B: 0.354 cycle_B: 0.477 idt_B: 0.824 \n",
            "(epoch: 41, iters: 2000, time: 0.308, data: 0.004) D_A: 0.192 G_A: 0.768 cycle_A: 0.694 idt_A: 0.144 D_B: 0.103 G_B: 0.706 cycle_B: 0.396 idt_B: 0.234 \n",
            "(epoch: 41, iters: 2100, time: 0.356, data: 0.005) D_A: 0.054 G_A: 0.554 cycle_A: 0.961 idt_A: 0.171 D_B: 0.125 G_B: 0.515 cycle_B: 0.468 idt_B: 0.327 \n",
            "(epoch: 41, iters: 2200, time: 0.319, data: 0.013) D_A: 0.143 G_A: 0.666 cycle_A: 0.624 idt_A: 0.165 D_B: 0.105 G_B: 0.710 cycle_B: 0.574 idt_B: 0.229 \n",
            "(epoch: 41, iters: 2300, time: 1.068, data: 0.018) D_A: 0.094 G_A: 0.581 cycle_A: 0.634 idt_A: 0.269 D_B: 0.194 G_B: 0.549 cycle_B: 1.038 idt_B: 0.214 \n",
            "(epoch: 41, iters: 2400, time: 0.369, data: 0.003) D_A: 0.051 G_A: 0.390 cycle_A: 0.665 idt_A: 0.166 D_B: 0.073 G_B: 0.266 cycle_B: 0.463 idt_B: 0.201 \n",
            "(epoch: 41, iters: 2500, time: 0.310, data: 0.004) D_A: 0.067 G_A: 0.500 cycle_A: 1.140 idt_A: 0.167 D_B: 0.172 G_B: 0.553 cycle_B: 0.531 idt_B: 0.441 \n",
            "saving the latest model (epoch 41, total_iters 55000)\n",
            "End of epoch 41 / 60 \t Time Taken: 811 sec\n",
            "learning rate 0.0000927 -> 0.0000878\n",
            "(epoch: 42, iters: 100, time: 0.327, data: 1.002) D_A: 0.044 G_A: 0.647 cycle_A: 1.172 idt_A: 0.341 D_B: 0.125 G_B: 0.866 cycle_B: 1.017 idt_B: 0.676 \n",
            "(epoch: 42, iters: 200, time: 2.443, data: 0.009) D_A: 0.067 G_A: 0.669 cycle_A: 1.224 idt_A: 0.167 D_B: 0.162 G_B: 0.101 cycle_B: 0.516 idt_B: 0.519 \n",
            "(epoch: 42, iters: 300, time: 0.337, data: 0.004) D_A: 0.065 G_A: 0.499 cycle_A: 0.633 idt_A: 0.364 D_B: 0.124 G_B: 0.363 cycle_B: 0.855 idt_B: 0.188 \n",
            "(epoch: 42, iters: 400, time: 0.315, data: 0.003) D_A: 0.126 G_A: 0.365 cycle_A: 1.047 idt_A: 0.209 D_B: 0.198 G_B: 0.615 cycle_B: 0.585 idt_B: 0.442 \n",
            "(epoch: 42, iters: 500, time: 0.338, data: 0.018) D_A: 0.224 G_A: 0.557 cycle_A: 1.425 idt_A: 0.233 D_B: 0.084 G_B: 0.412 cycle_B: 0.764 idt_B: 0.627 \n",
            "(epoch: 42, iters: 600, time: 1.113, data: 0.021) D_A: 0.068 G_A: 0.438 cycle_A: 0.600 idt_A: 0.163 D_B: 0.131 G_B: 0.657 cycle_B: 0.602 idt_B: 0.363 \n",
            "(epoch: 42, iters: 700, time: 0.319, data: 0.005) D_A: 0.233 G_A: 0.214 cycle_A: 0.932 idt_A: 0.197 D_B: 0.136 G_B: 0.748 cycle_B: 0.656 idt_B: 0.371 \n",
            "(epoch: 42, iters: 800, time: 0.309, data: 0.011) D_A: 0.105 G_A: 0.922 cycle_A: 0.721 idt_A: 0.168 D_B: 0.092 G_B: 0.138 cycle_B: 0.574 idt_B: 0.320 \n",
            "(epoch: 42, iters: 900, time: 0.385, data: 0.011) D_A: 0.047 G_A: 0.379 cycle_A: 0.834 idt_A: 0.292 D_B: 0.082 G_B: 0.478 cycle_B: 0.809 idt_B: 0.570 \n",
            "(epoch: 42, iters: 1000, time: 2.170, data: 0.003) D_A: 0.043 G_A: 0.744 cycle_A: 0.959 idt_A: 0.181 D_B: 0.200 G_B: 0.281 cycle_B: 0.518 idt_B: 0.331 \n",
            "(epoch: 42, iters: 1100, time: 0.435, data: 0.004) D_A: 0.300 G_A: 0.637 cycle_A: 0.852 idt_A: 0.254 D_B: 0.183 G_B: 0.458 cycle_B: 0.787 idt_B: 0.314 \n",
            "(epoch: 42, iters: 1200, time: 0.304, data: 0.009) D_A: 0.130 G_A: 0.832 cycle_A: 1.078 idt_A: 0.294 D_B: 0.202 G_B: 0.207 cycle_B: 0.744 idt_B: 0.480 \n",
            "(epoch: 42, iters: 1300, time: 0.331, data: 0.004) D_A: 0.145 G_A: 0.507 cycle_A: 0.638 idt_A: 0.157 D_B: 0.200 G_B: 0.300 cycle_B: 0.558 idt_B: 0.182 \n",
            "(epoch: 42, iters: 1400, time: 1.214, data: 0.003) D_A: 0.046 G_A: 1.021 cycle_A: 0.881 idt_A: 0.221 D_B: 0.083 G_B: 0.500 cycle_B: 0.768 idt_B: 0.307 \n",
            "(epoch: 42, iters: 1500, time: 0.317, data: 0.004) D_A: 0.099 G_A: 0.584 cycle_A: 1.857 idt_A: 0.151 D_B: 0.101 G_B: 0.602 cycle_B: 0.583 idt_B: 0.759 \n",
            "(epoch: 42, iters: 1600, time: 0.365, data: 0.008) D_A: 0.098 G_A: 0.427 cycle_A: 0.841 idt_A: 0.131 D_B: 0.225 G_B: 0.276 cycle_B: 0.471 idt_B: 0.267 \n",
            "(epoch: 42, iters: 1700, time: 0.361, data: 0.004) D_A: 0.091 G_A: 0.164 cycle_A: 0.802 idt_A: 0.253 D_B: 0.350 G_B: 0.386 cycle_B: 0.459 idt_B: 0.371 \n",
            "(epoch: 42, iters: 1800, time: 1.173, data: 0.006) D_A: 0.248 G_A: 0.200 cycle_A: 0.794 idt_A: 0.109 D_B: 0.401 G_B: 0.222 cycle_B: 0.410 idt_B: 0.300 \n",
            "(epoch: 42, iters: 1900, time: 0.289, data: 0.006) D_A: 0.271 G_A: 0.724 cycle_A: 1.388 idt_A: 0.237 D_B: 0.157 G_B: 1.023 cycle_B: 0.547 idt_B: 0.451 \n",
            "(epoch: 42, iters: 2000, time: 0.329, data: 0.003) D_A: 0.101 G_A: 0.837 cycle_A: 1.519 idt_A: 0.172 D_B: 0.138 G_B: 0.369 cycle_B: 0.516 idt_B: 0.484 \n",
            "(epoch: 42, iters: 2100, time: 0.307, data: 0.003) D_A: 0.188 G_A: 0.673 cycle_A: 0.839 idt_A: 0.224 D_B: 0.188 G_B: 0.320 cycle_B: 0.558 idt_B: 0.231 \n",
            "(epoch: 42, iters: 2200, time: 1.179, data: 0.003) D_A: 0.194 G_A: 0.471 cycle_A: 1.441 idt_A: 0.290 D_B: 0.196 G_B: 0.462 cycle_B: 0.640 idt_B: 0.312 \n",
            "(epoch: 42, iters: 2300, time: 0.309, data: 0.003) D_A: 0.202 G_A: 0.358 cycle_A: 0.468 idt_A: 0.284 D_B: 0.159 G_B: 0.780 cycle_B: 0.668 idt_B: 0.177 \n",
            "(epoch: 42, iters: 2400, time: 0.351, data: 0.020) D_A: 0.190 G_A: 0.497 cycle_A: 0.979 idt_A: 0.194 D_B: 0.278 G_B: 0.105 cycle_B: 0.563 idt_B: 0.294 \n",
            "(epoch: 42, iters: 2500, time: 0.309, data: 0.013) D_A: 0.070 G_A: 0.516 cycle_A: 0.886 idt_A: 0.343 D_B: 0.182 G_B: 0.527 cycle_B: 0.653 idt_B: 0.269 \n",
            "End of epoch 42 / 60 \t Time Taken: 812 sec\n",
            "learning rate 0.0000878 -> 0.0000829\n",
            "(epoch: 43, iters: 100, time: 2.391, data: 1.264) D_A: 0.057 G_A: 0.431 cycle_A: 0.784 idt_A: 0.177 D_B: 0.244 G_B: 0.692 cycle_B: 0.516 idt_B: 0.233 \n",
            "(epoch: 43, iters: 200, time: 0.308, data: 0.004) D_A: 0.255 G_A: 0.980 cycle_A: 1.206 idt_A: 0.279 D_B: 0.178 G_B: 0.428 cycle_B: 0.779 idt_B: 0.468 \n",
            "(epoch: 43, iters: 300, time: 0.306, data: 0.004) D_A: 0.160 G_A: 0.925 cycle_A: 0.723 idt_A: 0.294 D_B: 0.129 G_B: 0.592 cycle_B: 0.722 idt_B: 0.255 \n",
            "(epoch: 43, iters: 400, time: 0.303, data: 0.005) D_A: 0.089 G_A: 0.479 cycle_A: 0.752 idt_A: 0.435 D_B: 0.229 G_B: 0.848 cycle_B: 0.968 idt_B: 0.219 \n",
            "(epoch: 43, iters: 500, time: 2.231, data: 0.003) D_A: 0.061 G_A: 0.830 cycle_A: 0.749 idt_A: 0.106 D_B: 0.160 G_B: 0.355 cycle_B: 0.464 idt_B: 0.279 \n",
            "(epoch: 43, iters: 600, time: 0.305, data: 0.003) D_A: 0.039 G_A: 0.433 cycle_A: 1.025 idt_A: 0.181 D_B: 0.094 G_B: 0.626 cycle_B: 0.534 idt_B: 0.316 \n",
            "(epoch: 43, iters: 700, time: 0.347, data: 0.003) D_A: 0.047 G_A: 0.693 cycle_A: 0.616 idt_A: 0.356 D_B: 0.128 G_B: 0.426 cycle_B: 0.954 idt_B: 0.370 \n",
            "(epoch: 43, iters: 800, time: 0.325, data: 0.012) D_A: 0.082 G_A: 0.483 cycle_A: 1.135 idt_A: 0.289 D_B: 0.189 G_B: 0.509 cycle_B: 0.635 idt_B: 0.346 \n",
            "(epoch: 43, iters: 900, time: 1.050, data: 0.006) D_A: 0.046 G_A: 0.570 cycle_A: 0.532 idt_A: 0.192 D_B: 0.120 G_B: 0.420 cycle_B: 0.514 idt_B: 0.168 \n",
            "(epoch: 43, iters: 1000, time: 0.342, data: 0.004) D_A: 0.182 G_A: 0.272 cycle_A: 1.192 idt_A: 0.165 D_B: 0.112 G_B: 0.321 cycle_B: 0.504 idt_B: 0.440 \n",
            "(epoch: 43, iters: 1100, time: 0.316, data: 0.004) D_A: 0.179 G_A: 0.327 cycle_A: 0.660 idt_A: 0.143 D_B: 0.469 G_B: 0.118 cycle_B: 0.508 idt_B: 0.257 \n",
            "(epoch: 43, iters: 1200, time: 0.308, data: 0.022) D_A: 0.143 G_A: 0.335 cycle_A: 0.727 idt_A: 0.412 D_B: 0.166 G_B: 0.568 cycle_B: 1.119 idt_B: 0.342 \n",
            "(epoch: 43, iters: 1300, time: 1.034, data: 0.004) D_A: 0.046 G_A: 0.625 cycle_A: 1.123 idt_A: 0.141 D_B: 0.177 G_B: 0.754 cycle_B: 0.456 idt_B: 0.458 \n",
            "(epoch: 43, iters: 1400, time: 0.305, data: 0.006) D_A: 0.054 G_A: 0.491 cycle_A: 1.126 idt_A: 0.148 D_B: 0.115 G_B: 0.136 cycle_B: 0.384 idt_B: 0.231 \n",
            "(epoch: 43, iters: 1500, time: 0.420, data: 0.003) D_A: 0.272 G_A: 0.212 cycle_A: 0.660 idt_A: 0.292 D_B: 0.482 G_B: 0.053 cycle_B: 0.876 idt_B: 0.194 \n",
            "(epoch: 43, iters: 1600, time: 0.304, data: 0.009) D_A: 0.135 G_A: 0.186 cycle_A: 1.126 idt_A: 0.220 D_B: 0.146 G_B: 0.718 cycle_B: 0.617 idt_B: 0.268 \n",
            "(epoch: 43, iters: 1700, time: 1.118, data: 0.007) D_A: 0.080 G_A: 0.693 cycle_A: 1.232 idt_A: 0.215 D_B: 0.124 G_B: 0.241 cycle_B: 0.652 idt_B: 0.397 \n",
            "(epoch: 43, iters: 1800, time: 0.308, data: 0.004) D_A: 0.265 G_A: 0.681 cycle_A: 0.653 idt_A: 0.241 D_B: 0.201 G_B: 0.192 cycle_B: 0.631 idt_B: 0.166 \n",
            "(epoch: 43, iters: 1900, time: 0.307, data: 0.003) D_A: 0.154 G_A: 0.493 cycle_A: 1.027 idt_A: 0.146 D_B: 0.134 G_B: 0.286 cycle_B: 0.486 idt_B: 0.243 \n",
            "(epoch: 43, iters: 2000, time: 0.305, data: 0.004) D_A: 0.192 G_A: 0.896 cycle_A: 1.146 idt_A: 0.174 D_B: 0.059 G_B: 0.290 cycle_B: 0.506 idt_B: 0.391 \n",
            "(epoch: 43, iters: 2100, time: 1.208, data: 0.004) D_A: 0.066 G_A: 0.564 cycle_A: 0.700 idt_A: 0.247 D_B: 0.074 G_B: 0.511 cycle_B: 0.722 idt_B: 0.248 \n",
            "(epoch: 43, iters: 2200, time: 0.303, data: 0.004) D_A: 0.033 G_A: 0.682 cycle_A: 0.892 idt_A: 0.131 D_B: 0.077 G_B: 0.364 cycle_B: 0.538 idt_B: 0.351 \n",
            "(epoch: 43, iters: 2300, time: 0.308, data: 0.003) D_A: 0.083 G_A: 1.026 cycle_A: 0.728 idt_A: 0.286 D_B: 0.193 G_B: 0.326 cycle_B: 0.681 idt_B: 0.269 \n",
            "(epoch: 43, iters: 2400, time: 0.323, data: 0.004) D_A: 0.106 G_A: 0.359 cycle_A: 0.804 idt_A: 0.259 D_B: 0.337 G_B: 0.350 cycle_B: 0.550 idt_B: 0.233 \n",
            "(epoch: 43, iters: 2500, time: 2.007, data: 0.003) D_A: 0.154 G_A: 0.495 cycle_A: 0.828 idt_A: 0.235 D_B: 0.260 G_B: 0.450 cycle_B: 0.456 idt_B: 0.243 \n",
            "saving the latest model (epoch 43, total_iters 60000)\n",
            "End of epoch 43 / 60 \t Time Taken: 814 sec\n",
            "learning rate 0.0000829 -> 0.0000780\n",
            "(epoch: 44, iters: 100, time: 0.305, data: 1.921) D_A: 0.111 G_A: 0.733 cycle_A: 1.235 idt_A: 0.124 D_B: 0.164 G_B: 0.286 cycle_B: 0.390 idt_B: 0.436 \n",
            "(epoch: 44, iters: 200, time: 0.292, data: 0.003) D_A: 0.058 G_A: 0.421 cycle_A: 0.705 idt_A: 0.342 D_B: 0.145 G_B: 0.195 cycle_B: 0.805 idt_B: 0.206 \n",
            "(epoch: 44, iters: 300, time: 0.335, data: 0.019) D_A: 0.131 G_A: 0.369 cycle_A: 0.652 idt_A: 0.161 D_B: 0.155 G_B: 0.596 cycle_B: 0.527 idt_B: 0.207 \n",
            "(epoch: 44, iters: 400, time: 2.416, data: 0.008) D_A: 0.111 G_A: 0.236 cycle_A: 0.749 idt_A: 0.175 D_B: 0.109 G_B: 0.324 cycle_B: 0.558 idt_B: 0.351 \n",
            "(epoch: 44, iters: 500, time: 0.304, data: 0.003) D_A: 0.127 G_A: 0.729 cycle_A: 0.940 idt_A: 0.170 D_B: 0.165 G_B: 0.637 cycle_B: 0.517 idt_B: 0.297 \n",
            "(epoch: 44, iters: 600, time: 0.302, data: 0.003) D_A: 0.089 G_A: 0.685 cycle_A: 0.662 idt_A: 0.232 D_B: 0.169 G_B: 0.629 cycle_B: 0.670 idt_B: 0.276 \n",
            "(epoch: 44, iters: 700, time: 0.307, data: 0.001) D_A: 0.095 G_A: 0.530 cycle_A: 0.971 idt_A: 0.232 D_B: 0.069 G_B: 0.413 cycle_B: 0.554 idt_B: 0.370 \n",
            "(epoch: 44, iters: 800, time: 1.120, data: 0.004) D_A: 0.057 G_A: 0.683 cycle_A: 0.765 idt_A: 0.507 D_B: 0.135 G_B: 0.553 cycle_B: 0.934 idt_B: 0.216 \n",
            "(epoch: 44, iters: 900, time: 0.406, data: 0.005) D_A: 0.154 G_A: 0.331 cycle_A: 0.747 idt_A: 0.182 D_B: 0.192 G_B: 0.546 cycle_B: 0.522 idt_B: 0.226 \n",
            "(epoch: 44, iters: 1000, time: 0.350, data: 0.005) D_A: 0.126 G_A: 0.539 cycle_A: 1.169 idt_A: 0.151 D_B: 0.127 G_B: 0.567 cycle_B: 0.492 idt_B: 0.597 \n",
            "(epoch: 44, iters: 1100, time: 0.362, data: 0.003) D_A: 0.321 G_A: 0.761 cycle_A: 0.879 idt_A: 0.197 D_B: 0.208 G_B: 0.700 cycle_B: 0.613 idt_B: 0.326 \n",
            "(epoch: 44, iters: 1200, time: 1.126, data: 0.025) D_A: 0.068 G_A: 0.721 cycle_A: 0.812 idt_A: 0.157 D_B: 0.272 G_B: 0.126 cycle_B: 0.558 idt_B: 0.321 \n",
            "(epoch: 44, iters: 1300, time: 0.323, data: 0.008) D_A: 0.145 G_A: 0.324 cycle_A: 0.563 idt_A: 0.286 D_B: 0.091 G_B: 0.429 cycle_B: 0.844 idt_B: 0.163 \n",
            "(epoch: 44, iters: 1400, time: 0.345, data: 0.003) D_A: 0.106 G_A: 0.588 cycle_A: 0.764 idt_A: 0.182 D_B: 0.244 G_B: 0.320 cycle_B: 0.553 idt_B: 0.222 \n",
            "(epoch: 44, iters: 1500, time: 0.292, data: 0.019) D_A: 0.331 G_A: 0.367 cycle_A: 0.801 idt_A: 0.129 D_B: 0.220 G_B: 0.359 cycle_B: 0.508 idt_B: 0.236 \n",
            "(epoch: 44, iters: 1600, time: 1.017, data: 0.001) D_A: 0.130 G_A: 0.129 cycle_A: 0.891 idt_A: 0.239 D_B: 0.130 G_B: 0.628 cycle_B: 0.917 idt_B: 0.253 \n",
            "(epoch: 44, iters: 1700, time: 0.310, data: 0.004) D_A: 0.055 G_A: 1.093 cycle_A: 0.608 idt_A: 0.175 D_B: 0.196 G_B: 0.210 cycle_B: 0.679 idt_B: 0.160 \n",
            "(epoch: 44, iters: 1800, time: 0.373, data: 0.007) D_A: 0.189 G_A: 0.250 cycle_A: 0.621 idt_A: 0.128 D_B: 0.276 G_B: 0.737 cycle_B: 0.451 idt_B: 0.254 \n",
            "(epoch: 44, iters: 1900, time: 0.342, data: 0.003) D_A: 0.118 G_A: 0.652 cycle_A: 1.044 idt_A: 0.244 D_B: 0.079 G_B: 0.467 cycle_B: 0.702 idt_B: 0.381 \n",
            "(epoch: 44, iters: 2000, time: 2.204, data: 0.011) D_A: 0.307 G_A: 0.246 cycle_A: 0.797 idt_A: 0.216 D_B: 0.199 G_B: 0.115 cycle_B: 0.603 idt_B: 0.272 \n",
            "(epoch: 44, iters: 2100, time: 0.310, data: 0.003) D_A: 0.083 G_A: 0.386 cycle_A: 0.968 idt_A: 0.186 D_B: 0.165 G_B: 0.382 cycle_B: 0.525 idt_B: 0.363 \n",
            "(epoch: 44, iters: 2200, time: 0.323, data: 0.004) D_A: 0.277 G_A: 0.303 cycle_A: 0.914 idt_A: 0.231 D_B: 0.291 G_B: 0.219 cycle_B: 0.636 idt_B: 0.254 \n",
            "(epoch: 44, iters: 2300, time: 0.309, data: 0.003) D_A: 0.106 G_A: 0.495 cycle_A: 1.338 idt_A: 0.178 D_B: 0.146 G_B: 0.287 cycle_B: 0.572 idt_B: 0.372 \n",
            "(epoch: 44, iters: 2400, time: 1.015, data: 0.004) D_A: 0.127 G_A: 0.356 cycle_A: 1.004 idt_A: 0.186 D_B: 0.076 G_B: 0.629 cycle_B: 0.647 idt_B: 0.263 \n",
            "(epoch: 44, iters: 2500, time: 0.309, data: 0.007) D_A: 0.195 G_A: 0.324 cycle_A: 0.751 idt_A: 0.200 D_B: 0.233 G_B: 0.219 cycle_B: 0.529 idt_B: 0.201 \n",
            "End of epoch 44 / 60 \t Time Taken: 814 sec\n",
            "learning rate 0.0000780 -> 0.0000732\n",
            "(epoch: 45, iters: 100, time: 0.316, data: 0.634) D_A: 0.099 G_A: 0.461 cycle_A: 0.623 idt_A: 0.295 D_B: 0.087 G_B: 0.517 cycle_B: 0.682 idt_B: 0.251 \n",
            "(epoch: 45, iters: 200, time: 0.324, data: 0.009) D_A: 0.198 G_A: 0.173 cycle_A: 0.755 idt_A: 0.186 D_B: 0.282 G_B: 0.117 cycle_B: 0.550 idt_B: 0.246 \n",
            "(epoch: 45, iters: 300, time: 2.431, data: 0.003) D_A: 0.126 G_A: 0.436 cycle_A: 0.769 idt_A: 0.188 D_B: 0.182 G_B: 0.284 cycle_B: 0.533 idt_B: 0.241 \n",
            "(epoch: 45, iters: 400, time: 0.413, data: 0.003) D_A: 0.076 G_A: 0.506 cycle_A: 0.792 idt_A: 0.135 D_B: 0.075 G_B: 0.422 cycle_B: 0.505 idt_B: 0.224 \n",
            "(epoch: 45, iters: 500, time: 0.307, data: 0.013) D_A: 0.118 G_A: 0.242 cycle_A: 0.759 idt_A: 0.192 D_B: 0.273 G_B: 0.317 cycle_B: 0.594 idt_B: 0.280 \n",
            "(epoch: 45, iters: 600, time: 0.367, data: 0.011) D_A: 0.116 G_A: 0.643 cycle_A: 0.732 idt_A: 0.160 D_B: 0.149 G_B: 0.312 cycle_B: 0.485 idt_B: 0.358 \n",
            "(epoch: 45, iters: 700, time: 1.091, data: 0.006) D_A: 0.105 G_A: 0.601 cycle_A: 0.996 idt_A: 0.264 D_B: 0.249 G_B: 0.543 cycle_B: 0.769 idt_B: 0.381 \n",
            "(epoch: 45, iters: 800, time: 0.359, data: 0.003) D_A: 0.053 G_A: 0.423 cycle_A: 1.256 idt_A: 0.181 D_B: 0.154 G_B: 0.375 cycle_B: 0.578 idt_B: 0.301 \n",
            "(epoch: 45, iters: 900, time: 0.319, data: 0.003) D_A: 0.220 G_A: 0.678 cycle_A: 0.711 idt_A: 0.171 D_B: 0.165 G_B: 0.654 cycle_B: 0.591 idt_B: 0.192 \n",
            "(epoch: 45, iters: 1000, time: 0.301, data: 0.010) D_A: 0.136 G_A: 0.422 cycle_A: 1.003 idt_A: 0.184 D_B: 0.130 G_B: 0.371 cycle_B: 0.630 idt_B: 0.576 \n",
            "(epoch: 45, iters: 1100, time: 1.116, data: 0.010) D_A: 0.084 G_A: 0.402 cycle_A: 0.876 idt_A: 0.186 D_B: 0.141 G_B: 0.321 cycle_B: 0.658 idt_B: 0.272 \n",
            "(epoch: 45, iters: 1200, time: 0.311, data: 0.004) D_A: 0.068 G_A: 0.635 cycle_A: 0.674 idt_A: 0.211 D_B: 0.364 G_B: 0.564 cycle_B: 0.673 idt_B: 0.255 \n",
            "(epoch: 45, iters: 1300, time: 0.304, data: 0.003) D_A: 0.083 G_A: 0.453 cycle_A: 0.675 idt_A: 0.209 D_B: 0.051 G_B: 0.468 cycle_B: 0.614 idt_B: 0.284 \n",
            "(epoch: 45, iters: 1400, time: 0.313, data: 0.014) D_A: 0.298 G_A: 1.176 cycle_A: 1.115 idt_A: 0.137 D_B: 0.167 G_B: 0.119 cycle_B: 0.492 idt_B: 0.483 \n",
            "(epoch: 45, iters: 1500, time: 2.257, data: 0.005) D_A: 0.043 G_A: 0.425 cycle_A: 0.990 idt_A: 0.178 D_B: 0.286 G_B: 0.426 cycle_B: 0.493 idt_B: 0.279 \n",
            "(epoch: 45, iters: 1600, time: 0.322, data: 0.001) D_A: 0.243 G_A: 0.805 cycle_A: 1.307 idt_A: 0.258 D_B: 0.117 G_B: 0.491 cycle_B: 0.647 idt_B: 0.644 \n",
            "(epoch: 45, iters: 1700, time: 0.307, data: 0.005) D_A: 0.068 G_A: 0.425 cycle_A: 0.785 idt_A: 0.203 D_B: 0.073 G_B: 0.669 cycle_B: 0.455 idt_B: 0.224 \n",
            "(epoch: 45, iters: 1800, time: 0.387, data: 0.003) D_A: 0.095 G_A: 0.432 cycle_A: 0.860 idt_A: 0.206 D_B: 0.189 G_B: 0.409 cycle_B: 0.455 idt_B: 0.323 \n",
            "(epoch: 45, iters: 1900, time: 1.054, data: 0.005) D_A: 0.046 G_A: 0.666 cycle_A: 0.914 idt_A: 0.185 D_B: 0.120 G_B: 0.444 cycle_B: 0.595 idt_B: 0.300 \n",
            "(epoch: 45, iters: 2000, time: 0.299, data: 0.004) D_A: 0.061 G_A: 0.582 cycle_A: 0.706 idt_A: 0.183 D_B: 0.125 G_B: 0.362 cycle_B: 0.525 idt_B: 0.295 \n",
            "(epoch: 45, iters: 2100, time: 0.308, data: 0.003) D_A: 0.019 G_A: 0.188 cycle_A: 0.745 idt_A: 0.104 D_B: 0.181 G_B: 0.363 cycle_B: 0.448 idt_B: 0.268 \n",
            "(epoch: 45, iters: 2200, time: 0.309, data: 0.010) D_A: 0.094 G_A: 0.333 cycle_A: 1.122 idt_A: 0.231 D_B: 0.191 G_B: 0.356 cycle_B: 0.792 idt_B: 0.559 \n",
            "(epoch: 45, iters: 2300, time: 1.134, data: 0.012) D_A: 0.209 G_A: 0.219 cycle_A: 0.897 idt_A: 0.166 D_B: 0.274 G_B: 0.178 cycle_B: 0.707 idt_B: 0.259 \n",
            "(epoch: 45, iters: 2400, time: 0.358, data: 0.004) D_A: 0.150 G_A: 0.351 cycle_A: 1.158 idt_A: 0.205 D_B: 0.087 G_B: 0.494 cycle_B: 0.644 idt_B: 0.439 \n",
            "(epoch: 45, iters: 2500, time: 0.310, data: 0.004) D_A: 0.175 G_A: 0.885 cycle_A: 0.921 idt_A: 0.140 D_B: 0.174 G_B: 0.414 cycle_B: 0.509 idt_B: 0.281 \n",
            "saving the latest model (epoch 45, total_iters 65000)\n",
            "saving the model at the end of epoch 45, iters 65000\n",
            "End of epoch 45 / 60 \t Time Taken: 818 sec\n",
            "learning rate 0.0000732 -> 0.0000683\n",
            "(epoch: 46, iters: 100, time: 0.306, data: 0.852) D_A: 0.134 G_A: 0.314 cycle_A: 0.741 idt_A: 0.231 D_B: 0.202 G_B: 0.596 cycle_B: 0.607 idt_B: 0.245 \n",
            "(epoch: 46, iters: 200, time: 2.569, data: 0.012) D_A: 0.044 G_A: 0.496 cycle_A: 1.192 idt_A: 0.191 D_B: 0.051 G_B: 0.519 cycle_B: 0.586 idt_B: 0.500 \n",
            "(epoch: 46, iters: 300, time: 0.428, data: 0.007) D_A: 0.064 G_A: 0.828 cycle_A: 0.876 idt_A: 0.193 D_B: 0.121 G_B: 0.354 cycle_B: 0.631 idt_B: 0.301 \n",
            "(epoch: 46, iters: 400, time: 0.321, data: 0.003) D_A: 0.116 G_A: 0.378 cycle_A: 0.933 idt_A: 0.182 D_B: 0.125 G_B: 0.584 cycle_B: 0.528 idt_B: 0.352 \n",
            "(epoch: 46, iters: 500, time: 0.352, data: 0.023) D_A: 0.112 G_A: 0.798 cycle_A: 0.742 idt_A: 0.211 D_B: 0.240 G_B: 0.188 cycle_B: 0.665 idt_B: 0.297 \n",
            "(epoch: 46, iters: 600, time: 1.145, data: 0.011) D_A: 0.063 G_A: 0.922 cycle_A: 0.911 idt_A: 0.310 D_B: 0.313 G_B: 0.188 cycle_B: 0.872 idt_B: 0.261 \n",
            "(epoch: 46, iters: 700, time: 0.316, data: 0.005) D_A: 0.036 G_A: 0.815 cycle_A: 1.643 idt_A: 0.347 D_B: 0.098 G_B: 0.457 cycle_B: 0.878 idt_B: 0.743 \n",
            "(epoch: 46, iters: 800, time: 0.337, data: 0.009) D_A: 0.033 G_A: 0.663 cycle_A: 0.742 idt_A: 0.177 D_B: 0.094 G_B: 0.406 cycle_B: 0.504 idt_B: 0.228 \n",
            "(epoch: 46, iters: 900, time: 0.396, data: 0.003) D_A: 0.067 G_A: 0.342 cycle_A: 0.835 idt_A: 0.209 D_B: 0.144 G_B: 0.450 cycle_B: 0.613 idt_B: 0.312 \n",
            "(epoch: 46, iters: 1000, time: 2.231, data: 0.004) D_A: 0.134 G_A: 1.097 cycle_A: 0.714 idt_A: 0.202 D_B: 0.125 G_B: 0.376 cycle_B: 0.713 idt_B: 0.245 \n",
            "(epoch: 46, iters: 1100, time: 0.308, data: 0.004) D_A: 0.061 G_A: 0.797 cycle_A: 0.763 idt_A: 0.321 D_B: 0.088 G_B: 0.188 cycle_B: 0.723 idt_B: 0.247 \n",
            "(epoch: 46, iters: 1200, time: 0.306, data: 0.003) D_A: 0.051 G_A: 0.582 cycle_A: 0.697 idt_A: 0.243 D_B: 0.315 G_B: 0.428 cycle_B: 0.814 idt_B: 0.248 \n",
            "(epoch: 46, iters: 1300, time: 0.302, data: 0.005) D_A: 0.065 G_A: 0.834 cycle_A: 1.176 idt_A: 0.305 D_B: 0.042 G_B: 0.370 cycle_B: 0.906 idt_B: 0.391 \n",
            "(epoch: 46, iters: 1400, time: 1.035, data: 0.006) D_A: 0.032 G_A: 1.235 cycle_A: 0.789 idt_A: 0.134 D_B: 0.126 G_B: 0.415 cycle_B: 0.519 idt_B: 0.291 \n",
            "(epoch: 46, iters: 1500, time: 0.306, data: 0.003) D_A: 0.110 G_A: 0.372 cycle_A: 0.951 idt_A: 0.227 D_B: 0.201 G_B: 0.296 cycle_B: 0.592 idt_B: 0.220 \n",
            "(epoch: 46, iters: 1600, time: 0.336, data: 0.003) D_A: 0.037 G_A: 1.237 cycle_A: 0.999 idt_A: 0.208 D_B: 0.038 G_B: 0.444 cycle_B: 0.585 idt_B: 0.302 \n",
            "(epoch: 46, iters: 1700, time: 0.296, data: 0.012) D_A: 0.046 G_A: 0.927 cycle_A: 0.953 idt_A: 0.195 D_B: 0.194 G_B: 0.118 cycle_B: 0.683 idt_B: 0.233 \n",
            "(epoch: 46, iters: 1800, time: 1.123, data: 0.001) D_A: 0.053 G_A: 1.531 cycle_A: 0.934 idt_A: 0.438 D_B: 0.140 G_B: 0.764 cycle_B: 1.206 idt_B: 0.439 \n",
            "(epoch: 46, iters: 1900, time: 0.306, data: 0.005) D_A: 0.056 G_A: 0.945 cycle_A: 1.634 idt_A: 0.175 D_B: 0.084 G_B: 0.611 cycle_B: 0.761 idt_B: 0.362 \n",
            "(epoch: 46, iters: 2000, time: 0.391, data: 0.003) D_A: 0.026 G_A: 0.648 cycle_A: 0.746 idt_A: 0.230 D_B: 0.147 G_B: 0.328 cycle_B: 0.678 idt_B: 0.228 \n",
            "(epoch: 46, iters: 2100, time: 0.346, data: 0.004) D_A: 0.021 G_A: 0.609 cycle_A: 0.605 idt_A: 0.227 D_B: 0.126 G_B: 0.586 cycle_B: 0.626 idt_B: 0.182 \n",
            "(epoch: 46, iters: 2200, time: 1.069, data: 0.007) D_A: 0.051 G_A: 0.481 cycle_A: 0.885 idt_A: 0.153 D_B: 0.096 G_B: 0.459 cycle_B: 0.489 idt_B: 0.276 \n",
            "(epoch: 46, iters: 2300, time: 0.319, data: 0.004) D_A: 0.040 G_A: 0.631 cycle_A: 1.024 idt_A: 0.271 D_B: 0.086 G_B: 0.509 cycle_B: 0.834 idt_B: 0.308 \n",
            "(epoch: 46, iters: 2400, time: 0.306, data: 0.017) D_A: 0.041 G_A: 1.014 cycle_A: 0.629 idt_A: 0.186 D_B: 0.126 G_B: 0.897 cycle_B: 0.631 idt_B: 0.196 \n",
            "(epoch: 46, iters: 2500, time: 0.310, data: 0.010) D_A: 0.183 G_A: 0.654 cycle_A: 0.764 idt_A: 0.213 D_B: 0.226 G_B: 0.485 cycle_B: 0.671 idt_B: 0.195 \n",
            "End of epoch 46 / 60 \t Time Taken: 817 sec\n",
            "learning rate 0.0000683 -> 0.0000634\n",
            "(epoch: 47, iters: 100, time: 2.416, data: 1.047) D_A: 0.096 G_A: 0.549 cycle_A: 0.611 idt_A: 0.216 D_B: 0.160 G_B: 0.304 cycle_B: 0.680 idt_B: 0.217 \n",
            "(epoch: 47, iters: 200, time: 0.306, data: 0.007) D_A: 0.117 G_A: 0.730 cycle_A: 0.642 idt_A: 0.326 D_B: 0.248 G_B: 0.278 cycle_B: 0.849 idt_B: 0.211 \n",
            "(epoch: 47, iters: 300, time: 0.300, data: 0.003) D_A: 0.097 G_A: 0.405 cycle_A: 1.109 idt_A: 0.148 D_B: 0.189 G_B: 0.606 cycle_B: 0.489 idt_B: 0.719 \n",
            "(epoch: 47, iters: 400, time: 0.318, data: 0.003) D_A: 0.073 G_A: 0.629 cycle_A: 1.452 idt_A: 0.284 D_B: 0.064 G_B: 0.514 cycle_B: 0.728 idt_B: 0.450 \n",
            "(epoch: 47, iters: 500, time: 1.934, data: 0.024) D_A: 0.206 G_A: 0.482 cycle_A: 0.666 idt_A: 0.181 D_B: 0.069 G_B: 0.462 cycle_B: 0.717 idt_B: 0.354 \n",
            "(epoch: 47, iters: 600, time: 0.307, data: 0.004) D_A: 0.138 G_A: 0.287 cycle_A: 0.900 idt_A: 0.226 D_B: 0.169 G_B: 0.469 cycle_B: 0.546 idt_B: 0.339 \n",
            "(epoch: 47, iters: 700, time: 0.306, data: 0.016) D_A: 0.164 G_A: 0.248 cycle_A: 1.212 idt_A: 0.113 D_B: 0.109 G_B: 0.233 cycle_B: 0.479 idt_B: 0.442 \n",
            "(epoch: 47, iters: 800, time: 0.306, data: 0.001) D_A: 0.062 G_A: 0.599 cycle_A: 0.888 idt_A: 0.285 D_B: 0.178 G_B: 0.252 cycle_B: 0.787 idt_B: 0.431 \n",
            "(epoch: 47, iters: 900, time: 1.079, data: 0.003) D_A: 0.186 G_A: 0.358 cycle_A: 1.355 idt_A: 0.178 D_B: 0.126 G_B: 0.192 cycle_B: 0.642 idt_B: 0.434 \n",
            "(epoch: 47, iters: 1000, time: 0.361, data: 0.004) D_A: 0.091 G_A: 0.453 cycle_A: 0.841 idt_A: 0.240 D_B: 0.083 G_B: 0.474 cycle_B: 0.711 idt_B: 0.253 \n",
            "(epoch: 47, iters: 1100, time: 0.318, data: 0.009) D_A: 0.124 G_A: 0.922 cycle_A: 0.989 idt_A: 0.135 D_B: 0.285 G_B: 0.355 cycle_B: 0.453 idt_B: 0.525 \n",
            "(epoch: 47, iters: 1200, time: 0.371, data: 0.023) D_A: 0.153 G_A: 0.983 cycle_A: 1.053 idt_A: 0.256 D_B: 0.108 G_B: 0.406 cycle_B: 0.788 idt_B: 0.422 \n",
            "(epoch: 47, iters: 1300, time: 1.031, data: 0.014) D_A: 0.148 G_A: 0.791 cycle_A: 0.557 idt_A: 0.244 D_B: 0.310 G_B: 0.714 cycle_B: 0.584 idt_B: 0.190 \n",
            "(epoch: 47, iters: 1400, time: 0.308, data: 0.004) D_A: 0.144 G_A: 0.577 cycle_A: 0.733 idt_A: 0.155 D_B: 0.176 G_B: 0.510 cycle_B: 0.532 idt_B: 0.268 \n",
            "(epoch: 47, iters: 1500, time: 0.351, data: 0.003) D_A: 0.121 G_A: 0.339 cycle_A: 0.563 idt_A: 0.196 D_B: 0.250 G_B: 0.609 cycle_B: 0.430 idt_B: 0.174 \n",
            "(epoch: 47, iters: 1600, time: 0.307, data: 0.025) D_A: 0.084 G_A: 0.589 cycle_A: 0.747 idt_A: 0.483 D_B: 0.086 G_B: 0.186 cycle_B: 0.769 idt_B: 0.258 \n",
            "(epoch: 47, iters: 1700, time: 1.034, data: 0.011) D_A: 0.232 G_A: 0.230 cycle_A: 0.417 idt_A: 0.118 D_B: 0.100 G_B: 0.571 cycle_B: 0.404 idt_B: 0.177 \n",
            "(epoch: 47, iters: 1800, time: 0.301, data: 0.004) D_A: 0.201 G_A: 0.543 cycle_A: 0.937 idt_A: 0.290 D_B: 0.246 G_B: 0.197 cycle_B: 0.778 idt_B: 0.406 \n",
            "(epoch: 47, iters: 1900, time: 0.312, data: 0.008) D_A: 0.097 G_A: 0.583 cycle_A: 0.729 idt_A: 0.197 D_B: 0.137 G_B: 0.560 cycle_B: 0.592 idt_B: 0.246 \n",
            "(epoch: 47, iters: 2000, time: 0.321, data: 0.004) D_A: 0.077 G_A: 0.632 cycle_A: 0.858 idt_A: 0.267 D_B: 0.083 G_B: 0.849 cycle_B: 0.546 idt_B: 0.336 \n",
            "(epoch: 47, iters: 2100, time: 1.071, data: 0.019) D_A: 0.129 G_A: 0.338 cycle_A: 0.833 idt_A: 0.194 D_B: 0.193 G_B: 0.570 cycle_B: 0.576 idt_B: 0.251 \n",
            "(epoch: 47, iters: 2200, time: 0.325, data: 0.006) D_A: 0.061 G_A: 0.836 cycle_A: 0.681 idt_A: 0.139 D_B: 0.238 G_B: 0.302 cycle_B: 0.456 idt_B: 0.266 \n",
            "(epoch: 47, iters: 2300, time: 0.331, data: 0.010) D_A: 0.124 G_A: 0.695 cycle_A: 0.565 idt_A: 0.192 D_B: 0.232 G_B: 0.550 cycle_B: 0.576 idt_B: 0.146 \n",
            "(epoch: 47, iters: 2400, time: 0.292, data: 0.006) D_A: 0.165 G_A: 0.537 cycle_A: 0.702 idt_A: 0.148 D_B: 0.189 G_B: 0.621 cycle_B: 0.443 idt_B: 0.157 \n",
            "(epoch: 47, iters: 2500, time: 2.076, data: 0.001) D_A: 0.109 G_A: 0.623 cycle_A: 0.603 idt_A: 0.183 D_B: 0.350 G_B: 0.420 cycle_B: 0.606 idt_B: 0.186 \n",
            "saving the latest model (epoch 47, total_iters 70000)\n",
            "End of epoch 47 / 60 \t Time Taken: 820 sec\n",
            "learning rate 0.0000634 -> 0.0000585\n",
            "(epoch: 48, iters: 100, time: 0.309, data: 0.719) D_A: 0.100 G_A: 0.349 cycle_A: 1.009 idt_A: 0.146 D_B: 0.090 G_B: 0.188 cycle_B: 0.544 idt_B: 0.485 \n",
            "(epoch: 48, iters: 200, time: 0.309, data: 0.016) D_A: 0.218 G_A: 0.437 cycle_A: 1.064 idt_A: 0.220 D_B: 0.095 G_B: 0.181 cycle_B: 0.672 idt_B: 0.362 \n",
            "(epoch: 48, iters: 300, time: 0.298, data: 0.008) D_A: 0.041 G_A: 0.334 cycle_A: 1.041 idt_A: 0.218 D_B: 0.286 G_B: 0.182 cycle_B: 0.704 idt_B: 0.349 \n",
            "(epoch: 48, iters: 400, time: 2.566, data: 0.003) D_A: 0.126 G_A: 0.684 cycle_A: 0.830 idt_A: 0.204 D_B: 0.272 G_B: 0.378 cycle_B: 0.685 idt_B: 0.317 \n",
            "(epoch: 48, iters: 500, time: 0.364, data: 0.004) D_A: 0.105 G_A: 0.302 cycle_A: 0.690 idt_A: 0.145 D_B: 0.124 G_B: 0.510 cycle_B: 0.504 idt_B: 0.195 \n",
            "(epoch: 48, iters: 600, time: 0.321, data: 0.003) D_A: 0.046 G_A: 0.843 cycle_A: 1.181 idt_A: 0.107 D_B: 0.068 G_B: 0.770 cycle_B: 0.385 idt_B: 0.252 \n",
            "(epoch: 48, iters: 700, time: 0.317, data: 0.003) D_A: 0.050 G_A: 0.757 cycle_A: 0.626 idt_A: 0.114 D_B: 0.211 G_B: 0.252 cycle_B: 0.419 idt_B: 0.247 \n",
            "(epoch: 48, iters: 800, time: 1.054, data: 0.004) D_A: 0.185 G_A: 0.573 cycle_A: 0.556 idt_A: 0.199 D_B: 0.216 G_B: 0.317 cycle_B: 0.647 idt_B: 0.204 \n",
            "(epoch: 48, iters: 900, time: 0.369, data: 0.004) D_A: 0.131 G_A: 1.204 cycle_A: 1.320 idt_A: 0.207 D_B: 0.227 G_B: 0.364 cycle_B: 0.572 idt_B: 0.669 \n",
            "(epoch: 48, iters: 1000, time: 0.306, data: 0.001) D_A: 0.123 G_A: 1.046 cycle_A: 0.884 idt_A: 0.099 D_B: 0.209 G_B: 0.236 cycle_B: 0.418 idt_B: 0.560 \n",
            "(epoch: 48, iters: 1100, time: 0.305, data: 0.005) D_A: 0.098 G_A: 0.428 cycle_A: 0.953 idt_A: 0.213 D_B: 0.112 G_B: 0.387 cycle_B: 0.699 idt_B: 0.318 \n",
            "(epoch: 48, iters: 1200, time: 1.154, data: 0.003) D_A: 0.089 G_A: 0.492 cycle_A: 0.726 idt_A: 0.313 D_B: 0.201 G_B: 0.400 cycle_B: 0.886 idt_B: 0.223 \n",
            "(epoch: 48, iters: 1300, time: 0.332, data: 0.004) D_A: 0.133 G_A: 0.473 cycle_A: 0.967 idt_A: 0.152 D_B: 0.147 G_B: 0.390 cycle_B: 0.507 idt_B: 0.392 \n",
            "(epoch: 48, iters: 1400, time: 0.315, data: 0.003) D_A: 0.069 G_A: 0.549 cycle_A: 0.491 idt_A: 0.172 D_B: 0.198 G_B: 0.325 cycle_B: 0.535 idt_B: 0.185 \n",
            "(epoch: 48, iters: 1500, time: 0.302, data: 0.006) D_A: 0.070 G_A: 0.606 cycle_A: 0.681 idt_A: 0.171 D_B: 0.191 G_B: 0.553 cycle_B: 0.460 idt_B: 0.236 \n",
            "(epoch: 48, iters: 1600, time: 1.152, data: 0.014) D_A: 0.082 G_A: 0.532 cycle_A: 0.966 idt_A: 0.237 D_B: 0.223 G_B: 0.437 cycle_B: 0.811 idt_B: 0.207 \n",
            "(epoch: 48, iters: 1700, time: 0.298, data: 0.004) D_A: 0.233 G_A: 0.196 cycle_A: 0.850 idt_A: 0.256 D_B: 0.133 G_B: 0.379 cycle_B: 0.754 idt_B: 0.260 \n",
            "(epoch: 48, iters: 1800, time: 0.312, data: 0.003) D_A: 0.065 G_A: 0.613 cycle_A: 0.559 idt_A: 0.159 D_B: 0.097 G_B: 0.162 cycle_B: 0.516 idt_B: 0.159 \n",
            "(epoch: 48, iters: 1900, time: 0.323, data: 0.022) D_A: 0.068 G_A: 0.737 cycle_A: 0.755 idt_A: 0.122 D_B: 0.102 G_B: 0.405 cycle_B: 0.469 idt_B: 0.284 \n",
            "(epoch: 48, iters: 2000, time: 2.408, data: 0.003) D_A: 0.121 G_A: 0.903 cycle_A: 0.963 idt_A: 0.138 D_B: 0.128 G_B: 0.384 cycle_B: 0.527 idt_B: 0.470 \n",
            "(epoch: 48, iters: 2100, time: 0.317, data: 0.005) D_A: 0.056 G_A: 0.917 cycle_A: 0.481 idt_A: 0.102 D_B: 0.090 G_B: 0.134 cycle_B: 0.362 idt_B: 0.202 \n",
            "(epoch: 48, iters: 2200, time: 0.308, data: 0.027) D_A: 0.252 G_A: 0.755 cycle_A: 0.928 idt_A: 0.206 D_B: 0.084 G_B: 0.502 cycle_B: 0.641 idt_B: 0.377 \n",
            "(epoch: 48, iters: 2300, time: 0.334, data: 0.003) D_A: 0.189 G_A: 0.482 cycle_A: 0.731 idt_A: 0.237 D_B: 0.251 G_B: 0.580 cycle_B: 0.549 idt_B: 0.237 \n",
            "(epoch: 48, iters: 2400, time: 1.058, data: 0.013) D_A: 0.061 G_A: 0.780 cycle_A: 0.754 idt_A: 0.112 D_B: 0.093 G_B: 0.558 cycle_B: 0.387 idt_B: 0.296 \n",
            "(epoch: 48, iters: 2500, time: 0.309, data: 0.021) D_A: 0.094 G_A: 0.411 cycle_A: 0.854 idt_A: 0.197 D_B: 0.256 G_B: 0.351 cycle_B: 0.660 idt_B: 0.306 \n",
            "End of epoch 48 / 60 \t Time Taken: 817 sec\n",
            "learning rate 0.0000585 -> 0.0000537\n",
            "(epoch: 49, iters: 100, time: 0.308, data: 1.276) D_A: 0.060 G_A: 0.535 cycle_A: 0.948 idt_A: 0.184 D_B: 0.146 G_B: 0.444 cycle_B: 0.487 idt_B: 0.299 \n",
            "(epoch: 49, iters: 200, time: 0.339, data: 0.012) D_A: 0.076 G_A: 0.534 cycle_A: 0.701 idt_A: 0.189 D_B: 0.260 G_B: 0.757 cycle_B: 0.619 idt_B: 0.248 \n",
            "(epoch: 49, iters: 300, time: 2.611, data: 0.012) D_A: 0.109 G_A: 1.034 cycle_A: 0.622 idt_A: 0.417 D_B: 0.050 G_B: 0.406 cycle_B: 1.083 idt_B: 0.192 \n",
            "(epoch: 49, iters: 400, time: 0.296, data: 0.004) D_A: 0.134 G_A: 0.699 cycle_A: 1.130 idt_A: 0.192 D_B: 0.038 G_B: 0.503 cycle_B: 0.618 idt_B: 0.451 \n",
            "(epoch: 49, iters: 500, time: 0.322, data: 0.025) D_A: 0.047 G_A: 0.825 cycle_A: 1.037 idt_A: 0.206 D_B: 0.028 G_B: 0.777 cycle_B: 0.582 idt_B: 0.336 \n",
            "(epoch: 49, iters: 600, time: 0.310, data: 0.014) D_A: 0.186 G_A: 0.636 cycle_A: 0.769 idt_A: 0.112 D_B: 0.245 G_B: 0.480 cycle_B: 0.377 idt_B: 0.349 \n",
            "(epoch: 49, iters: 700, time: 1.139, data: 0.003) D_A: 0.163 G_A: 0.126 cycle_A: 0.897 idt_A: 0.152 D_B: 0.348 G_B: 0.241 cycle_B: 0.495 idt_B: 0.335 \n",
            "(epoch: 49, iters: 800, time: 0.313, data: 0.004) D_A: 0.029 G_A: 0.781 cycle_A: 0.825 idt_A: 0.117 D_B: 0.119 G_B: 0.367 cycle_B: 0.406 idt_B: 0.329 \n",
            "(epoch: 49, iters: 900, time: 0.305, data: 0.003) D_A: 0.081 G_A: 0.838 cycle_A: 0.823 idt_A: 0.212 D_B: 0.108 G_B: 0.386 cycle_B: 0.662 idt_B: 0.308 \n",
            "(epoch: 49, iters: 1000, time: 0.309, data: 0.006) D_A: 0.046 G_A: 0.372 cycle_A: 1.200 idt_A: 0.109 D_B: 0.229 G_B: 0.483 cycle_B: 0.484 idt_B: 0.623 \n",
            "(epoch: 49, iters: 1100, time: 1.064, data: 0.005) D_A: 0.101 G_A: 0.429 cycle_A: 0.569 idt_A: 0.198 D_B: 0.156 G_B: 0.794 cycle_B: 0.658 idt_B: 0.161 \n",
            "(epoch: 49, iters: 1200, time: 0.311, data: 0.004) D_A: 0.277 G_A: 0.676 cycle_A: 0.739 idt_A: 0.236 D_B: 0.315 G_B: 0.705 cycle_B: 0.634 idt_B: 0.274 \n",
            "(epoch: 49, iters: 1300, time: 0.310, data: 0.004) D_A: 0.085 G_A: 0.377 cycle_A: 1.188 idt_A: 0.175 D_B: 0.259 G_B: 0.412 cycle_B: 0.553 idt_B: 0.460 \n",
            "(epoch: 49, iters: 1400, time: 0.364, data: 0.003) D_A: 0.223 G_A: 0.521 cycle_A: 1.043 idt_A: 0.269 D_B: 0.134 G_B: 0.379 cycle_B: 0.756 idt_B: 0.358 \n",
            "(epoch: 49, iters: 1500, time: 2.228, data: 0.008) D_A: 0.138 G_A: 0.297 cycle_A: 0.649 idt_A: 0.154 D_B: 0.351 G_B: 0.359 cycle_B: 0.416 idt_B: 0.212 \n",
            "(epoch: 49, iters: 1600, time: 0.307, data: 0.006) D_A: 0.262 G_A: 0.474 cycle_A: 0.726 idt_A: 0.169 D_B: 0.209 G_B: 0.284 cycle_B: 0.321 idt_B: 0.207 \n",
            "(epoch: 49, iters: 1700, time: 0.344, data: 0.003) D_A: 0.093 G_A: 0.836 cycle_A: 0.764 idt_A: 0.201 D_B: 0.109 G_B: 0.448 cycle_B: 0.594 idt_B: 0.221 \n",
            "(epoch: 49, iters: 1800, time: 0.342, data: 0.023) D_A: 0.266 G_A: 0.420 cycle_A: 0.583 idt_A: 0.150 D_B: 0.114 G_B: 0.550 cycle_B: 0.529 idt_B: 0.188 \n",
            "(epoch: 49, iters: 1900, time: 1.283, data: 0.003) D_A: 0.116 G_A: 0.427 cycle_A: 0.677 idt_A: 0.227 D_B: 0.246 G_B: 0.545 cycle_B: 0.657 idt_B: 0.180 \n",
            "(epoch: 49, iters: 2000, time: 0.317, data: 0.004) D_A: 0.101 G_A: 0.530 cycle_A: 0.630 idt_A: 0.147 D_B: 0.292 G_B: 0.101 cycle_B: 0.425 idt_B: 0.212 \n",
            "(epoch: 49, iters: 2100, time: 0.319, data: 0.003) D_A: 0.068 G_A: 0.685 cycle_A: 0.721 idt_A: 0.161 D_B: 0.122 G_B: 0.345 cycle_B: 0.602 idt_B: 0.277 \n",
            "(epoch: 49, iters: 2200, time: 0.310, data: 0.003) D_A: 0.050 G_A: 0.757 cycle_A: 0.542 idt_A: 0.174 D_B: 0.238 G_B: 0.549 cycle_B: 0.581 idt_B: 0.239 \n",
            "(epoch: 49, iters: 2300, time: 1.023, data: 0.003) D_A: 0.053 G_A: 0.634 cycle_A: 1.323 idt_A: 0.231 D_B: 0.069 G_B: 0.633 cycle_B: 0.638 idt_B: 0.462 \n",
            "(epoch: 49, iters: 2400, time: 0.308, data: 0.004) D_A: 0.086 G_A: 0.847 cycle_A: 0.622 idt_A: 0.276 D_B: 0.124 G_B: 0.463 cycle_B: 0.787 idt_B: 0.228 \n",
            "(epoch: 49, iters: 2500, time: 0.309, data: 0.003) D_A: 0.091 G_A: 0.653 cycle_A: 1.018 idt_A: 0.154 D_B: 0.073 G_B: 0.402 cycle_B: 0.527 idt_B: 0.306 \n",
            "saving the latest model (epoch 49, total_iters 75000)\n",
            "End of epoch 49 / 60 \t Time Taken: 815 sec\n",
            "learning rate 0.0000537 -> 0.0000488\n",
            "(epoch: 50, iters: 100, time: 0.415, data: 0.840) D_A: 0.110 G_A: 0.634 cycle_A: 0.788 idt_A: 0.229 D_B: 0.150 G_B: 0.438 cycle_B: 0.599 idt_B: 0.298 \n",
            "(epoch: 50, iters: 200, time: 2.446, data: 0.006) D_A: 0.172 G_A: 0.269 cycle_A: 0.805 idt_A: 0.142 D_B: 0.224 G_B: 0.318 cycle_B: 0.465 idt_B: 0.216 \n",
            "(epoch: 50, iters: 300, time: 0.348, data: 0.005) D_A: 0.089 G_A: 0.651 cycle_A: 0.977 idt_A: 0.150 D_B: 0.455 G_B: 0.041 cycle_B: 0.408 idt_B: 0.371 \n",
            "(epoch: 50, iters: 400, time: 0.308, data: 0.006) D_A: 0.067 G_A: 0.717 cycle_A: 1.013 idt_A: 0.211 D_B: 0.053 G_B: 0.703 cycle_B: 0.596 idt_B: 0.324 \n",
            "(epoch: 50, iters: 500, time: 0.315, data: 0.005) D_A: 0.076 G_A: 0.596 cycle_A: 0.832 idt_A: 0.180 D_B: 0.149 G_B: 0.399 cycle_B: 0.562 idt_B: 0.291 \n",
            "(epoch: 50, iters: 600, time: 1.115, data: 0.013) D_A: 0.114 G_A: 0.418 cycle_A: 0.476 idt_A: 0.124 D_B: 0.107 G_B: 0.484 cycle_B: 0.447 idt_B: 0.195 \n",
            "(epoch: 50, iters: 700, time: 0.357, data: 0.004) D_A: 0.163 G_A: 0.369 cycle_A: 0.795 idt_A: 0.179 D_B: 0.089 G_B: 0.430 cycle_B: 0.570 idt_B: 0.263 \n",
            "(epoch: 50, iters: 800, time: 0.368, data: 0.008) D_A: 0.044 G_A: 0.659 cycle_A: 0.708 idt_A: 0.136 D_B: 0.131 G_B: 0.305 cycle_B: 0.475 idt_B: 0.204 \n",
            "(epoch: 50, iters: 900, time: 0.306, data: 0.006) D_A: 0.067 G_A: 0.288 cycle_A: 1.173 idt_A: 0.075 D_B: 0.088 G_B: 0.425 cycle_B: 0.312 idt_B: 0.385 \n",
            "(epoch: 50, iters: 1000, time: 2.401, data: 0.003) D_A: 0.062 G_A: 0.349 cycle_A: 0.686 idt_A: 0.189 D_B: 0.122 G_B: 0.317 cycle_B: 0.639 idt_B: 0.272 \n",
            "(epoch: 50, iters: 1100, time: 0.350, data: 0.003) D_A: 0.079 G_A: 0.482 cycle_A: 1.094 idt_A: 0.144 D_B: 0.185 G_B: 0.348 cycle_B: 0.481 idt_B: 0.327 \n",
            "(epoch: 50, iters: 1200, time: 0.298, data: 0.003) D_A: 0.081 G_A: 0.885 cycle_A: 0.830 idt_A: 0.206 D_B: 0.078 G_B: 0.500 cycle_B: 0.610 idt_B: 0.245 \n",
            "(epoch: 50, iters: 1300, time: 0.334, data: 0.007) D_A: 0.069 G_A: 0.551 cycle_A: 0.734 idt_A: 0.159 D_B: 0.111 G_B: 0.331 cycle_B: 0.550 idt_B: 0.226 \n",
            "(epoch: 50, iters: 1400, time: 0.984, data: 0.018) D_A: 0.190 G_A: 0.274 cycle_A: 0.640 idt_A: 0.322 D_B: 0.097 G_B: 0.361 cycle_B: 0.564 idt_B: 0.230 \n",
            "(epoch: 50, iters: 1500, time: 0.301, data: 0.004) D_A: 0.025 G_A: 0.802 cycle_A: 0.930 idt_A: 0.176 D_B: 0.125 G_B: 0.425 cycle_B: 0.393 idt_B: 0.404 \n",
            "(epoch: 50, iters: 1600, time: 0.366, data: 0.008) D_A: 0.140 G_A: 0.281 cycle_A: 0.505 idt_A: 0.445 D_B: 0.204 G_B: 0.262 cycle_B: 0.827 idt_B: 0.212 \n",
            "(epoch: 50, iters: 1700, time: 0.372, data: 0.003) D_A: 0.142 G_A: 0.372 cycle_A: 0.776 idt_A: 0.181 D_B: 0.089 G_B: 0.436 cycle_B: 0.568 idt_B: 0.357 \n",
            "(epoch: 50, iters: 1800, time: 1.000, data: 0.004) D_A: 0.074 G_A: 0.468 cycle_A: 0.811 idt_A: 0.154 D_B: 0.160 G_B: 0.560 cycle_B: 0.490 idt_B: 0.208 \n",
            "(epoch: 50, iters: 1900, time: 0.311, data: 0.001) D_A: 0.391 G_A: 0.451 cycle_A: 0.663 idt_A: 0.218 D_B: 0.159 G_B: 0.317 cycle_B: 0.750 idt_B: 0.224 \n",
            "(epoch: 50, iters: 2000, time: 0.323, data: 0.003) D_A: 0.083 G_A: 0.221 cycle_A: 0.755 idt_A: 0.253 D_B: 0.129 G_B: 0.824 cycle_B: 0.709 idt_B: 0.240 \n",
            "(epoch: 50, iters: 2100, time: 0.383, data: 0.003) D_A: 0.116 G_A: 0.432 cycle_A: 0.697 idt_A: 0.249 D_B: 0.162 G_B: 0.238 cycle_B: 0.678 idt_B: 0.171 \n",
            "(epoch: 50, iters: 2200, time: 1.035, data: 0.005) D_A: 0.040 G_A: 0.403 cycle_A: 0.829 idt_A: 0.238 D_B: 0.053 G_B: 0.757 cycle_B: 0.637 idt_B: 0.389 \n",
            "(epoch: 50, iters: 2300, time: 0.305, data: 0.003) D_A: 0.295 G_A: 0.467 cycle_A: 0.991 idt_A: 0.163 D_B: 0.226 G_B: 0.290 cycle_B: 0.557 idt_B: 0.342 \n",
            "(epoch: 50, iters: 2400, time: 0.336, data: 0.003) D_A: 0.078 G_A: 0.630 cycle_A: 0.726 idt_A: 0.145 D_B: 0.266 G_B: 0.228 cycle_B: 0.503 idt_B: 0.245 \n",
            "(epoch: 50, iters: 2500, time: 0.309, data: 0.015) D_A: 0.158 G_A: 0.673 cycle_A: 0.990 idt_A: 0.171 D_B: 0.163 G_B: 0.765 cycle_B: 0.502 idt_B: 0.371 \n",
            "saving the model at the end of epoch 50, iters 77500\n",
            "End of epoch 50 / 60 \t Time Taken: 815 sec\n",
            "learning rate 0.0000488 -> 0.0000439\n",
            "(epoch: 51, iters: 100, time: 2.432, data: 1.043) D_A: 0.255 G_A: 0.814 cycle_A: 0.885 idt_A: 0.291 D_B: 0.121 G_B: 0.510 cycle_B: 0.643 idt_B: 0.291 \n",
            "(epoch: 51, iters: 200, time: 0.308, data: 0.007) D_A: 0.152 G_A: 0.911 cycle_A: 0.817 idt_A: 0.109 D_B: 0.142 G_B: 0.146 cycle_B: 0.437 idt_B: 0.482 \n",
            "(epoch: 51, iters: 300, time: 0.314, data: 0.003) D_A: 0.058 G_A: 0.423 cycle_A: 0.667 idt_A: 0.443 D_B: 0.333 G_B: 0.244 cycle_B: 0.910 idt_B: 0.222 \n",
            "(epoch: 51, iters: 400, time: 0.429, data: 0.019) D_A: 0.153 G_A: 0.270 cycle_A: 0.780 idt_A: 0.150 D_B: 0.153 G_B: 0.256 cycle_B: 0.555 idt_B: 0.281 \n",
            "(epoch: 51, iters: 500, time: 2.364, data: 0.006) D_A: 0.075 G_A: 0.752 cycle_A: 0.853 idt_A: 0.240 D_B: 0.222 G_B: 0.290 cycle_B: 0.706 idt_B: 0.290 \n",
            "(epoch: 51, iters: 600, time: 0.302, data: 0.006) D_A: 0.060 G_A: 0.538 cycle_A: 1.035 idt_A: 0.209 D_B: 0.051 G_B: 0.633 cycle_B: 0.682 idt_B: 0.397 \n",
            "(epoch: 51, iters: 700, time: 0.334, data: 0.020) D_A: 0.230 G_A: 0.476 cycle_A: 1.094 idt_A: 0.287 D_B: 0.125 G_B: 0.401 cycle_B: 0.877 idt_B: 0.277 \n",
            "(epoch: 51, iters: 800, time: 0.306, data: 0.013) D_A: 0.242 G_A: 0.923 cycle_A: 0.965 idt_A: 0.125 D_B: 0.119 G_B: 0.167 cycle_B: 0.297 idt_B: 0.270 \n",
            "(epoch: 51, iters: 900, time: 1.080, data: 0.001) D_A: 0.054 G_A: 0.768 cycle_A: 0.956 idt_A: 0.321 D_B: 0.077 G_B: 0.502 cycle_B: 0.758 idt_B: 0.529 \n",
            "(epoch: 51, iters: 1000, time: 0.308, data: 0.003) D_A: 0.047 G_A: 0.380 cycle_A: 1.197 idt_A: 0.185 D_B: 0.147 G_B: 0.432 cycle_B: 0.525 idt_B: 0.382 \n",
            "(epoch: 51, iters: 1100, time: 0.305, data: 0.012) D_A: 0.112 G_A: 1.032 cycle_A: 0.633 idt_A: 0.367 D_B: 0.148 G_B: 0.461 cycle_B: 0.834 idt_B: 0.192 \n",
            "(epoch: 51, iters: 1200, time: 0.304, data: 0.003) D_A: 0.053 G_A: 0.611 cycle_A: 0.733 idt_A: 0.321 D_B: 0.033 G_B: 0.639 cycle_B: 0.570 idt_B: 0.528 \n",
            "(epoch: 51, iters: 1300, time: 1.040, data: 0.001) D_A: 0.024 G_A: 0.918 cycle_A: 0.680 idt_A: 0.163 D_B: 0.136 G_B: 0.627 cycle_B: 0.495 idt_B: 0.212 \n",
            "(epoch: 51, iters: 1400, time: 0.299, data: 0.004) D_A: 0.047 G_A: 0.608 cycle_A: 0.761 idt_A: 0.146 D_B: 0.081 G_B: 0.288 cycle_B: 0.387 idt_B: 0.220 \n",
            "(epoch: 51, iters: 1500, time: 0.292, data: 0.012) D_A: 0.179 G_A: 1.137 cycle_A: 0.698 idt_A: 0.256 D_B: 0.122 G_B: 0.361 cycle_B: 0.779 idt_B: 0.295 \n",
            "(epoch: 51, iters: 1600, time: 0.314, data: 0.003) D_A: 0.161 G_A: 0.425 cycle_A: 1.580 idt_A: 0.258 D_B: 0.133 G_B: 0.362 cycle_B: 0.642 idt_B: 0.770 \n",
            "(epoch: 51, iters: 1700, time: 1.094, data: 0.006) D_A: 0.156 G_A: 0.272 cycle_A: 0.582 idt_A: 0.306 D_B: 0.439 G_B: 0.592 cycle_B: 0.551 idt_B: 0.277 \n",
            "(epoch: 51, iters: 1800, time: 0.318, data: 0.005) D_A: 0.133 G_A: 0.631 cycle_A: 0.811 idt_A: 0.191 D_B: 0.146 G_B: 0.345 cycle_B: 0.523 idt_B: 0.300 \n",
            "(epoch: 51, iters: 1900, time: 0.376, data: 0.003) D_A: 0.119 G_A: 0.647 cycle_A: 0.829 idt_A: 0.164 D_B: 0.336 G_B: 0.369 cycle_B: 0.524 idt_B: 0.255 \n",
            "(epoch: 51, iters: 2000, time: 0.308, data: 0.008) D_A: 0.132 G_A: 0.989 cycle_A: 0.614 idt_A: 0.181 D_B: 0.145 G_B: 0.656 cycle_B: 0.643 idt_B: 0.235 \n",
            "(epoch: 51, iters: 2100, time: 1.034, data: 0.003) D_A: 0.133 G_A: 0.389 cycle_A: 0.562 idt_A: 0.189 D_B: 0.133 G_B: 0.321 cycle_B: 0.594 idt_B: 0.156 \n",
            "(epoch: 51, iters: 2200, time: 0.341, data: 0.007) D_A: 0.065 G_A: 0.555 cycle_A: 0.987 idt_A: 0.195 D_B: 0.285 G_B: 0.459 cycle_B: 0.549 idt_B: 0.424 \n",
            "(epoch: 51, iters: 2300, time: 0.310, data: 0.003) D_A: 0.055 G_A: 0.539 cycle_A: 0.799 idt_A: 0.106 D_B: 0.336 G_B: 0.184 cycle_B: 0.357 idt_B: 0.335 \n",
            "(epoch: 51, iters: 2400, time: 0.293, data: 0.005) D_A: 0.064 G_A: 0.657 cycle_A: 0.852 idt_A: 0.133 D_B: 0.082 G_B: 0.348 cycle_B: 0.531 idt_B: 0.243 \n",
            "(epoch: 51, iters: 2500, time: 2.253, data: 0.004) D_A: 0.036 G_A: 0.768 cycle_A: 0.962 idt_A: 0.210 D_B: 0.105 G_B: 0.534 cycle_B: 0.547 idt_B: 0.310 \n",
            "saving the latest model (epoch 51, total_iters 80000)\n",
            "End of epoch 51 / 60 \t Time Taken: 821 sec\n",
            "learning rate 0.0000439 -> 0.0000390\n",
            "(epoch: 52, iters: 100, time: 0.351, data: 1.485) D_A: 0.117 G_A: 0.501 cycle_A: 0.540 idt_A: 0.118 D_B: 0.027 G_B: 0.877 cycle_B: 0.377 idt_B: 0.194 \n",
            "(epoch: 52, iters: 200, time: 0.309, data: 0.004) D_A: 0.057 G_A: 0.723 cycle_A: 0.638 idt_A: 0.131 D_B: 0.088 G_B: 0.707 cycle_B: 0.499 idt_B: 0.212 \n",
            "(epoch: 52, iters: 300, time: 0.342, data: 0.014) D_A: 0.136 G_A: 0.756 cycle_A: 0.706 idt_A: 0.183 D_B: 0.067 G_B: 0.377 cycle_B: 0.616 idt_B: 0.248 \n",
            "(epoch: 52, iters: 400, time: 2.436, data: 0.004) D_A: 0.184 G_A: 0.586 cycle_A: 1.118 idt_A: 0.298 D_B: 0.098 G_B: 0.534 cycle_B: 0.478 idt_B: 0.377 \n",
            "(epoch: 52, iters: 500, time: 0.317, data: 0.004) D_A: 0.111 G_A: 0.631 cycle_A: 0.924 idt_A: 0.296 D_B: 0.121 G_B: 0.477 cycle_B: 0.784 idt_B: 0.282 \n",
            "(epoch: 52, iters: 600, time: 0.385, data: 0.011) D_A: 0.146 G_A: 0.500 cycle_A: 0.706 idt_A: 0.223 D_B: 0.199 G_B: 0.172 cycle_B: 0.700 idt_B: 0.244 \n",
            "(epoch: 52, iters: 700, time: 0.353, data: 0.003) D_A: 0.152 G_A: 0.318 cycle_A: 0.640 idt_A: 0.249 D_B: 0.268 G_B: 0.383 cycle_B: 0.620 idt_B: 0.193 \n",
            "(epoch: 52, iters: 800, time: 1.024, data: 0.003) D_A: 0.164 G_A: 0.582 cycle_A: 0.671 idt_A: 0.161 D_B: 0.111 G_B: 0.413 cycle_B: 0.510 idt_B: 0.235 \n",
            "(epoch: 52, iters: 900, time: 0.307, data: 0.004) D_A: 0.114 G_A: 1.036 cycle_A: 0.869 idt_A: 0.155 D_B: 0.180 G_B: 0.268 cycle_B: 0.541 idt_B: 0.313 \n",
            "(epoch: 52, iters: 1000, time: 0.304, data: 0.013) D_A: 0.037 G_A: 0.767 cycle_A: 0.962 idt_A: 0.107 D_B: 0.117 G_B: 0.468 cycle_B: 0.411 idt_B: 0.439 \n",
            "(epoch: 52, iters: 1100, time: 0.305, data: 0.007) D_A: 0.109 G_A: 0.408 cycle_A: 0.688 idt_A: 0.215 D_B: 0.136 G_B: 0.415 cycle_B: 0.534 idt_B: 0.188 \n",
            "(epoch: 52, iters: 1200, time: 1.033, data: 0.003) D_A: 0.148 G_A: 0.556 cycle_A: 0.734 idt_A: 0.152 D_B: 0.088 G_B: 0.212 cycle_B: 0.460 idt_B: 0.267 \n",
            "(epoch: 52, iters: 1300, time: 0.309, data: 0.004) D_A: 0.067 G_A: 0.547 cycle_A: 0.436 idt_A: 0.316 D_B: 0.332 G_B: 0.510 cycle_B: 0.725 idt_B: 1.285 \n",
            "(epoch: 52, iters: 1400, time: 0.307, data: 0.030) D_A: 0.065 G_A: 0.708 cycle_A: 0.941 idt_A: 0.293 D_B: 0.144 G_B: 0.536 cycle_B: 0.599 idt_B: 0.265 \n",
            "(epoch: 52, iters: 1500, time: 0.337, data: 0.006) D_A: 0.081 G_A: 0.472 cycle_A: 0.840 idt_A: 0.124 D_B: 0.078 G_B: 0.507 cycle_B: 0.464 idt_B: 0.333 \n",
            "(epoch: 52, iters: 1600, time: 1.025, data: 0.003) D_A: 0.163 G_A: 0.484 cycle_A: 0.838 idt_A: 0.147 D_B: 0.174 G_B: 0.362 cycle_B: 0.615 idt_B: 0.357 \n",
            "(epoch: 52, iters: 1700, time: 0.302, data: 0.003) D_A: 0.134 G_A: 0.445 cycle_A: 0.692 idt_A: 0.203 D_B: 0.098 G_B: 0.583 cycle_B: 0.694 idt_B: 0.212 \n",
            "(epoch: 52, iters: 1800, time: 0.304, data: 0.003) D_A: 0.105 G_A: 0.746 cycle_A: 0.617 idt_A: 0.130 D_B: 0.291 G_B: 0.244 cycle_B: 0.364 idt_B: 0.217 \n",
            "(epoch: 52, iters: 1900, time: 0.323, data: 0.008) D_A: 0.052 G_A: 0.470 cycle_A: 0.879 idt_A: 0.133 D_B: 0.283 G_B: 0.367 cycle_B: 0.445 idt_B: 0.188 \n",
            "(epoch: 52, iters: 2000, time: 2.368, data: 0.012) D_A: 0.104 G_A: 0.404 cycle_A: 0.644 idt_A: 0.161 D_B: 0.115 G_B: 0.266 cycle_B: 0.534 idt_B: 0.205 \n",
            "(epoch: 52, iters: 2100, time: 0.307, data: 0.006) D_A: 0.072 G_A: 0.328 cycle_A: 0.553 idt_A: 0.163 D_B: 0.121 G_B: 0.571 cycle_B: 0.519 idt_B: 0.281 \n",
            "(epoch: 52, iters: 2200, time: 0.297, data: 0.003) D_A: 0.116 G_A: 0.496 cycle_A: 0.961 idt_A: 0.138 D_B: 0.222 G_B: 0.791 cycle_B: 0.473 idt_B: 0.335 \n",
            "(epoch: 52, iters: 2300, time: 0.398, data: 0.006) D_A: 0.199 G_A: 0.999 cycle_A: 0.647 idt_A: 0.161 D_B: 0.392 G_B: 0.048 cycle_B: 0.453 idt_B: 0.241 \n",
            "(epoch: 52, iters: 2400, time: 1.145, data: 0.003) D_A: 0.116 G_A: 0.797 cycle_A: 1.307 idt_A: 0.347 D_B: 0.100 G_B: 0.398 cycle_B: 0.835 idt_B: 0.675 \n",
            "(epoch: 52, iters: 2500, time: 0.306, data: 0.005) D_A: 0.141 G_A: 0.298 cycle_A: 0.696 idt_A: 0.154 D_B: 0.117 G_B: 0.414 cycle_B: 0.532 idt_B: 0.245 \n",
            "End of epoch 52 / 60 \t Time Taken: 822 sec\n",
            "learning rate 0.0000390 -> 0.0000341\n",
            "(epoch: 53, iters: 100, time: 0.305, data: 0.676) D_A: 0.036 G_A: 0.707 cycle_A: 1.025 idt_A: 0.152 D_B: 0.094 G_B: 0.526 cycle_B: 0.511 idt_B: 0.329 \n",
            "(epoch: 53, iters: 200, time: 0.343, data: 0.020) D_A: 0.058 G_A: 0.719 cycle_A: 1.143 idt_A: 0.162 D_B: 0.189 G_B: 0.271 cycle_B: 0.541 idt_B: 0.244 \n",
            "(epoch: 53, iters: 300, time: 2.392, data: 0.004) D_A: 0.037 G_A: 0.863 cycle_A: 1.402 idt_A: 0.264 D_B: 0.067 G_B: 0.547 cycle_B: 0.761 idt_B: 0.474 \n",
            "(epoch: 53, iters: 400, time: 0.347, data: 0.005) D_A: 0.101 G_A: 0.588 cycle_A: 1.102 idt_A: 0.246 D_B: 0.156 G_B: 0.218 cycle_B: 0.730 idt_B: 0.413 \n",
            "(epoch: 53, iters: 500, time: 0.305, data: 0.006) D_A: 0.122 G_A: 0.330 cycle_A: 0.952 idt_A: 0.204 D_B: 0.043 G_B: 0.712 cycle_B: 0.659 idt_B: 0.439 \n",
            "(epoch: 53, iters: 600, time: 0.381, data: 0.003) D_A: 0.109 G_A: 0.431 cycle_A: 0.550 idt_A: 0.367 D_B: 0.190 G_B: 0.518 cycle_B: 0.769 idt_B: 0.243 \n",
            "(epoch: 53, iters: 700, time: 1.006, data: 0.017) D_A: 0.106 G_A: 0.514 cycle_A: 0.807 idt_A: 0.108 D_B: 0.257 G_B: 0.327 cycle_B: 0.360 idt_B: 0.292 \n",
            "(epoch: 53, iters: 800, time: 0.331, data: 0.004) D_A: 0.089 G_A: 0.408 cycle_A: 0.822 idt_A: 0.139 D_B: 0.133 G_B: 0.208 cycle_B: 0.443 idt_B: 0.211 \n",
            "(epoch: 53, iters: 900, time: 0.336, data: 0.004) D_A: 0.173 G_A: 0.907 cycle_A: 0.975 idt_A: 0.251 D_B: 0.362 G_B: 0.263 cycle_B: 0.572 idt_B: 0.328 \n",
            "(epoch: 53, iters: 1000, time: 0.314, data: 0.023) D_A: 0.102 G_A: 0.634 cycle_A: 0.780 idt_A: 0.254 D_B: 0.069 G_B: 0.604 cycle_B: 0.609 idt_B: 0.222 \n",
            "(epoch: 53, iters: 1100, time: 1.200, data: 0.003) D_A: 0.233 G_A: 0.300 cycle_A: 0.598 idt_A: 0.146 D_B: 0.279 G_B: 0.138 cycle_B: 0.496 idt_B: 0.177 \n",
            "(epoch: 53, iters: 1200, time: 0.299, data: 0.003) D_A: 0.038 G_A: 0.545 cycle_A: 0.533 idt_A: 0.106 D_B: 0.110 G_B: 0.759 cycle_B: 0.401 idt_B: 0.170 \n",
            "(epoch: 53, iters: 1300, time: 0.372, data: 0.012) D_A: 0.160 G_A: 0.737 cycle_A: 0.959 idt_A: 0.100 D_B: 0.232 G_B: 0.298 cycle_B: 0.398 idt_B: 0.355 \n",
            "(epoch: 53, iters: 1400, time: 0.301, data: 0.012) D_A: 0.302 G_A: 0.878 cycle_A: 0.747 idt_A: 0.238 D_B: 0.134 G_B: 0.545 cycle_B: 0.633 idt_B: 0.391 \n",
            "(epoch: 53, iters: 1500, time: 2.478, data: 0.005) D_A: 0.114 G_A: 0.366 cycle_A: 0.801 idt_A: 0.197 D_B: 0.104 G_B: 0.497 cycle_B: 0.740 idt_B: 0.255 \n",
            "(epoch: 53, iters: 1600, time: 0.316, data: 0.004) D_A: 0.100 G_A: 0.391 cycle_A: 0.697 idt_A: 0.173 D_B: 0.080 G_B: 0.414 cycle_B: 0.632 idt_B: 0.198 \n",
            "(epoch: 53, iters: 1700, time: 0.305, data: 0.008) D_A: 0.144 G_A: 0.708 cycle_A: 0.829 idt_A: 0.189 D_B: 0.117 G_B: 0.494 cycle_B: 0.547 idt_B: 0.336 \n",
            "(epoch: 53, iters: 1800, time: 0.309, data: 0.004) D_A: 0.110 G_A: 0.663 cycle_A: 0.883 idt_A: 0.190 D_B: 0.196 G_B: 0.296 cycle_B: 0.635 idt_B: 0.346 \n",
            "(epoch: 53, iters: 1900, time: 1.102, data: 0.017) D_A: 0.061 G_A: 0.743 cycle_A: 1.175 idt_A: 0.156 D_B: 0.053 G_B: 0.612 cycle_B: 0.456 idt_B: 0.380 \n",
            "(epoch: 53, iters: 2000, time: 0.314, data: 0.004) D_A: 0.052 G_A: 0.430 cycle_A: 1.144 idt_A: 0.217 D_B: 0.169 G_B: 0.259 cycle_B: 0.660 idt_B: 0.349 \n",
            "(epoch: 53, iters: 2100, time: 0.309, data: 0.005) D_A: 0.093 G_A: 0.483 cycle_A: 1.246 idt_A: 0.283 D_B: 0.261 G_B: 0.269 cycle_B: 0.575 idt_B: 0.366 \n",
            "(epoch: 53, iters: 2200, time: 0.309, data: 0.001) D_A: 0.087 G_A: 0.563 cycle_A: 0.532 idt_A: 0.116 D_B: 0.167 G_B: 0.523 cycle_B: 0.398 idt_B: 0.175 \n",
            "(epoch: 53, iters: 2300, time: 1.038, data: 0.003) D_A: 0.047 G_A: 0.691 cycle_A: 0.626 idt_A: 0.105 D_B: 0.087 G_B: 0.217 cycle_B: 0.439 idt_B: 0.232 \n",
            "(epoch: 53, iters: 2400, time: 0.311, data: 0.007) D_A: 0.187 G_A: 0.527 cycle_A: 0.960 idt_A: 0.172 D_B: 0.105 G_B: 0.461 cycle_B: 0.520 idt_B: 0.464 \n",
            "(epoch: 53, iters: 2500, time: 0.311, data: 0.005) D_A: 0.166 G_A: 0.623 cycle_A: 0.848 idt_A: 0.199 D_B: 0.127 G_B: 0.413 cycle_B: 0.699 idt_B: 0.243 \n",
            "saving the latest model (epoch 53, total_iters 85000)\n",
            "End of epoch 53 / 60 \t Time Taken: 819 sec\n",
            "learning rate 0.0000341 -> 0.0000293\n",
            "(epoch: 54, iters: 100, time: 0.338, data: 0.778) D_A: 0.063 G_A: 0.577 cycle_A: 0.604 idt_A: 0.184 D_B: 0.198 G_B: 0.322 cycle_B: 0.613 idt_B: 0.182 \n",
            "(epoch: 54, iters: 200, time: 2.453, data: 0.009) D_A: 0.049 G_A: 0.724 cycle_A: 1.200 idt_A: 0.239 D_B: 0.107 G_B: 0.478 cycle_B: 0.552 idt_B: 0.615 \n",
            "(epoch: 54, iters: 300, time: 0.309, data: 0.005) D_A: 0.102 G_A: 0.495 cycle_A: 0.613 idt_A: 0.135 D_B: 0.143 G_B: 0.292 cycle_B: 0.468 idt_B: 0.253 \n",
            "(epoch: 54, iters: 400, time: 0.351, data: 0.014) D_A: 0.122 G_A: 0.797 cycle_A: 0.839 idt_A: 0.175 D_B: 0.193 G_B: 0.357 cycle_B: 0.446 idt_B: 0.307 \n",
            "(epoch: 54, iters: 500, time: 0.325, data: 0.003) D_A: 0.183 G_A: 0.230 cycle_A: 0.832 idt_A: 0.156 D_B: 0.169 G_B: 0.563 cycle_B: 0.507 idt_B: 0.315 \n",
            "(epoch: 54, iters: 600, time: 1.075, data: 0.003) D_A: 0.098 G_A: 0.676 cycle_A: 0.757 idt_A: 0.186 D_B: 0.080 G_B: 0.459 cycle_B: 0.586 idt_B: 0.259 \n",
            "(epoch: 54, iters: 700, time: 0.319, data: 0.005) D_A: 0.061 G_A: 0.647 cycle_A: 0.795 idt_A: 0.134 D_B: 0.060 G_B: 0.576 cycle_B: 0.501 idt_B: 0.265 \n",
            "(epoch: 54, iters: 800, time: 0.307, data: 0.010) D_A: 0.057 G_A: 0.334 cycle_A: 0.689 idt_A: 0.130 D_B: 0.132 G_B: 0.319 cycle_B: 0.462 idt_B: 0.262 \n",
            "(epoch: 54, iters: 900, time: 0.317, data: 0.003) D_A: 0.050 G_A: 0.530 cycle_A: 0.770 idt_A: 0.184 D_B: 0.127 G_B: 0.351 cycle_B: 0.571 idt_B: 0.293 \n",
            "(epoch: 54, iters: 1000, time: 2.400, data: 0.004) D_A: 0.061 G_A: 0.558 cycle_A: 1.032 idt_A: 0.185 D_B: 0.213 G_B: 0.258 cycle_B: 0.531 idt_B: 0.371 \n",
            "(epoch: 54, iters: 1100, time: 0.367, data: 0.005) D_A: 0.068 G_A: 0.530 cycle_A: 0.602 idt_A: 0.164 D_B: 0.188 G_B: 0.416 cycle_B: 0.582 idt_B: 0.201 \n",
            "(epoch: 54, iters: 1200, time: 0.292, data: 0.006) D_A: 0.076 G_A: 0.657 cycle_A: 0.571 idt_A: 0.109 D_B: 0.110 G_B: 0.441 cycle_B: 0.371 idt_B: 0.168 \n",
            "(epoch: 54, iters: 1300, time: 0.293, data: 0.003) D_A: 0.118 G_A: 0.545 cycle_A: 0.732 idt_A: 0.170 D_B: 0.060 G_B: 0.376 cycle_B: 0.518 idt_B: 0.220 \n",
            "(epoch: 54, iters: 1400, time: 1.247, data: 0.007) D_A: 0.071 G_A: 0.797 cycle_A: 0.746 idt_A: 0.105 D_B: 0.251 G_B: 0.169 cycle_B: 0.301 idt_B: 0.232 \n",
            "(epoch: 54, iters: 1500, time: 0.303, data: 0.004) D_A: 0.041 G_A: 0.875 cycle_A: 0.713 idt_A: 0.181 D_B: 0.313 G_B: 0.529 cycle_B: 0.531 idt_B: 0.203 \n",
            "(epoch: 54, iters: 1600, time: 0.368, data: 0.004) D_A: 0.134 G_A: 0.643 cycle_A: 1.957 idt_A: 0.112 D_B: 0.248 G_B: 0.267 cycle_B: 0.315 idt_B: 0.859 \n",
            "(epoch: 54, iters: 1700, time: 0.305, data: 0.010) D_A: 0.251 G_A: 0.553 cycle_A: 0.679 idt_A: 0.156 D_B: 0.098 G_B: 0.613 cycle_B: 0.566 idt_B: 0.236 \n",
            "(epoch: 54, iters: 1800, time: 1.174, data: 0.003) D_A: 0.158 G_A: 0.448 cycle_A: 0.702 idt_A: 0.222 D_B: 0.150 G_B: 0.369 cycle_B: 0.438 idt_B: 0.262 \n",
            "(epoch: 54, iters: 1900, time: 0.290, data: 0.005) D_A: 0.065 G_A: 0.749 cycle_A: 0.713 idt_A: 0.160 D_B: 0.215 G_B: 0.248 cycle_B: 0.433 idt_B: 0.191 \n",
            "(epoch: 54, iters: 2000, time: 0.343, data: 0.003) D_A: 0.085 G_A: 0.170 cycle_A: 0.661 idt_A: 0.206 D_B: 0.257 G_B: 0.237 cycle_B: 0.484 idt_B: 0.210 \n",
            "(epoch: 54, iters: 2100, time: 0.306, data: 0.001) D_A: 0.049 G_A: 0.724 cycle_A: 0.829 idt_A: 0.149 D_B: 0.153 G_B: 0.325 cycle_B: 0.516 idt_B: 0.403 \n",
            "(epoch: 54, iters: 2200, time: 1.025, data: 0.006) D_A: 0.125 G_A: 0.585 cycle_A: 0.731 idt_A: 0.144 D_B: 0.263 G_B: 0.216 cycle_B: 0.463 idt_B: 0.284 \n",
            "(epoch: 54, iters: 2300, time: 0.308, data: 0.008) D_A: 0.127 G_A: 0.422 cycle_A: 0.971 idt_A: 0.195 D_B: 0.222 G_B: 0.618 cycle_B: 0.521 idt_B: 0.255 \n",
            "(epoch: 54, iters: 2400, time: 0.396, data: 0.003) D_A: 0.090 G_A: 0.718 cycle_A: 0.905 idt_A: 0.180 D_B: 0.133 G_B: 0.590 cycle_B: 0.483 idt_B: 0.250 \n",
            "(epoch: 54, iters: 2500, time: 0.310, data: 0.006) D_A: 0.074 G_A: 0.529 cycle_A: 0.741 idt_A: 0.212 D_B: 0.154 G_B: 0.433 cycle_B: 0.683 idt_B: 0.263 \n",
            "End of epoch 54 / 60 \t Time Taken: 819 sec\n",
            "learning rate 0.0000293 -> 0.0000244\n",
            "(epoch: 55, iters: 100, time: 2.564, data: 1.050) D_A: 0.036 G_A: 0.973 cycle_A: 0.595 idt_A: 0.223 D_B: 0.175 G_B: 0.429 cycle_B: 0.630 idt_B: 0.197 \n",
            "(epoch: 55, iters: 200, time: 0.358, data: 0.004) D_A: 0.161 G_A: 0.602 cycle_A: 0.831 idt_A: 0.188 D_B: 0.175 G_B: 0.304 cycle_B: 0.596 idt_B: 0.361 \n",
            "(epoch: 55, iters: 300, time: 0.308, data: 0.004) D_A: 0.210 G_A: 0.691 cycle_A: 0.857 idt_A: 0.200 D_B: 0.229 G_B: 0.304 cycle_B: 0.682 idt_B: 0.296 \n",
            "(epoch: 55, iters: 400, time: 0.303, data: 0.013) D_A: 0.249 G_A: 0.147 cycle_A: 0.680 idt_A: 0.172 D_B: 0.105 G_B: 0.123 cycle_B: 0.560 idt_B: 0.230 \n",
            "(epoch: 55, iters: 500, time: 2.401, data: 0.003) D_A: 0.152 G_A: 0.750 cycle_A: 0.789 idt_A: 0.274 D_B: 0.096 G_B: 0.476 cycle_B: 0.714 idt_B: 0.256 \n",
            "(epoch: 55, iters: 600, time: 0.345, data: 0.004) D_A: 0.063 G_A: 0.648 cycle_A: 1.030 idt_A: 0.159 D_B: 0.128 G_B: 0.618 cycle_B: 0.578 idt_B: 0.206 \n",
            "(epoch: 55, iters: 700, time: 0.378, data: 0.018) D_A: 0.130 G_A: 0.803 cycle_A: 0.813 idt_A: 0.153 D_B: 0.121 G_B: 0.617 cycle_B: 0.469 idt_B: 0.337 \n",
            "(epoch: 55, iters: 800, time: 0.305, data: 0.001) D_A: 0.163 G_A: 0.414 cycle_A: 0.605 idt_A: 0.203 D_B: 0.263 G_B: 0.365 cycle_B: 0.558 idt_B: 0.201 \n",
            "(epoch: 55, iters: 900, time: 1.066, data: 0.003) D_A: 0.188 G_A: 0.498 cycle_A: 0.864 idt_A: 0.229 D_B: 0.064 G_B: 0.186 cycle_B: 0.593 idt_B: 0.378 \n",
            "(epoch: 55, iters: 1000, time: 0.306, data: 0.001) D_A: 0.052 G_A: 0.921 cycle_A: 0.740 idt_A: 0.177 D_B: 0.153 G_B: 0.496 cycle_B: 0.462 idt_B: 0.330 \n",
            "(epoch: 55, iters: 1100, time: 0.626, data: 0.010) D_A: 0.039 G_A: 0.633 cycle_A: 1.320 idt_A: 0.094 D_B: 0.083 G_B: 0.306 cycle_B: 0.336 idt_B: 0.889 \n",
            "(epoch: 55, iters: 1200, time: 0.306, data: 0.018) D_A: 0.158 G_A: 0.400 cycle_A: 0.738 idt_A: 0.194 D_B: 0.133 G_B: 0.439 cycle_B: 0.671 idt_B: 0.170 \n",
            "(epoch: 55, iters: 1300, time: 1.062, data: 0.010) D_A: 0.085 G_A: 0.597 cycle_A: 0.542 idt_A: 0.191 D_B: 0.209 G_B: 0.239 cycle_B: 0.596 idt_B: 0.151 \n",
            "(epoch: 55, iters: 1400, time: 0.311, data: 0.005) D_A: 0.127 G_A: 0.518 cycle_A: 0.818 idt_A: 0.134 D_B: 0.226 G_B: 0.490 cycle_B: 0.548 idt_B: 0.379 \n",
            "(epoch: 55, iters: 1500, time: 0.323, data: 0.004) D_A: 0.050 G_A: 0.640 cycle_A: 0.589 idt_A: 0.146 D_B: 0.170 G_B: 0.245 cycle_B: 0.462 idt_B: 0.326 \n",
            "(epoch: 55, iters: 1600, time: 0.311, data: 0.015) D_A: 0.304 G_A: 0.410 cycle_A: 0.579 idt_A: 0.177 D_B: 0.056 G_B: 0.492 cycle_B: 0.571 idt_B: 0.196 \n",
            "(epoch: 55, iters: 1700, time: 1.080, data: 0.005) D_A: 0.284 G_A: 0.725 cycle_A: 0.764 idt_A: 0.186 D_B: 0.140 G_B: 0.299 cycle_B: 0.537 idt_B: 0.247 \n",
            "(epoch: 55, iters: 1800, time: 0.322, data: 0.004) D_A: 0.293 G_A: 0.794 cycle_A: 0.741 idt_A: 0.156 D_B: 0.123 G_B: 0.659 cycle_B: 0.530 idt_B: 0.295 \n",
            "(epoch: 55, iters: 1900, time: 0.333, data: 0.006) D_A: 0.074 G_A: 0.754 cycle_A: 0.581 idt_A: 0.145 D_B: 0.164 G_B: 0.534 cycle_B: 0.402 idt_B: 0.200 \n",
            "(epoch: 55, iters: 2000, time: 0.311, data: 0.003) D_A: 0.045 G_A: 0.707 cycle_A: 1.205 idt_A: 0.165 D_B: 0.092 G_B: 0.678 cycle_B: 0.599 idt_B: 0.371 \n",
            "(epoch: 55, iters: 2100, time: 1.029, data: 0.001) D_A: 0.041 G_A: 1.027 cycle_A: 0.670 idt_A: 0.214 D_B: 0.116 G_B: 0.344 cycle_B: 0.653 idt_B: 0.611 \n",
            "(epoch: 55, iters: 2200, time: 0.312, data: 0.005) D_A: 0.241 G_A: 0.446 cycle_A: 1.062 idt_A: 0.199 D_B: 0.173 G_B: 0.233 cycle_B: 0.620 idt_B: 0.529 \n",
            "(epoch: 55, iters: 2300, time: 0.376, data: 0.005) D_A: 0.194 G_A: 0.429 cycle_A: 0.659 idt_A: 0.243 D_B: 0.121 G_B: 0.415 cycle_B: 0.689 idt_B: 0.275 \n",
            "(epoch: 55, iters: 2400, time: 0.422, data: 0.001) D_A: 0.059 G_A: 0.465 cycle_A: 0.669 idt_A: 0.271 D_B: 0.145 G_B: 0.480 cycle_B: 0.838 idt_B: 0.348 \n",
            "(epoch: 55, iters: 2500, time: 2.207, data: 0.004) D_A: 0.063 G_A: 0.733 cycle_A: 0.716 idt_A: 0.218 D_B: 0.186 G_B: 0.570 cycle_B: 0.591 idt_B: 0.268 \n",
            "saving the latest model (epoch 55, total_iters 90000)\n",
            "saving the model at the end of epoch 55, iters 90000\n",
            "End of epoch 55 / 60 \t Time Taken: 827 sec\n",
            "learning rate 0.0000244 -> 0.0000195\n",
            "(epoch: 56, iters: 100, time: 0.309, data: 1.865) D_A: 0.052 G_A: 0.775 cycle_A: 0.953 idt_A: 0.102 D_B: 0.135 G_B: 0.436 cycle_B: 0.381 idt_B: 0.174 \n",
            "(epoch: 56, iters: 200, time: 0.341, data: 0.005) D_A: 0.125 G_A: 0.553 cycle_A: 0.752 idt_A: 0.141 D_B: 0.207 G_B: 0.166 cycle_B: 0.516 idt_B: 0.287 \n",
            "(epoch: 56, iters: 300, time: 0.305, data: 0.003) D_A: 0.061 G_A: 0.632 cycle_A: 0.603 idt_A: 0.170 D_B: 0.134 G_B: 0.407 cycle_B: 0.533 idt_B: 0.211 \n",
            "(epoch: 56, iters: 400, time: 2.616, data: 0.003) D_A: 0.068 G_A: 0.685 cycle_A: 1.250 idt_A: 0.298 D_B: 0.101 G_B: 0.370 cycle_B: 0.613 idt_B: 0.535 \n",
            "(epoch: 56, iters: 500, time: 0.458, data: 0.004) D_A: 0.213 G_A: 0.574 cycle_A: 0.745 idt_A: 0.191 D_B: 0.152 G_B: 0.492 cycle_B: 0.569 idt_B: 0.302 \n",
            "(epoch: 56, iters: 600, time: 0.309, data: 0.008) D_A: 0.058 G_A: 0.539 cycle_A: 0.669 idt_A: 0.138 D_B: 0.061 G_B: 0.462 cycle_B: 0.503 idt_B: 0.245 \n",
            "(epoch: 56, iters: 700, time: 0.307, data: 0.005) D_A: 0.178 G_A: 0.582 cycle_A: 0.686 idt_A: 0.218 D_B: 0.107 G_B: 0.522 cycle_B: 0.576 idt_B: 0.366 \n",
            "(epoch: 56, iters: 800, time: 1.049, data: 0.012) D_A: 0.077 G_A: 0.547 cycle_A: 0.895 idt_A: 0.159 D_B: 0.118 G_B: 0.316 cycle_B: 0.516 idt_B: 0.222 \n",
            "(epoch: 56, iters: 900, time: 0.341, data: 0.005) D_A: 0.171 G_A: 0.618 cycle_A: 1.031 idt_A: 0.178 D_B: 0.075 G_B: 0.553 cycle_B: 0.564 idt_B: 0.286 \n",
            "(epoch: 56, iters: 1000, time: 0.392, data: 0.012) D_A: 0.046 G_A: 1.160 cycle_A: 0.694 idt_A: 0.188 D_B: 0.082 G_B: 0.533 cycle_B: 0.608 idt_B: 0.282 \n",
            "(epoch: 56, iters: 1100, time: 0.358, data: 0.002) D_A: 0.085 G_A: 0.525 cycle_A: 0.537 idt_A: 0.110 D_B: 0.162 G_B: 0.417 cycle_B: 0.388 idt_B: 0.167 \n",
            "(epoch: 56, iters: 1200, time: 1.052, data: 0.004) D_A: 0.089 G_A: 0.560 cycle_A: 0.645 idt_A: 0.106 D_B: 0.175 G_B: 0.536 cycle_B: 0.392 idt_B: 0.159 \n",
            "(epoch: 56, iters: 1300, time: 0.378, data: 0.005) D_A: 0.097 G_A: 0.827 cycle_A: 0.785 idt_A: 0.126 D_B: 0.177 G_B: 0.417 cycle_B: 0.317 idt_B: 0.322 \n",
            "(epoch: 56, iters: 1400, time: 0.307, data: 0.007) D_A: 0.048 G_A: 0.675 cycle_A: 0.803 idt_A: 0.145 D_B: 0.116 G_B: 0.364 cycle_B: 0.398 idt_B: 0.336 \n",
            "(epoch: 56, iters: 1500, time: 0.336, data: 0.001) D_A: 0.115 G_A: 1.006 cycle_A: 0.926 idt_A: 0.256 D_B: 0.197 G_B: 0.755 cycle_B: 0.545 idt_B: 0.433 \n",
            "(epoch: 56, iters: 1600, time: 1.083, data: 0.003) D_A: 0.077 G_A: 0.590 cycle_A: 0.678 idt_A: 0.075 D_B: 0.314 G_B: 0.531 cycle_B: 0.332 idt_B: 0.199 \n",
            "(epoch: 56, iters: 1700, time: 0.299, data: 0.004) D_A: 0.154 G_A: 0.444 cycle_A: 0.691 idt_A: 0.291 D_B: 0.301 G_B: 0.454 cycle_B: 0.760 idt_B: 0.167 \n",
            "(epoch: 56, iters: 1800, time: 0.508, data: 0.004) D_A: 0.039 G_A: 0.894 cycle_A: 0.823 idt_A: 0.272 D_B: 0.286 G_B: 0.519 cycle_B: 0.778 idt_B: 0.290 \n",
            "(epoch: 56, iters: 1900, time: 0.308, data: 0.006) D_A: 0.136 G_A: 0.336 cycle_A: 0.658 idt_A: 0.260 D_B: 0.113 G_B: 0.849 cycle_B: 0.736 idt_B: 0.233 \n",
            "(epoch: 56, iters: 2000, time: 2.335, data: 0.005) D_A: 0.114 G_A: 0.645 cycle_A: 0.691 idt_A: 0.126 D_B: 0.166 G_B: 0.341 cycle_B: 0.465 idt_B: 0.209 \n",
            "(epoch: 56, iters: 2100, time: 0.308, data: 0.007) D_A: 0.084 G_A: 0.488 cycle_A: 0.831 idt_A: 0.132 D_B: 0.323 G_B: 0.159 cycle_B: 0.485 idt_B: 0.357 \n",
            "(epoch: 56, iters: 2200, time: 0.305, data: 0.003) D_A: 0.252 G_A: 0.514 cycle_A: 0.674 idt_A: 0.194 D_B: 0.078 G_B: 0.434 cycle_B: 0.499 idt_B: 0.202 \n",
            "(epoch: 56, iters: 2300, time: 0.294, data: 0.005) D_A: 0.075 G_A: 0.211 cycle_A: 0.546 idt_A: 0.274 D_B: 0.097 G_B: 0.516 cycle_B: 0.684 idt_B: 0.223 \n",
            "(epoch: 56, iters: 2400, time: 1.084, data: 0.005) D_A: 0.043 G_A: 0.495 cycle_A: 0.657 idt_A: 0.208 D_B: 0.137 G_B: 0.349 cycle_B: 0.679 idt_B: 0.201 \n",
            "(epoch: 56, iters: 2500, time: 0.307, data: 0.004) D_A: 0.154 G_A: 0.694 cycle_A: 0.799 idt_A: 0.190 D_B: 0.069 G_B: 0.642 cycle_B: 0.525 idt_B: 0.295 \n",
            "End of epoch 56 / 60 \t Time Taken: 829 sec\n",
            "learning rate 0.0000195 -> 0.0000146\n",
            "(epoch: 57, iters: 100, time: 0.327, data: 1.013) D_A: 0.096 G_A: 0.658 cycle_A: 0.642 idt_A: 0.206 D_B: 0.074 G_B: 0.509 cycle_B: 0.684 idt_B: 0.215 \n",
            "(epoch: 57, iters: 200, time: 0.308, data: 0.005) D_A: 0.165 G_A: 0.827 cycle_A: 0.806 idt_A: 0.206 D_B: 0.107 G_B: 0.589 cycle_B: 0.574 idt_B: 0.268 \n",
            "(epoch: 57, iters: 300, time: 2.477, data: 0.003) D_A: 0.139 G_A: 0.286 cycle_A: 0.710 idt_A: 0.128 D_B: 0.125 G_B: 0.454 cycle_B: 0.473 idt_B: 0.317 \n",
            "(epoch: 57, iters: 400, time: 0.412, data: 0.006) D_A: 0.072 G_A: 0.544 cycle_A: 0.708 idt_A: 0.154 D_B: 0.060 G_B: 0.660 cycle_B: 0.527 idt_B: 0.200 \n",
            "(epoch: 57, iters: 500, time: 0.362, data: 0.011) D_A: 0.164 G_A: 0.476 cycle_A: 0.658 idt_A: 0.244 D_B: 0.127 G_B: 0.220 cycle_B: 0.481 idt_B: 0.212 \n",
            "(epoch: 57, iters: 600, time: 0.354, data: 0.003) D_A: 0.111 G_A: 0.959 cycle_A: 0.749 idt_A: 0.274 D_B: 0.341 G_B: 0.375 cycle_B: 0.777 idt_B: 1.435 \n",
            "(epoch: 57, iters: 700, time: 1.018, data: 0.003) D_A: 0.140 G_A: 0.821 cycle_A: 0.906 idt_A: 0.211 D_B: 0.336 G_B: 0.461 cycle_B: 0.544 idt_B: 0.400 \n",
            "(epoch: 57, iters: 800, time: 0.379, data: 0.005) D_A: 0.091 G_A: 0.980 cycle_A: 1.151 idt_A: 0.176 D_B: 0.050 G_B: 0.763 cycle_B: 0.540 idt_B: 0.535 \n",
            "(epoch: 57, iters: 900, time: 0.315, data: 0.003) D_A: 0.082 G_A: 0.726 cycle_A: 0.896 idt_A: 0.254 D_B: 0.097 G_B: 0.532 cycle_B: 0.742 idt_B: 0.239 \n",
            "(epoch: 57, iters: 1000, time: 0.309, data: 0.007) D_A: 0.081 G_A: 0.419 cycle_A: 0.850 idt_A: 0.167 D_B: 0.069 G_B: 0.499 cycle_B: 0.591 idt_B: 0.218 \n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot ./datasets/data_sample --name night2dayV2 --model cycle_gan  --use_wandb --n_epochs 20 --n_epochs_decay 40 --epoch_count 20 --continue_train "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
        "\n",
        "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp ./checkpoints/night2dayV2/latest_net_G_A.pth ./checkpoints/night2dayV2/latest_net_G.pth"
      ],
      "metadata": {
        "id": "-ZyvjnCF6lhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6V-ol0pB_W4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b058bf-937b-414c-8fb5-298eeec0d502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/data_v2/testB      \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: night2dayV2                   \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 1                             \t[default: 50]\n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content                      \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: True                          \t[default: False]\n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/night2dayV2/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "OrderedDict([('real', tensor([[[[-0.3255, -0.2706, -0.2000,  ..., -0.7255, -0.7333, -0.7412],\n",
            "          [-0.3412, -0.2784, -0.2235,  ..., -0.7255, -0.7255, -0.7333],\n",
            "          [-0.3647, -0.3098, -0.2627,  ..., -0.7255, -0.7255, -0.7255],\n",
            "          ...,\n",
            "          [-0.5059, -0.5059, -0.5216,  ..., -0.7098, -0.7176, -0.7255],\n",
            "          [-0.5216, -0.5216, -0.5216,  ..., -0.7176, -0.7333, -0.7412],\n",
            "          [-0.5216, -0.5216, -0.5216,  ..., -0.7412, -0.7569, -0.7647]],\n",
            "\n",
            "         [[-0.4667, -0.4118, -0.3412,  ..., -0.7961, -0.8039, -0.8118],\n",
            "          [-0.4745, -0.4196, -0.3647,  ..., -0.7961, -0.7961, -0.8039],\n",
            "          [-0.4902, -0.4353, -0.3882,  ..., -0.7961, -0.7961, -0.7961],\n",
            "          ...,\n",
            "          [-0.5529, -0.5608, -0.5686,  ..., -0.7725, -0.7804, -0.7961],\n",
            "          [-0.5608, -0.5608, -0.5608,  ..., -0.7804, -0.7961, -0.8039],\n",
            "          [-0.5608, -0.5608, -0.5608,  ..., -0.8118, -0.8275, -0.8275]],\n",
            "\n",
            "         [[-0.7020, -0.6471, -0.6000,  ..., -0.8588, -0.8667, -0.8745],\n",
            "          [-0.7098, -0.6549, -0.6078,  ..., -0.8588, -0.8588, -0.8667],\n",
            "          [-0.7176, -0.6706, -0.6314,  ..., -0.8588, -0.8588, -0.8588],\n",
            "          ...,\n",
            "          [-0.6706, -0.6784, -0.6706,  ..., -0.8510, -0.8588, -0.8745],\n",
            "          [-0.6706, -0.6706, -0.6706,  ..., -0.8667, -0.8824, -0.8902],\n",
            "          [-0.6706, -0.6706, -0.6706,  ..., -0.8902, -0.8980, -0.9059]]]],\n",
            "       device='cuda:0')), ('fake', tensor([[[[-0.3574, -0.3214, -0.2798,  ..., -0.8127, -0.7726, -0.8259],\n",
            "          [-0.3753, -0.3420, -0.2799,  ..., -0.8361, -0.7899, -0.7811],\n",
            "          [-0.3996, -0.3668, -0.3083,  ..., -0.8447, -0.8452, -0.8194],\n",
            "          ...,\n",
            "          [-0.5309, -0.5320, -0.5546,  ..., -0.6804, -0.6808, -0.7088],\n",
            "          [-0.5445, -0.5463, -0.5527,  ..., -0.7246, -0.7264, -0.7500],\n",
            "          [-0.5493, -0.5457, -0.5391,  ..., -0.7551, -0.7464, -0.7594]],\n",
            "\n",
            "         [[-0.5235, -0.4950, -0.4446,  ..., -0.8794, -0.8444, -0.8577],\n",
            "          [-0.5549, -0.5284, -0.4579,  ..., -0.8899, -0.8472, -0.8220],\n",
            "          [-0.5779, -0.5532, -0.4841,  ..., -0.8906, -0.8826, -0.8325],\n",
            "          ...,\n",
            "          [-0.6192, -0.6150, -0.6306,  ..., -0.7783, -0.7654, -0.7756],\n",
            "          [-0.6190, -0.6217, -0.6267,  ..., -0.8190, -0.8148, -0.8159],\n",
            "          [-0.6269, -0.6283, -0.6170,  ..., -0.8346, -0.8335, -0.8287]],\n",
            "\n",
            "         [[-0.7271, -0.7042, -0.6684,  ..., -0.8833, -0.8559, -0.8920],\n",
            "          [-0.7436, -0.7183, -0.6757,  ..., -0.9086, -0.8803, -0.8742],\n",
            "          [-0.7548, -0.7392, -0.6968,  ..., -0.9060, -0.9185, -0.8935],\n",
            "          ...,\n",
            "          [-0.7159, -0.7152, -0.7282,  ..., -0.8539, -0.8428, -0.8548],\n",
            "          [-0.7112, -0.7169, -0.7288,  ..., -0.8758, -0.8737, -0.8772],\n",
            "          [-0.7148, -0.7132, -0.7154,  ..., -0.8882, -0.8851, -0.8867]]]],\n",
            "       device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "!python test_for_me.py --dataroot ./datasets/data_v2/testB --name night2dayV2 --model test --no_dropout --use_wandb --num_test 1 --results_dir /content"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CycleGAN_git.ipynb",
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}